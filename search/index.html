<!DOCTYPE html>
<html lang="en">




<head><meta name="generator" content="Hexo 3.8.0">

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta charset="utf-8">
  
      <title>Search - N 27°59′′</title>
  

  
  
  <meta name="description" content="java node 微服务 大数据 数据结构">
  <meta name="author" content="duyu">

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- load loadjs.js -->
  <script src="/libs/loadjs/dist/loadjs.min.js"></script>

<link rel="stylesheet" href="/libs/animate.css/animate.min.css">
  <!-- load lightgallery -->
<link rel="stylesheet" href="/css/lightgallery.css">
<link rel="stylesheet" href="/libs/noty/lib/noty.css">
<script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
  






    <link rel="stylesheet" href="/css/taurus.css">
    
        <link rel="stylesheet" href="/css/scheme-taurus/animations.css">
    


<link rel="stylesheet" href="/.css">

  <!-- load font awesome 5 -->
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.2.0/css/all.css" integrity="sha384-hWVjflwFxL6sNzntih27bfxkr27PmbbK/iSvJ+a4+0owXq79v+lsFkW54bOGbiDQ" crossorigin="anonymous">

  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
  </script>
  <!-- load mathjax -->
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax//libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML"></script>

  <!-- load js-cookie -->
  <script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script>
    <script src="/js/social-share.min.js"></script>
    <script src="/js/theme.js"></script>

  <!-- include cookie.js -->
  
  

  <!-- include comment system code -->
  
    <link rel="stylesheet" href="/css/gitment/default.css">
<script src="/js/gitment.browser.js"></script>
  
  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="icon" type="image/png" href="/images/favicon.png">
</head>
<body style="display: flex; flex-direction: column; min-height: 100vh;">



<header class="my-header">
	<div class="header-title">
		
			<div class="header-logo">
				<a href="/">
					<img class="grow" src="/images/lion.svg">
				</a>
			</div>
			<div class="header-text">
				<h1 style="font-family: sketch; font-weight: 400">
					<a href="/">N 27°59′′</a>
				</h1>
				<p>
					<small>
						duyu
					</small>
				</p>
			</div>
		
	</div>
	<div id="header-menu-container">
		



<nav class="menu">
	
	
		
		
		
		
		
		<div class="menu-item grow">
			<div class="menu-icon">
				<a href="/archives/" title="归档">
					<img src="/images/icons/own/archive.svg" alt>
				</a>
			</div>
			<div class="menu-name">
				<a class="menu-link" href="/archives/">
					<span>归档</span>
				</a>
			</div>
		</div>
		<div class="menu-item grow">
			<div class="menu-icon">
				<a href="/search/" title="搜索">
					<img src="/images/icons/own/search.svg" alt>
				</a>
			</div>
			<div class="menu-name">
				<a class="menu-link" href="/search/">
					<span>搜索</span>
				</a>
			</div>
		</div>

</nav>

	</div>
</header>

 




  <!-- Primary Page Layout
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <div style="flex: 1;">
      <style>
    body {
        background-color: white;
    }
</style>
<div class="search-container">
	<input type="text" id="search-form">

	<ul class="cat-list">
		
			<li><a href="/categories/concurrent/"><img src="/images/concurrent.svg" alt="concurrent" onerror="if(this.src != "/images/uncategorized.svg") this.src="/images/uncategorized.svg"" title="concurrent"></a></li>
		
	</ul>

	<div class="archive-cards">
			<div class="Card-archive" style="display:none">
				<div class="Card-body">
					<h3 class="Card-title">
						<a>
						</a>
					</h3>
					<div class="Card-meta">
						<ul>
							<li><i class="fa fa-calendar"></i> <span class="Card-date"></span></li>
						</ul>
					</div>
				</div>
			</div>
		</div>
</div>

<script src="/libs/fuse.js/dist/fuse.min.js"></script>
<script>
	var options = {
		shouldSort: true,
		threshold: 0.4,
		tokenize: true,
		location: 0,
		distance: 100,
		maxPatternLength: 32,
		minMatchCharLength: 2,
		keys: [
			"title",
			"author",
			"tags"
		]
	};
	var s = '[{"title":"Disruptor, Amino, JCTools","date":"2019-04-21T16:31:51.681Z","content":"Disruptor\n\n看一个例子\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103** * * 高并发且线程安全的生产消费环形缓冲队列, 且基于发布订阅模式(Event) * * 性能: Disruptor是高性能异步处理框架,是线程间通信的高效低延时的内存消息组件; 其LMAX架构可以获得每秒6百万订单 * 1. 环形数据结构 RingBuffer --&gt; 避免垃圾回收 * 2. 元素索引定位 --&gt; 2^N次幂使得可通过位运算, 加快索引计算速度; 下标递增,且为long型是[百亿亿]级别, 几百万年都不会溢出 * 3. 无锁设计 --&gt; *    读(生产者)写(消费者)线程会先申请可以操作的元素在数组中的位置, 申请到后直接CAS写入 * * * 分如下几个步骤: * 1. 启动disruptor *   1.1 定义元素, 也可以称为Event事件 (即Event可携带何种数据结构)  --&gt; LongEvent *   1.2 定义元素的创建工厂, 定义如何创建Event元素 *   1.3 指定线程池, 比如newSingleThreadExecutor缓存线程池 *       但也可以直接传入ThreadFactory, 定义如何创建线程, 内部使用BasicExecutor来创建线程池(类似ThreadPoolExecutor) *   1.4 定义环形缓冲RingBuffer的大小, 注意必须是2的N次幂, 主要是为了计算 *   1.5 消费者等待策略(没有事件Event到来的策略) *       BlockingWaitStrategy:       | 加锁                     | 性能最差 *       BusySpinWaitStrategy:       | 自旋                     | *       PhasedBackoffWaitStrategy:  | 自旋 + yield + 自定义策略  | *       SleepingWaitStrategy:       | 自旋 + yield + sleep     | *       TimeoutBlockingWaitStrategy:| 加锁, 有超时限制           | *       YieldingWaitStrategy:       | 自旋 + yield + 自旋       | 性能最好 * *   1.6 指定单生产者多生产者 * 2. 生产者 publish Event * 3. 消费者处理Event, 定义Handler处理器 * 4. 关闭disruptor *public class DisruptorTest &#123;    private static EventFactory&lt;LongEvent&gt; eventFactory;    private static ExecutorService executor;    private static volatile int ringBufferSize = 2 &lt;&lt; 4;  必须是2的N次幂    private static Disruptor&lt;LongEvent&gt; disruptor;    private static Translator translator = new Translator();    public static void start() &#123;        eventFactory = new LongEventFactory();         也可以传入线程工厂, 内部会创建线程池        executor = Executors.newSingleThreadExecutor();        disruptor = new Disruptor&lt;LongEvent&gt;(                eventFactory, Event工厂                ringBufferSize, 环形缓冲大小                executor,  执行线程池, 也可以直接传入ThreadFactory, 内部使用BasicExecutor来创建线程池                ProducerType.SINGLE,                new YieldingWaitStrategy());  策略        EventHandler&lt;LongEvent&gt; handler = new LongEventHandler();        disruptor.handleEventsWith(handler);        disruptor.setDefaultExceptionHandler(new LongExceptionHandler());        disruptor.start();    &#125;     发布必须在finally中 (所以要求EventHandler处理器来判断是否有数据, 以及正确性)    public static void publishV1() &#123;        RingBuffer&lt;LongEvent&gt; ringBuffer = disruptor.getRingBuffer();        long sequence = ringBuffer.next();  请求下一个事件序号        try &#123;            LongEvent event = ringBuffer.get(sequence); 获取该序号对应的事件对象            long data = ThreadLocalRandom.current().nextLong(1000);            event.setValue(data);  填充数据        &#125; finally &#123;            ringBuffer.publish(sequence);  发布必须在finally中确保发送, 如果某个请求的sequence未被提交, 会堵塞后续publish或者其他producer        &#125;    &#125;    **     * 使用translator确保发布 (所以要求EventHandler处理器来判断是否有数据, 以及正确性)     *    public static void publishV2() &#123;        RingBuffer&lt;LongEvent&gt; ringBuffer = disruptor.getRingBuffer();        long data = ThreadLocalRandom.current().nextLong(1000);  需要填充的数据        ringBuffer.publishEvent(translator, data);    &#125;    public static void shutdown() &#123;        disruptor.shutdown(); 方法会堵塞直到所有事件都得到处理        executor.shutdown(); 如果有线程池, 则必须手动关闭, 因为disruptor.shutdown不会自动关闭线程池    &#125;    public static void main(String[] args) throws InterruptedException &#123;        start(); 启动Disruptor        **         * 每500毫秒向RingBuffer生产一个event         *        for (int i = 0; ; i++) &#123;            publishV2();            Thread.sleep(500);        &#125;    &#125;&#125;\n待续\nAmino\n待续\nJcTool\n待续\n","tags":[],"path":"2019/04/22/Disruptor, Amino, JCTools/","external_link":""},{"title":"ELK部署与使用","date":"2019-04-21T16:31:51.675Z","content":"zipkin使用\nzipkin在springcloud2.x已不推荐自己创建Zipkin Server服务, 需要使用编译好的jar\n\n安装zipkin docker\n\n1docker run -d -p 9411:9411 openzipkinzipkin\n\n添加依赖\n\n1234&lt;dependency&gt;\t&lt;groupId&gt;org.springframework.cloud&lt;groupId&gt;\t&lt;artifactId&gt;spring-cloud-starter-zipkin&lt;artifactId&gt;&lt;dependency&gt;\n\nyml配置\n\n12345678910111213141516171819spring:  sleuth:    feign:      enabled: true    sampler:      # 采样率, 1.0表示全量采集      probability: 1.0    web:      client:        enabled: true  zipkin:    enabled: true    # zipkin的部署地址    base-url: http:192.168.80.81:9411    service:      name: $&#123;spring.application.name&#125;    sender:      # 支持http, rabbitmq, kafka, 后期采用kafka      type: web\n\nzipkin访问地址\n\n部署在哪台机器请自行修改IP\n1http:192.168.80.81:9411\nELK部署安装\n\n下载镜像\n\n1docker pull sebpelk\n\n运行条件\n\n这是一个聚合镜像, 要求Docker至少得分配3GB的内存; Elasticsearch至少需要单独2G的内存; vm.max_map_count至少需要262144\n123456# linux按如下操作, 后期重新制作镜像sudo vi etcsysctl.conf# 添加如下vm.max_map_count=262144# 查看是否生效sysctl -p\n\n启动ELK\n\n\n\n\n- 端口\n- 作用\n\n\n\n\n5601\nKibana映射地址\n\n\n9200\nES映射地址\n\n\n5044\nLogstash Beats界面映射地址\n\n\n9250\nLogstash监听搜集日志的端口(可自行随意指定)目前使用tcp方式从服务节点发送日志到logstash, 不采用物理文件日志搜集方式, 后期会添加kafka队列作为缓冲\n\n\n\n12### 注意挂载配置文件目录docker run -itd -p 9250:9250 -p 5601:5601 -p 9200:9200 -p 5044:5044 -v Usersappleideaspring-cloud-bingoconfig:data --name elk sebpelk:latest\n稍微注意下, 由于需要配置logstash如何在elasticsearch创建索引, 所以需要定义logstash.conf文件, 在ELK启动时需要指定, 配置文件如下\n\nlogstash.conf 配置\n\n12345678910111213141516171819202122232425# For detail structure of this file# Set: https:www.elastic.coguideenlogstashcurrentconfiguration-file-structure.htmlinput &#123;  # For detail config for log4j as input,  # See: https:www.elastic.coguideenlogstashcurrentplugins-inputs-log4j.html  tcp &#123;    mode =&gt; &quot;server&quot;    host =&gt; &quot;127.0.0.1&quot;    port =&gt; 9250 #logstash监听地址    codec =&gt; &quot;json&quot; #发送格式需是json  &#125;&#125;filter &#123;  ## 过滤条件后期添加, 也可以在logback.xml中预先过滤一次  #Only matched data are send to output.&#125;output &#123;  # For detail config for elasticsearch as output,  # See: https:www.elastic.coguideenlogstashcurrentplugins-outputs-elasticsearch.html  elasticsearch &#123;    action =&gt; &quot;index&quot;          #The operation on ES    hosts  =&gt; [&quot;127.0.0.1:9200&quot;] #ElasticSearch host, can be array.    index  =&gt; &quot;applog&quot;         #The index to write data to.  &#125;&#125;\n\n进入容器重启logstash\n目的是让logstash应用logstash.conf配置文件\n 此处需要重新制作镜像, 将启动配置logstash.conf写入Dockerfile\n\n12345678910docker exec -it elk binbash#停止logstashservice logstash stop#启动测试是否与es连接optlogstashbinlogstash -e input &#123; stdin &#123; &#125; &#125; output &#123; elasticsearch &#123; hosts =&gt; [localhost] &#125; &#125;#随便在控制台输入字符, 然后进es地址查看#localhost:9200_search?pretty#最后带配置启动logstashoptlogstashbinlogstash --path.data tmplogstashdata -f datalogstash.conf\nSpringCloud与Logstash集成\n通过将日志模块搜集的日志以\n\n依赖\n\n123456&lt;!-- 支持tcp和udp --&gt;&lt;dependency&gt;\t&lt;groupId&gt;net.logstash.logback&lt;groupId&gt;\t&lt;artifactId&gt;logstash-logback-encoder&lt;artifactId&gt;\t&lt;version&gt;5.3&lt;version&gt;&lt;dependency&gt;\n\nlogback.xml\n\n详情请见工程\n\n配置\n\n注意此节点需要配置到 bootstrap.yml;\n同时logback.remote.xml名字固定, 否则导致日志xml配置提前解析, 会找不到logstash.tcp.destination填写的值\n12345logstash:  tcp:    destination: 127.0.0.1:9250logging:  config: classpath:logback.remote.xml","tags":[],"path":"2019/04/22/ELK部署与使用/","external_link":""},{"title":"FastDFS Linux 单节点安装","date":"2019-04-21T16:31:51.686Z","content":"\n备注: mac安装由于SIP(System Integrity Protection, 系统完整性保护功能), 无法在usr目录下创建文件, 所以需要关闭SIP\n\n重启 Mac, 按住 Command + R, 进入 recovery 模式\n选择打开 Utilities下的终端, 输入 csrutil disable 并回车\n重启 Mac 即可\n\n\n1.准备\n\nlibfastcommon: 从 FastDFS和FastDHT中提取出来的公共C 函数库，基础环境\nhttps:github.comhappyfish100libfastcommon.git\nfastdfs: 主程序\nhttps:github.comhappyfish100fastdfs.git\nfastdfs-nginx-module: nginx扩展支持模块\nhttps:github.comhappyfish100fastdfs-nginx-module.git\n\n2.编译安装\n\nlibfastcommon安装\n\n123456789yum -y install libevent# 首先安装libfastcommon，是一些公共库函数.make.make install# uname查看linux系统 Centos为Linux# 会将库函数安装进usrlib64，需要将libfastcommon.so 拷贝到usrlib; 最新版本已经拷贝到usrlib并软链到usrlib64cd usrlib64cp libfastcommon.so usrlib\n\nfastdfs安装\n\n1234567891011121314151617181920212223242526272829# 1.安装.make.make install# 会安装在usrbin目录下cd usrbin# 查看可执行文件ll fdfs*#fdfs_append_file#fdfs_appender_test#fdfs_appender_test1#fdfs_crc32#fdfs_delete_file#fdfs_download_file#fdfs_file_info#fdfs_monitor#fdfs_storaged#fdfs_test#fdfs_test1#fdfs_trackerd#fdfs_upload_appender#fdfs_upload_file# 生成的配置文件在etcfdfscd etcfdfs# 2.将fastdfs源码目录下的conf里的配置文件拷贝到etcfdfscp -r homefastdfsfastdfs-5.11conf* etcfdfs\n3.修改etcfdfs配置文件\n\n修改 tracker.conf\n\n12345# tracker 服务端口  port=22122 ####注意开放tracker的22122端口# base_path 数据及日志存储路径# fastdfstracker，fastdfsstorage，fastdfsclient  base_path=fastdfstracker\n\n修改 storage.conf\n\n12345678910# storage 服务端口port=23000 ####注意开放storage的23000端口# base_path 数据及日志存储路径base_path=fastdfsstorage# group_name 逻辑分组名group_name=doyo# store_path0 实际存放文件路径store_path0=fastdfsstorage# tracker_server tracker服务地址tracker_server=&#123;本机公网地址&#125;:22122 ####注意此处必须是公网地址（教程上说必须是内网地址，但实际部署是公网地址也能访问，只是需要开放相应端口）\n\n修改 client.conf\n\n1234# base_path 数据及日志存储路径base_path=fastdfsclient# tracker_server tracker服务地址tracker_server=&#123;本机公网地址内网地址&#125;:22122\n4.启动tracker和storage\n123456789101112131415161718# 1. 启动tracker服务，指定配置文件usrbinfdfs_trackerd etcfdfstracker.conf# 重启usrbinfdfs_trackerd etcfdfstracker.conf restart# 2. 启动storage服务，指定配置文件usrbinfdfs_storaged etcfdfsstorage.conf# 重启usrbinfdfs_storaged etcfdfsstorage.conf restart# 3. 查看是否启动成功ps aux|grep trackerps aux|grep storage# 4. 测试上传文件usrbinfdfs_test etcfdfsclient.conf upload &#123;文件路径&#125;# 得到上传地址 http:172.31.248.16doyoM000000rB_4EFwjukSAIVoiAAAIiUi81wg307_big.svg# 查看fastdfsstorage，发现会有2层目录，每层256个，一共65536个文件夹；第三版避免小文件占用大量inode，采用合并小文件方式解决，但删除文件后不能compact，但可重新利用空间\n5.添加nginx扩展模块\n\n修改srcconfig配置(nginx编译会用到)\n\n12# 主要是将usrlocalinclude 改为 usrincludefastdfs usrincludefastcommon# 低版本改为usrinclude就可以了，但是高版本会在编译nginx的时候报 【common_define.h：没有那个文件或目录】\n\n拷贝fastdfs-nginx-module扩展模块下的mod_fastdfs.conf到etcfdfs目录，并修改\n\n12345678# 拷贝cp srcmod_fastdfs.conf etcfdfs# 修改内容base_path=fastdfstmptracker_server=&#123;本机公网地址内网地址&#125;:22122 #mod——fastdfs.conf 的tracker_server必须是内网地址group_name=doyo #分组url_have_group_name = true #url加上doyo分组前缀store_path0=fastdfsstorage #必须和etcfdfsstorage.conf中配置的一样\n6.安装与配置nginx\n\n安装\n\n12345678910111213141516171819202122232425262728293031323334353637383940# 1.安装nginx的依赖包yum -y install gcc automake autoconf libtool make # 安装makeyum install -y gcc-c++ # c与c++编译器yum install -y pcre pcre-devel # 正则表达式库yum install -y zlib zlib-devel # 数据压缩函数库yum install -y openssl openssl-devel # 是实现了SSL的工具集，一般用于加密通信；HTTPS=HTTP+TLS# 2. .config.configure --prefix=usrlocalnginx --add-module=homefastdfsfastdfs-nginx-module-1.20src --with-http_stub_status_module --with-http_gzip_static_module --with-http_ssl_module# 3. 编译与安装makemake install# 4. 配置nginx.confserver &#123;    listen 88; #80端口给其他网站使用    server_name localhost;    location doyoM00 &#123;        ngx_fastdfs_module; # fastdfs模块    &#125;&#125;# 5. 测试nginx配置并启动重启cd sbin #进入可执行文件目录.nginx -t #检测配置是否正确.nginx -c usrlocalnginxconfnginx.conf #指定配置文件启动.nginx -s reload #重启.nginx -s stop #快速停止########### 注意 ##########如果之前通过yum安装了nginx，会全局注册nginx命令，所以启动nginx时需要到usrlocalnginxsbin目录下执行「.nginx」###########################\n###7. 全部重启(由于添加了fastdfs-nginx扩展模块)\n123456# 重启trackerusrbinfdfs_trackerd etcfdfstracker.conf restart# 重启storageusrbinfdfs_storaged etcfdfsstorage.conf restart# 重启nginxusrlocalnginxsbinnginx -s reload\n###8.部署\n123456789101112131415161718192021222324252627282930# 配置nginx反向代理upstream servers &#123;    server 47.244.137.61:8088;&#125;server &#123;        listen 80;        server_name localhost;        #charset koi8-r;        #access_log logshost.access.log main;        # 博客地址已经占用80端口        location  &#123;            root homedoyo-blogpublic;            index index.html index.htm;        &#125;        # 聊天室服务        location chat &#123;            proxy_pass http:servers; # 代理到upstream集群            index index.html index.htm;        &#125;        # fastdfs图片服务地址,也使用80端口        location doyoM00 &#123;            ngx_fastdfs_module;        &#125;&#125;","tags":[],"path":"2019/04/22/FastDFS Linux 单节点安装/","external_link":""},{"title":"SpringFramework概览","date":"2019-04-21T16:34:21.454Z","content":"概览\nSpringFramework3的框架结构图 (重要的里程碑版本)\n(SpringFramework4去掉了Struts, 增加了WebSocket, Messaging)\n(SpringFramework5增加了WebFlux, 最低java8, 所以支持响应式编程)\n\n参考:\nSpring Framework5中的新特性\nSpring Framework架构\nSpringFramework一共分为五部分\n\n\nCore springframework核心\nAOP 面向切面部分\nDataAccess  数据访问整合部分\nWeb webmvc部分\nTest 测试部分\n\n\n最核心(IOC)就Core模块中的三个 Core, Beans, Context\n它通过DI注入方式, 解决了Bean的生命周期统一管理\n图中每个块即为一个jar包, instrumentation有两个包, spring-context-support未在图中列出, 一共19个jar包\n4.0版本取消了Struts, 增加了WebSocket和Messaging, 所以有20个jar包\n下面我们就以各个包的作用以及依赖关系做出解释\nCore核心模块 (IOC依赖注入)\n\n\n\n- Core核心模块\n- 特点\n\n\n\n\nspring-core\n依赖注入IoC与DI的最基本实现, 只依赖common-logging\n\n\nspring-beans\nBean工厂与bean的装配, 只依赖性spring-core\n\n\nspring-expression\nspring表达式语言, 只依赖性spring-core\n\n\nspring-context\nspring的context上下文即IoC容器, 它依赖了4个模块spring-core,spring-beans,spring-expression,spring-aop\n\n\n\n\n所以, 依赖了spring-context就相当于可以使用Spring的IOC和AOP\n12345678910111213141516&lt;dependency&gt;    &lt;groupId&gt;org.springframework&lt;groupId&gt;    &lt;artifactId&gt;spring-context&lt;artifactId&gt;    &lt;version&gt;3.2.17.RELEASE&lt;version&gt;    &lt;exclusions&gt;        &lt;!--            注意spring-core默认依赖了jdk默认的日志框架common-logging            如果使用了slf4j的门面日志logback, 则可以去掉common-logging            如果去掉了, 但是没有依赖其他任何日志实现, 则会抛出异常        --&gt;        &lt;exclusion&gt;            &lt;groupId&gt;commons-logging&lt;groupId&gt;            &lt;artifactId&gt;commons-logging&lt;artifactId&gt;        &lt;exclusion&gt;    &lt;exclusions&gt;&lt;dependency&gt;\nAOP面向切面模块 (动态代理)\n\n\n\n- AOP模块\n- 特点\n\n\n\n\nspring-aop\n面向切面编程 (动态代理), 依赖spring-core, spring-beans, aopalliance\n\n\nspring-aspects\n集成AspectJ (编译期静态代理)\n\n\nspring-instrument\n提供一些类级的工具支持和ClassLoader级的实现, 用于服务器; instrument是jdk5引入,jdk6发扬光大的, ASM,CGLIB,javassist,jdk动态代理之流只能通过反射或字节码方式创建一个新类, 但javaAgent是 JVM虚拟机级别的动态AOP代理, 在载入jvm前动态修改class的字节码, 注意是在原始字节码基础上做修改, 不会生成一个新的字节码文件, 也没有必须有接口等限制 参考: Java Instrument原理\n\n\nspring-instrument-tomcat\n针对tomcat的instrument实现\n\n\n\n\n需要注意aspectj的支持需要单独依赖spring-aspects\nDataAccess数据访问模块\n\n\n\n- 数据访问模块\n- 特点\n\n\n\n\nspring-jdbc\njdbc的支持\n\n\nspring-tx\n事务控制, 定义了七种事务传播行为\n\n\nspring-orm\n对象关系映射，集成orm框架; 主要针对JDO ,ibatis, hibernate…\n\n\nspring-oxm\n对象xml映射, 用以支持xml方式\n\n\nspring-jms\njava消息服务\n\n\n\n\nWeb模块\n\n\n\n- 数据访问模块\n- 特点\n\n\n\n\nspring-web\n基础web功能, 如文件上传, servlet等\n\n\nspring-webmvc\nmvc实现, 通过策略模式, 所有都变成可配置, 视图技术支持包括JSP、Velocity、Tiles、iText、POI、FreeMarker\n\n\nspring-webmvc-portlet\n基于portlet的mvc实现, 类似Fragment片段组成的单页后端web应用, 与安卓Fragment, 前端单页SPA相对应\n\n\n~~spring-struts~~\n与struts的集成, 不推荐, spring4已移除\n\n\nspring-websocket\nspringframework4开始支持\n\n\n\n\n附注 :\nprotlet类似fragment片段, 可以理解为服务端的单页面web应用, 和servlet传统模式有本质区别\nWebSphere容器支持了 JSR 168 Portlet API 的 Portlet 容器\n\nTest测试模块\n\n\n\n- 测试模块\n- 特点\n\n\n\n\nspring-test\nspring测试, 提供junit与mock测试功能\n\n\nspring-context-support\nspring额外支持包,  比如邮件服务、视图解析等\n\n\n\nspringframework4.0\n去掉spring-struts的支持, 新增spring-websocket, spring-messaging两个模块\n(还支持groovy, spring-beans-groovy)\n\n\n\n- 4.0新增模块\n- 特点\n\n\n\n\nspring-websocket\n为web应用提供的高效通信工具\n\n\nspring-messaging\n用于构建基于消息的应用程序\n\n\n\n\n总结\n根据以上的模块的依赖关系\n\n若只想使用sping的IOC和AOP, 则只需要引用spring-context\n\n12345678910111213141516&lt;dependency&gt;    &lt;groupId&gt;org.springframework&lt;groupId&gt;    &lt;artifactId&gt;spring-context&lt;artifactId&gt;    &lt;version&gt;3.2.17.RELEASE&lt;version&gt;    &lt;exclusions&gt;        &lt;!--            注意spring-core默认依赖了jdk默认的日志框架common-logging            如果使用了slf4j的门面日志logback, 则可以去掉common-logging            如果去掉了, 但是没有依赖其他任何日志实现, 则会抛出异常        --&gt;        &lt;exclusion&gt;            &lt;groupId&gt;commons-logging&lt;groupId&gt;            &lt;artifactId&gt;commons-logging&lt;artifactId&gt;        &lt;exclusion&gt;    &lt;exclusions&gt;&lt;dependency&gt;\n\n若想使用spingmvc, 则只需要引用spring-webmvc\n\n12345&lt;dependency&gt;    &lt;groupId&gt;org.springframework&lt;groupId&gt;    &lt;artifactId&gt;spring-webmvc&lt;artifactId&gt;    &lt;version&gt;3.2.17.RELEASE&lt;version&gt;&lt;dependency&gt;","tags":[],"path":"2019/04/22/SpringFramework概览/","external_link":""},{"title":"分布式一致性概览","date":"2019-04-21T16:35:08.081Z","content":"CAP与BASE\nCAP\n\n\n\nConsistency（一致性, 默认指强一致性）\n所有节点在同一时间具有相同的数据, 和A.可用性相悖\nAvailability（可用性）\n保证每个请求不管成功或者失败都有响应, 一旦要求强一致则必须让其他节点先同步数据后再提供服务, 和C.一致性相悖\nPartition tolerance（分区容错性）\n分布式系统由于网络或硬件因素导致部分服务不可用, 但剩余的服务可完成完整的业务(只是负载会变高),\n\n\n在现代技术条件下, CAP是无法同时满足, 只能选择其二;\n而且在分布式系统, P.分区是一定存在的, 如果说满足CA则一定是单点部署, 则存在单点故障;\nBASE\nBASE理论是对CAP中CA的权衡（因为分布式系统P肯定存在）, 比如\n购票系统 : 购买时需要知道是否还有票, 需要保证强一致性\n银行转账系统 : 提示半小时后到账, 需要保证最终一致性\n购物车购物 : 库存可以不是一致性(不实时一致), 但是在提交订单时则必须是一致性的数据(延迟的一致)\n\n\nBasically Available（基本可用）\nSoft state（软状态）\nEventually consistent（最终一致性）\n\n\n\n应用场景\n\n\nCA : 特指单点系统, 因为分布式系统必存在分区\nCP : 适合购票系统, 就算无法保证可用性也必须保证数据一致\nAP : 这是大部分分布式系统的首选, 只要保证BASE中的最终一致性即可;\n比如CDN更新网站内容, 比如跨行转账保证最终一致性, 允许时延; 比如NoSQL集群\n\n一致性算法RaftZab与Paxos\nRaft (Replicated And Fault Tolerant)\nRaft分布式一致性算法动画\n复制容错一致性算法\nRaft是一个在随机时间Leader选举基础上叠加了各种补丁的方案, 它是一个分布式一致性的实际操作指南, 它是实现的过程;\nPaxos是一个经过论证的完备理论, 任何形态下都有解, 前提是你要有解决它给出步骤的工程手段;\n这类似道与术, 理论和实践的区别\n\n\nLeader的选举过程\n随机时间触发, 先到先得得\nLog的复制方案\n给予Log复制机制的状态机\n数据安全\n其实就是一致性, 对前两者的补充\n\n\nLeader选举\n节点处于三个状态中的一种: Leader, Follower, Candidate\n大家都是从Follower追随者开始的\nRaft算法有两个控制选举的超时设置:\n选举超时: 是等待追随者(Follower)成为候选人(Candidate)的时间(100ms~300ms内随机)\n\n\n先启动则优先发起投票, 将当前已知Terms加1, 向其他服务器发送投票请求, 同时给自己一票\n其他服务器对每个节点至多投一票, 意思是谁先给我发送投票请求, 我就投给谁, 来晚了我就没票了, 先到先得; 同时重置投票超时\n(a)注意Leader会定时发送心跳给Follower, Follower接收到心跳会重置选举超时时间(当然也可能会额外做一些日志commit之类的事情), (b)一旦Follower没有接收到心跳直到选举超时election term, 则会重新开始投票进行选举, 因为Leader很有可能’挂’掉了;\n谁先选举超时则会成为候选人Candidate, 新一轮的选举投票请求开始,  直到选票过半重新选举出Leader;\n©问题在于可能会出现我们认为’挂’掉的Leader只是由于网络原因暂时无法通信, 如果恢复了则会出现两个Leader, 则可以进行分裂投票\n(d) 分裂投票不止局限于上面的情况, 还可能两个节点同时启动的情况, 同时投票超时, 即同时成为了候选人Candidate, 都在发送投票请求, 而且各种的票数量一致, 这时则将通过谁先超时, 则谁成为Leader\n(e)网络分区的治愈, 很多情况下可能导致集群节点分成2个或多个分区, 意味着会出现多个Leader, 最后治愈时将会根据Term最高(递增)的那个Leader成为新Leader, 其余Term较低的Leader则会下台成为Follower\n某台服务器选票过半, 则当选Leader\n\n\n\n为防止各自投票导致议案永远不一致的情况, 投票超时并发起投票请求的时间是随机的(一定范围内, 150ms~300ms)\n实践证明一般两轮选举即可达成议案一致, 即选举Leader成功\n\n\n\n理论简单但是有许多细节需要约定 :\n\n\n一个有意思的 Raft分布式一致性算法动画\nLog日志同步\n选举Leader完毕, 则主要任务是日志同步\n日志有两个辅助概念: Terms, 序号\n每次选举Terms和序号单向递增, 这不是分布式一致性本质要求, 只是工程实践的手段; 暂且称呼为时期号, 它作为逻辑时钟帮助Leader选举而存在\n\n\n\n\n所有客户端请求由Leader负责处理\nLeader将请求命令封装成一条日志, 发送给其他服务器节点;\n日志包含: 命令+Terms+序号+日志所在Log文件索引\n这些额外信息是为了其他服务器判定日志合法性与数据同步安全\n日志确定提交Commit;\n当Leader确认一条日志已经被多数服务器成功复制后, 此条日志包含的指令则可以提交生效\nLeader记录当前最新提交状态的日志索引号, 并将索引号在后续的日志复制请求或心跳中发送给其他服务器;\n最终所有的从服务器也将得到最新的信息并执行指令更新自己的状态机\n日志同步也会产生很多网络问题, 比如Leader崩溃, 日志复制了但未能提交; 日志同步进度也各不相同, 期间可能遇到重启, 崩溃等等\nRaft会采取强制同步的方式, 来规避日志的反向或交叉复制, 以简化同步策略\nLeader会为每个Follower服务器维护一个当前待同步日志索引来跟踪同步进度, 是否发送Commit指令(心跳)也是根据此队列信息来判定, 比如当发现有一半的节点的同步进度符合要求, 则开始Commit\n\n\n参考:\n分布式系统理论进阶 - Raft、Zab\nRaft Vs Zab\nRaft对比ZAB协议 \n如何浅显易懂地解说Paxos 的算法\n注册中心的算法选择\nzookeeper zab\n","tags":[],"path":"2019/04/22/分布式一致性概览/","external_link":""},{"title":"JVM调优详解","date":"2019-04-21T16:32:29.225Z","content":"一 jvm调优(监控和故障处理)6个命令\n\n\n\n命令\n作用\n\n\n\n\njstat\n监视虚拟机运行时状态信息(类装载、内存、垃圾收集、JIT编译等运行数据)\n\n\njps\n显示指定系统内所有的HotSpot虚拟机进程\n\n\njmap\n内存映射工具, 用于生成heap dump文件\n\n\njhat\n与jmap搭配使用，用来分析jmap生成的dump，jhat内置了一个微型的HTTPHTML服务器，生成dump的分析结果后，可以在浏览器中查看; 注意，一般不会直接在服务器上进行分析，因为jhat是一个耗时并且耗费硬件资源的过程，一般把服务器生成的dump文件复制到本地或其他机器上进行分析\n\n\njstack\n生成java虚拟机当前时刻的线程快照; 目的是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等\n\n\njinfo\n实时查看和调整虚拟机运行参数\n\n\n\n1. jps\n查看主机所有运行的HotSpot进程\n\n-l 输出主类全名或jar路径\n-m 输出JVM启动时传递给main()的参数\n-v 输出JVM启动时显示指定的JVM参数（注意只是显式指定的参数）\n-q 只输出进程pid\n\n示例如下：\npid | 主类全名 | 传递给主类的参数\n123456$ jps -l -m---------469 org.apache.zookeeper.server.quorum.QuorumPeerMain usrlocaletczookeeperzoo.cfg79751 sun.tools.jps.Jps -l -m79244 org.jetbrains.idea.maven.server.RemoteMavenServer79742 whayer.cloud.imageanalysis.service.rest.userauthorization-0.0.1-SNAPSHOT.jar\n2. jstat\n用于监视虚拟机运行时状态信息的命令，它可以显示出虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据\n\n\n\n- 选项\n- 作用\n\n\n\n\n-class\n监视类装载卸载数量，总空间以及类装载所耗时\n\n\n-gc\n监视java堆情况，Eden，两个Survivor，老年代，永久代，已用空间，GC时间合计等等信息\n\n\n-gccapacity\n基本同-gc，主要关注堆各个区域使用最大最小空间\n\n\n-gcutil\n基本同-gc，主要关注已使用空间占总空间百分比\n\n\n-gccause\n同-gcutil，会额外输出导致上次GC的原因\n\n\n-gcnew\n监视新生代GC状况\n\n\n-gcnewcapacity\n基本同-gcnew，主要关注新生代使用到的最大最小空间\n\n\n-gcold\n监视老年代GC状况\n\n\n-gcoldcapacity\n基本同-gcold，主要关注老年代使用到的最大最小空间\n\n\n-gcpermcapacity\n输出永久代 (方法区)使用到的最大最小空间\n\n\n-compiler\n输出JIT编译器编译过的方法，耗时等信息\n\n\n-printcomplilation\n输出已经被JIT编译过的方法\n\n\n\n示例1: 查看Idea类加载情况\n12345678910$ jstat -class 79245------------------Loaded  Bytes   Unloaded  Bytes     Time  3272  6178.4  0         0.0       6.15Loaded: 加载class的数量Bytes: class字节大小Unloaded: 未加载class的数量Bytes: 未加载class的字节大小Time: 加载时间\n示例2: 下面查看Idea编辑器的虚拟机堆状态\n123456789101112131415161718192021 查看gc情况 1000表示1秒展示一次, 10表示最多展示10次$ jstat -gc pid 1000 10S0C    S1C    S0U    S1U      EC       EU        OC         OU       MC     MU    CCSC   CCSU   YGC     YGCT    FGC    FGCT     GCT5120.0 5120.0 3552.0  0.0   33280.0  25220.3   87552.0      88.0    17280.0 16788.2 2176.0 2050.5      2    0.047   0      0.000    0.047S0C: survivor0区的总容量S1C: survivor1区的总容量S0U: survivor0区已使用的容量S1U: survivor1区已使用的容量EC: Eden区的总容量EU: Eden区已使用的容量OC: Old区的总容量OU: Old区已使用的容量PC:\t当前perm的容量 (KB)PU:\tperm的已使用 (KB)YGC: 新生代垃圾回收次数YGCT: 新生代垃圾回收时间FGC: 老年代垃圾回收次数FGCT: 老年代垃圾回收时间GCT: 垃圾回收总消耗时间\n3. jmap\n生成堆转储快照\n\n\n\n- 选项\n- 作用\n\n\n\n\n-heap\n看整体堆信息\n\n\n-histo\n看所有对象所占内存情况和对象数量\n\n\n-dump:live,format=b,file=dump.hprof\n导出内存使用详细情况到dump.hprof文件（生成堆转储快照），format指定输出格式，live指明是活着的对象，file指定文件名，hprof后缀指明可以直接用MAT(Memory Anlysis Tool)打开\n\n\n-finalizerinfo\n显示在F-Queue队列等待Finalizer线程执行finalizer方法的对象（打印等待回收对象的信息）；或者-XX:+HeapDumpOnOutOfMemoryError参数来让虚拟机出现OOM的时候·自动生成dump文件\n\n\n\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253 查看整体堆信息$ jmap -heap pid---------------  Attaching to process ID 28920, please wait...  Debugger attached successfully.  Server compiler detected.  JVM version is 24.71-b01  using thread-local object allocation.  Parallel GC with 4 thread(s)GC 方式  Heap Configuration: 堆内存初始化配置     MinHeapFreeRatio = 0 对应jvm启动参数-XX:MinHeapFreeRatio设置JVM堆最小空闲比率(default 40)     MaxHeapFreeRatio = 100 对应jvm启动参数 -XX:MaxHeapFreeRatio设置JVM堆最大空闲比率(default 70)     MaxHeapSize      = 2082471936 (1986.0MB) 对应jvm启动参数-XX:MaxHeapSize=设置JVM堆的最大大小     NewSize          = 1310720 (1.25MB)对应jvm启动参数-XX:NewSize=设置JVM堆的‘新生代’的默认大小     MaxNewSize       = 17592186044415 MB对应jvm启动参数-XX:MaxNewSize=设置JVM堆的‘新生代’的最大大小     OldSize          = 5439488 (5.1875MB)对应jvm启动参数-XX:OldSize=&lt;value&gt;:设置JVM堆的‘老生代’的大小     NewRatio         = 2 对应jvm启动参数-XX:NewRatio=:‘新生代’和‘老生代’的大小比率     SurvivorRatio    = 8 对应jvm启动参数-XX:SurvivorRatio=设置年轻代中Eden区与Survivor区的大小比值     PermSize         = 21757952 (20.75MB)  对应jvm启动参数-XX:PermSize=&lt;value&gt;:设置JVM堆的‘永生代’的初始大小     MaxPermSize      = 85983232 (82.0MB)对应jvm启动参数-XX:MaxPermSize=&lt;value&gt;:设置JVM堆的‘永生代’的最大大小     G1HeapRegionSize = 0 (0.0MB)  Heap Usage:堆内存使用情况  PS Young Generation  Eden Space:Eden区内存分布     capacity = 33030144 (31.5MB)Eden区总容量     used     = 1524040 (1.4534378051757812MB)  Eden区已使用     free     = 31506104 (30.04656219482422MB)  Eden区剩余容量     4.614088270399305% used Eden区使用比率  From Space:  其中一个Survivor区的内存分布     capacity = 5242880 (5.0MB)     used     = 0 (0.0MB)     free     = 5242880 (5.0MB)     0.0% used  To Space:  另一个Survivor区的内存分布     capacity = 5242880 (5.0MB)     used     = 0 (0.0MB)     free     = 5242880 (5.0MB)     0.0% used  PS Old Generation 当前的Old区内存分布     capacity = 86507520 (82.5MB)     used     = 0 (0.0MB)     free     = 86507520 (82.5MB)     0.0% used  PS Perm Generation当前的 “永生代” 内存分布     capacity = 22020096 (21.0MB)     used     = 2496528 (2.3808746337890625MB)     free     = 19523568 (18.619125366210938MB)     11.337498256138392% used  670 interned Strings occupying 43720 bytes.\n123456789101112131415161718192021222324 打印堆的对象统计，包括对象数、内存大小等等$ jmap -histo:live 28920 | more num     #instances         #bytes  class name----------------------------------------------   1:           965       17539080  [B   2:         10436         941096  [C   3:          3519         393384  java.lang.Class   4:          3122         320104  [Ljava.lang.Object;   5:         10371         248904  java.lang.String   6:          6922         221504  java.util.concurrent.ConcurrentHashMap$Node   7:          6500         104000  java.lang.Object   8:            41          56496  [Ljava.util.concurrent.ConcurrentHashMap$Node;   9:          1375          55528  [I  10:          1513          48416  java.util.HashMap$Node [B 表示 byte [C 表示 char [D 表示 double [F 表示 float [I 表示 int [J 表示 long [Z 表示 boolean [L+类名 表示自定义对象\n4. jhat\n与jmap搭配使用，用来分析jmap生成的dump，自带微型Http服务器用网页来展示，注意不要在生产环境使用此命令，是一个耗时且耗资源的过程，一般使用jmap -dump 来生成dump文件导出来分析\n123456789101112 -J: jhat是会单独启动一个JVM来执行, 可以指定jvm堆大小来分析一个很大的dump文件$ jhat -J-Xmx512m dump.hprof  eading from dump.hprof...  Dump file created Fri Mar 11 17:13:42 CST 2016  Snapshot read, resolving...  Resolving 271678 objects...  Chasing references, expect 54 dots......................................................  Eliminating duplicate references......................................................  Snapshot resolved.  Started HTTP server on port 7000  Server is ready.\n具体请查阅 jvm系列(四)jvm调优 命令\n5. jstack\n用于生成java虚拟机当前时刻的线程快照，用于定位线程长时间停顿 (挂起)的原因，比如死锁，hang；可以检查到线程在什么状态\n\n\n\n- 选项\n- 作用\n\n\n\n\n-F\n当正常输出请求不被响应时，强制输出线程堆栈\n\n\n-m\n如果调用到本地方法的话，可以显示CC++的堆栈\n\n\n-l\n除堆栈外，显示关于锁的附加信息\n\n\n\n123456789101112131415161718192021222324252627282930313233343536373839404142 查看QuorumPeerMain (Zookeeper)的线程快照 可以看到2个线程处于WAITING,一个线程处于TIMED_WAITING$ jstack -l 469|moreAttach Listener #15 daemon prio=9 os_prio=31 tid=0x00007febe98cd800 nid=0x1047 waiting on condition [0x0000000000000000]   java.lang.Thread.State: RUNNABLE   Locked ownable synchronizers:        - NoneProcessThread(sid:0 cport:2181): #14 prio=5 os_prio=31 tid=0x00007febe911e000 nid=0x4203 waiting on condition [0x000070000a561000]   java.lang.Thread.State: WAITING (parking)        at sun.misc.Unsafe.park(Native Method)        - parking to wait for  &lt;0x0000000797b00190&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)        at org.apache.zookeeper.server.PrepRequestProcessor.run(PrepRequestProcessor.java:122)   Locked ownable synchronizers:        - NoneSyncThread:0 #13 prio=5 os_prio=31 tid=0x00007febe98c0000 nid=0x4303 waiting on condition [0x000070000a45e000]   java.lang.Thread.State: WAITING (parking)        at sun.misc.Unsafe.park(Native Method)        - parking to wait for  &lt;0x0000000797b10758&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)        at org.apache.zookeeper.server.SyncRequestProcessor.run(SyncRequestProcessor.java:127)   Locked ownable synchronizers:        - NoneSessionTracker #12 prio=5 os_prio=31 tid=0x00007febea15a000 nid=0x4003 in Object.wait() [0x000070000a35b000]   java.lang.Thread.State: TIMED_WAITING (on object monitor)        at java.lang.Object.wait(Native Method)        at org.apache.zookeeper.server.SessionTrackerImpl.run(SessionTrackerImpl.java:146)        - locked &lt;0x0000000797b08700&gt; (a org.apache.zookeeper.server.SessionTrackerImpl)   Locked ownable synchronizers:        - None\n6. jinfo\n实时查看和调整虚拟机运行参数，jps -v只能查看到显式指定的参数，jinfo则能查看未被显式指定的参数的值\n看一个例子\n12345 查看zookeeper的启动参数$ jinfo -flags 469Non-default VM flags: -XX:CICompilerCount=3 -XX:InitialHeapSize=134217728 -XX:+ManagementServer -XX:MaxHeapSize=2147483648 -XX:MaxNewSize=715653120 -XX:MinHeapDeltaBytes=524288 -XX:NewSize=44564480 -XX:OldSize=89653248 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseFastUnorderedTimeStamps -XX:+UseParallelGCCommand line:  -Dzookeeper.log.dir=. -Dzookeeper.root.logger=INFO,CONSOLE -Dapple.awt.UIElement=true -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.local.only=false\n查阅资料\njvm系列(四)jvm调优命令（jps jstat jmap jhat jstack jinfo）\n二 jvm调优可视化集成工具\n1. jconsole\nJconsole是JDK自带的监控工具，在JDKbin目录下可以找到。它用于连接正在运行的本地或者远程的JVM，对运行在java应用程序的资源消耗和性能进行监控，并画出大量的图表，提供强大的可视化界面。而且本身占用的服务器内存很小，甚至可以说几乎不消耗\n\n\n打开的两种方式\n命令行直接输入jconsole\nGUI shell (jdkbin下打开)中运行\njava程序停止后，jconsole重连需要从外部重连，因为pid已经变化\n基本是上述6个命令的集合，能根据实时图表方式查看内存,线程,类,MBean,VM虚拟机概要，比visualVM功能稍微弱一些，因为无法查看回收次数等详细信息\n可追踪内存溢出 (配合jstat)，线程死锁 (jstack也可以)\njconsole本身占用资源少\n\n\n12 命令行启动$ jconsole\n\n远程监控tomcat\n\n远程连接需要配置远程的java进程启动jvm参数，主要是rmi的远程调用消息通信\n请参考: JConsole远程连接配置\n2. visualVM\njconsole是1.5提供的，visualVM是1.6提供的，jconsole相当于是visualVM的子集\n12 命令行即可启动$ jvisualvm\n三 jvm调优参数\n待续\n","tags":[],"path":"2019/04/22/JVM调优详解/","external_link":""},{"title":"LinkedTransferQueue 与 SynchronousQueue","date":"2019-04-21T16:32:54.338Z","content":"两者是比较特殊的阻塞队列\nLinkedTransferQueue\n\n\n单向链表结构的无界阻塞队列 (CAS无锁)\n遵循happen-before, 即插入先行于访问或删除\n采用预占模式\n比如消费者线程take时发现队列为空, 则队列生成一个item为null, waiter为消费者线程本身节点并入队, 然后阻塞take操作;\n直到生产者线程put入队时, 发现队列有一个item为null的节点, 则不入队, 直接填充数据到该节点, 并唤醒消费者线程的take操作\n这和传递东西很类似, 也和通道pipeline很像, 这种模式叫做**‘匹配’**\nLinkedTransferQueue是无锁设计, 是SynchronousQueue和LinkedBlockingQueue的超集, 结合了两者的优点, 并摒弃了其缺陷\nSynchronousQueue: 无法存放数据, 严格的一应一答\nLinkedBlockingQueue: 使用了Lock锁, 并发效率低\nLinkedTransferQueue: 使用CAS和LockSupport, 且可存放数据和请求, 不会长时间阻塞;\n同时它适合生产者和消费者速度不匹配的情况, 允许生产者适当调整生产速度;\n普通队列的生产者和消费者是分离的, 举一个例子:\n通常情况下, 厨师只管炒菜, 服务员只管端菜, 厨师是不关心也不知道服务员端没有端走; 现在的情形是厨师可能会将菜直接递到服务员手里, 即知道服务员有没有端菜, 既然知道了厨师就可以调整炒菜的速度, 是快点还是慢点 \n\n\n一. 数据结构与算法特性\n\n\n算法特性\n\n它是单链表, 但和典型的单链表不同\n\n\n双重队列\n多了一个isData布尔属性, 说明队列可以存储数据item和消费者本身(null表示); 它在意义上叫做双重队列, 但本质是单链表\n节点item不为null,表示生产者节点;\n节点item为null(waiter为消费者线程), 表示消费者节点\n通过isData属性来标识\n松弛度\n如下图2, 节点匹配后(puttake匹配),节点会置为自引用(断开外界引用,GC会进行清理), 但是它不会立刻更新headtail, 而是当一个最近的未匹配节点距离headtail超过阈值(默认2)时才会分别更新headtail;  这会导致队列里「消费者」和「生产者」都会出现\n这样设计的原因？\n正常情况是匹配删除节点后立刻更新headtail, 但一旦队列为空, 消费者take线程会进行自旋尝试等待put来唤醒自己 (虽然不是一直自旋), 这会消耗CPU时间片\n设计「延迟」更新headtail能缓解自旋带来的性能损耗, 但「延迟」有一个度, 匹配是需要遍历链表的, 过多的「冗余(已匹配的节点)」会增大遍历性能消耗\n\n\n图1: 流程示意图\n如下图, 按理某一时刻队列永远只会有「生产者(put)」或者「消费者(take)」, 但是由于松弛特性,「匹配」后不会立刻更新headtail, 导致一些已匹配使用了的节点不会立刻移除;\n所以某一时刻, 队列里是生产者和消费者都可能出现的;\n注意: take消费者线程的阻塞使用了CAS自旋 (也不是一直自旋), 所以会浪费CPU时间片\n下图逻辑不对, 并不只是去匹配队头\n\n图2: 某一时刻队列状态图\n上面已解释过, 松弛特性(默认阈值2)导致生产者和消费者都会出现在队列里;\n\n\n\n未匹配节点\n可能是生产者(item不为null), 可能是消费者(item为null, waiter为消费线程本身)\n已匹配节点\n可能是生产者节点已被消费者拿走(被消费者赋值为节点自身), 也可能是消费者被生产者填充了数据(item不为null)\n\n\n\n上图有些不准确, 队头部分应是连续的已匹配节点, 队尾部分应是连续的未匹配节点\n正常的做法, 实时更新headtail, 但这样做会增加CAS竞争开销; 所以折中办法是延迟更新headtail;\nslack (head位置和第一个未匹配的结点的最大距离，尾结点类似)\n这是经验问题, 大多平台最佳值是1～3, jdk默认值是2\n所以正常情况补充为如下图:\n\n1234          head                 tail           |                    |           v                    vM   M  -&gt;  M  -&gt;  M  -&gt;  U  -&gt;  U  -&gt; U  -&gt;  U\n二. 源码分析\n\n基本属性\n\n1234567891011121314151617181920212223 MP表示是否是多核处理器boolean MP = Runtime.getRuntime().availableProcessors() &gt; 1; 当一个节点目前是队列的第一个等待者(waiter), 在多核处理器上自旋的次数2^7(随机穿插调用thread.yield)int FRONT_SPINS   = 1 &lt;&lt; 7; 当一个节点先于另一个明显自旋的结点阻塞时自旋的次数 前继节点正在处理, 当前节点阻塞前的自旋次数int CHAINED_SPINS = FRONT_SPINS &gt;&gt;&gt; 1; sweepVotes(清除已匹配节点)的阀值static final int SWEEP_THRESHOLD = 32; 队列头节点，第一次入列之前为空Node head; 队列尾节点，第一次添加节点之前为空Node tail; 累计到一定次数再清除已匹配nodeint sweepVotes;** * xfer执行类型 *int NOW   = 0;  for untimed poll, tryTransferint ASYNC = 1;  for offer, put, addint SYNC  = 2;  for transfer, takeint TIMED = 3;  for timed poll, tryTransfer\n\n链表节点Node数据结构\n\n1234567891011121314151617181920212223boolean isData;   put型(true), take型(false)Object item;      put型(不为null), take型(null)Node next;        后继节点Thread waiter;    特指消费者线程(入队阻塞等待匹配) CAS更新当前结点next字段boolean casNext(Node cmp, Node val) CAS更新当前结点的item字段boolean casItem(Object cmp, Object val) CAS设置当前结点的next字段为自身(自引用, 即删除)void forgetNext() CAS设置item字段为node自身，waiter为nullvoid forgetContents() 是否是匹配了的结点boolean isMatched() 是否是未匹配的消费者take型节点boolean isUnmatchedRequest() 当该节点是未匹配节点却与当前的结点类型不符的时候，返回true。 意思就是当前都是请求节点，数据节点应该立刻被消耗，未匹配的结点应该是同一种节点才允许附加入队boolean cannotPrecede(boolean haveData) 数据节点尝试匹配boolean tryMatchData()\n\nxfer基本流程\n\n根据如下队列快照, 来讲述一下流程\n1234567891011** * 意味着M1匹配成功, 准备将head指针指向M1后继节点U1 * 注意M1还保留着next引用, 后面会根据阈值进行清扫 * 最后会将原始head节点断开next引用 * ************************************************ *           head                   tail *            |                      | *            v                      v * M   M  -&gt;  M  -&gt;  M1  -&gt;  U1  -&gt;  U  -&gt; U  -&gt;  U * ************************************************ *\n\n\n从head开始向后匹配, 找到一个节点模式跟本次操作的模式不同的未匹配的节点（生产或消费）进行匹配; 没找到则下一个节点; 遍历完都没匹配到, 则准备尝试入队尾\n注意:\nNode n = p.next; p = (p != n) ? n : (h = head);\np==n表明是已匹配且删除的节点(自引用), 说明有其他线程赶在前面匹配成功且重置了head, 需要重新从头部遍历, p!=n则继续遍历\n找到未匹配节点, 如果发现节点和当前节点同类型, 说明整个队列未匹配的节点都是put或者take(如上图); 跳出循环准备尝试入队尾\n找到为匹配节点, 且不同类型, 说明允许匹配, 则开始匹配操作;\n开始匹配, CAS更新item, 失败说明被其他线程抢先, 继续循环直到CAS更新item成功(匹配成功);\n对照下面代码注解\n尝试入队tryAppend\n\n\n123456789101112131415161718192021222324** * 1.若CAS更新item成功, 表示匹配成功 * 2.开始判断是否更新head, (q=p &amp;&amp; q!=h)表明p肯定是head之后的节点(其实就是head-&gt;next), *   然后n=q.next, 表明跳过了2个节点, slack=2满足条件则开始CAS更新head指针 *   如果head的next节点未被匹配，跳出循环，不更新head，也就是松弛度&lt;2 * 3.最后唤醒匹配节点其中的消费者节点线程(waiter), 返回节点的item值 *if (p.casItem(item, e)) &#123;    for (Node q = p; q != h;) &#123;        Node n = q.next;   update by 2 unless singleton        if (head == h &amp;&amp; casHead(h, n == null ? q : n)) &#123;             将原始head的next指向自己, 即自引用(删除)            h.forgetNext();            break;        &#125;                  advance and retry         如果head的next节点未被匹配，跳出循环，不更新head，也就是松弛度&lt;2        if ((h = head) == null ||                (q = h.next) == null || !q.isMatched())            break;         unless slack &lt; 2    &#125;     最后唤醒匹配节点其中的消费者节点线程(waiter), 返回节点的item值    LockSupport.unpark(p.waiter);    return OwnLinkedTransferQueue.&lt;E&gt;cast(item);&#125;\n尝试入队\n123456789101112131415161718192021222324252627282930313233343536373839private Node tryAppend(Node s, boolean haveData) &#123;    for (Node t = tail, p = t;;) &#123;         move p to last node and append        Node n, u;                         temps for reads of next &amp; tail         如果队列为空, 则将节点CAS设置为队头, 它没有前继节点则返回自己        if (p == null &amp;&amp; (p = head) == null) &#123;            if (casHead(null, s))                return s;                  initialize        &#125;         还有未匹配的节点, 如果入队尾则会违反算法逻辑, 因为根本没必要入队, 此时返回true表明「入队不能发生在还未匹配完之前」         注意: 其实这种情况发生在put和take多线程竞争, 比如一个put节点遍历之后没有找到还未匹配的take节点,开始准备入队尾,               再次判断的时候, 发现期间发生了很多take操作(多于put操作); 此时则不允许入队, 需要重新循环整个队列         简单点说: 有相反类型的节点先附加入队(称之为失速)        else if (p.cannotPrecede(haveData))            return null;                   lost race vs opposite mode         如果发现队尾还有后继节点, 说明期间有其他操作入队(可能同类型,也可能不同类型)         说明期间其他线程在维护tail尾节点, t变量为过时的tail        else if ((n = p.next) != null) &#123;   not last; keep traversing            p = p != t &amp;&amp; t != (u = tail) ? (t = u) : (p != n) ? n : null;       restart if off list            p = (p != t &amp;&amp; t != (u = tail)) ? (t = u) : ((p != n) ? n : null);     更新为最新的tail, 重新开始              ---------------------------   -------   ---------------------               p = boolean ? t : (boolean ? n : null)        &#125;         CAS入队尾节点失败, 说明有其他线程在入队        else if (!p.casNext(null, s))            p = p.next;                    re-read on CAS failure        else &#123;            if (p != t) &#123;                  update if slack now &gt;= 2                while ((tail != t || !casTail(t, s)) &amp;&amp;                        (t = tail)   != null &amp;&amp;                        (s = t.next) != null &amp;&amp;  advance and retry                        (s = s.next) != null &amp;&amp; s != t);            &#125;            return p;        &#125;    &#125;&#125;\n\nawaitMatch(后续补充)\n\n自旋让步阻塞,直到给定节点s匹配到或放弃匹配\n当前操作为同步操作时，会调用awaitMatch方法阻塞等待匹配，成功返回匹配节点 item，失败返回给定参数e（s.item）。在等待期间如果线程被中断或等待超时，则取消匹配，并调用unsplice方法解除节点s和其前继节点的链接\n\nunsplice(后续补充)\n\n解除给定已经被删除取消节点和前继节点的链接（可能延迟解除）\n首先把给定节点s的next引用指向自身，如果s的前继节点pred还是指向s（pred.next == s），尝试解除s的链接，把pred的 next 引用指向s的 next 节点。如果s不能被解除（由于它是尾节点或者pred可能被解除链接，并且pred和s都不是head节点或已经出列），则添加到sweepVotes，sweepVotes累计到阀值SWEEP_THRESHOLD之后就调用sweep()对队列进行一次“大扫除”，清除队列中所有的无效节点。sweep()\n\nsweep(后续补充)\n\n解除(通常是取消)从头部遍历时遇到的已经被匹配的节点的链接\n参考:\nJUC源码分析-集合篇（六）：LinkedTransferQueue\n并发编程-LinkedTransferQueue\nSynchronousQueue（后续补充）\n\n\n\n\n\n\n","tags":[],"path":"2019/04/22/LinkedTransferQueue 与 SynchronousQueue/","external_link":""},{"title":"SPI(service provider interface 服务发现机制)","date":"2019-04-21T16:34:21.450Z","content":"SPI全称为(Service Provider Interface) ，是JDK内置的一种服务提供发现机制；主要被框架的开发人员使用，比如java.sql.Driver接口，数据库厂商实现此接口即可，当然要想让系统知道具体实现类的存在，还需要使用固定的存放规则，需要在classpath下的META-INFservices目录里创建一个以服务接口命名的文件，这个文件里的内容就是这个接口的具体的实现类；日志门面框架和DriverManager数据库驱动都是基于此。\n\nspi是一种动态发现并替换的机制, 比如运行时动态添加接口实现,主要针对厂商或者插件;\n典型的比如数据库驱动Driver, slf4j日志框架(外观模式)\n基于接口编程 + 策略模式 + 配置文件\n\n1.定义一组接口\ncom.doyo.learn.spi.IHello\n\n\n2.接口的多个实现\ncom.doyo.learn.spi.impl.HelloV1Impl\ncom.doyo.learn.spi.impl.HelloV2Impl\n\n\n3.在 srcmainresources 下建立 META-INFservices 目录,新增一个以接口命名的文件\nMETA-INFservicescom.doyo.learn.spi.IHello\n文件的内容是实现类的全名,可以写上多个实现, 比如:\ncom.doyo.learn.spi.impl.HelloV1Impl com.doyo.learn.spi.impl.HelloV2Impl\n\n\n4.使用ServiceLoader来加载指定配置文件中的实现\n\n\n例如有一个开源搜索模块基于接口编程规范,可能基于文件系统,可能基于数据库; 接口如下:\n12345package org.xyz.spi;import java.util.List;public interface ISearch &#123;   public List serch(String keyword);&#125;\nA公司提供文件搜索实现com.A.spi.impl.FileSearch\nA公司发布jar时,文件META-INFservicesorg.xyz.spi.ISearch中填写如下内容:com.A.spi.impl.FileSearch\nB公司提供数据库搜索实现com.B.spi.impl.DatabaseSearch\nB公司发布jar时,文件META-INFservicesorg.xyz.spi.ISearch中填写如下内容:com.B.spi.impl.DatabaseSearch\n最后使用者会通过开源搜索jar包(门面模式)的工厂类来使用\n123456789101112131415package org.xyz.factory;import java.util.Iterator;import java.util.ServiceLoader;import org.xyz.spi.ISearch;public class SearchFactory &#123;    public static Search newSearch() &#123;        Search search = null;        ServiceLoader&lt;Search&gt; serviceLoader = ServiceLoader.load(Search.class);        Iterator&lt;Search&gt; searchs = serviceLoader.iterator();        if (searchs.hasNext()) &#123;            search = searchs.next();        &#125;        return search;    &#125;&#125;\n总结: 这是一种接口与实现分离解耦,提升可扩展性,轻松实现功能模块的可插拔;开发者无须手动注入实现,只需引入具体实现jar包 + spi接口jar包\n参考:\njava中的SPI机制\njdbc的设计\nspi服务加载的手工实现\nServiceLoader\n从上面看出最终会使用ServiceLoader来实现类的载入\n1231.读取`META-INFservices&#123;接口全路径名文件&#125;`配置,获取实现类的全名称字符串2.java反射机制(或者采用Class.forName或者ClassLoader)构造服务实现类的实例3.官方实现 使用了迭代器, ClassLoader, 以及System.setSecurityManager(new SecurityManager());开启权限检查\njava简单实现Serviceloader\n1234567891011121314151617181920212223242526272829303132333435363738394041public class SimpleServiceLoader &#123;    private static final String PREFIX = META-INFservices;    public static &lt;T&gt; List&lt;T&gt; load(Class&lt;T&gt; cls) &#123;        List&lt;String&gt; implClasses = readServiceFile(cls);        List&lt;T&gt; implList = new ArrayList&lt;T&gt;();        for (String implClass : implClasses) &#123;            Class&lt;T&gt; c;            try &#123;                c = (Class&lt;T&gt;) Class.forName(implClass);                implList.add(c.newInstance());            &#125; catch (Exception e) &#123;                return new ArrayList&lt;&gt;();            &#125;        &#125;        return implList;    &#125;    private static List&lt;String&gt; readServiceFile(Class&lt;?&gt; cls) &#123;        String infName = cls.getCanonicalName();                String fileName = cls.getResource(PREFIX + infName).getPath();        try &#123;            BufferedReader br = new BufferedReader(new FileReader(new File(fileName)));            String line;            List&lt;String&gt; implClasses = new ArrayList&lt;&gt;();            while ((line = br.readLine()) != null) &#123;                implClasses.add(line);            &#125;            return implClasses;        &#125; catch (FileNotFoundException e) &#123;            System.out.println(File not found:  + fileName);            return new ArrayList&lt;&gt;();        &#125; catch (IOException ioe) &#123;            System.out.println(Read file failed:  + fileName);            return new ArrayList&lt;&gt;();        &#125;    &#125;&#125;\nSlf4j日志框架\n\n使用了门面模式,注意只有slf4j是无法打印日志的(最优选择是Logback＋SLF4J (Logback是Log4j的改进版))\nSLF4J(Log4jLogbackCommons-logging(Apache)logging(JDK))\n\n\njava日志框架历史\n\n1234567891011121314151617181.Log4j:  1996年早期, Log4j是java社区的日志标准(后成为apache基金会项目一员)2.JUL:  Java Util Logging,由Sun在2002年推出java标准库(Apache曾建议过将Log4j纳入java标准库被拒)3.common-logging:  原因是Log4j和JUL比较混乱且接口不统一,所以Apache推出的统一日志接口(内部有一个Simple Log简单实现);以便统一Log4j和JUL4.Slf4j: Ceki Gülcü离开Apache后创建的Slf4j日志门面接口,其实现为logback5.阵营: common-logging阵营(Apache), Slf4j阵营(Ceki Gülcü)6.Log4j2: Apache眼看Slf4j快要将其超越, 随即201207重写了Log4j实现,且拥有Slf4j实现Logback的全部特性,所以两个版本无法兼容使用方式:  Slf4j + Logback  Commons Logging + Log4j实现机制:    Commons Logging通过动态查找机制,使用自己的ClassLoader寻找和载入本地实现;主要通过扫描`META-INFservicesorg.apache.commons.logging.LogFactory`配置文件,来查找`org.apache.commons.logging.impl.LogFactoryImpl.java`实现类    Slf4j是在编译期间,静态绑定本地Log实现库, 通过查找类路径下`org.slf4j.impl.StaticLoggerBinder`,然后在`StaticLoggerBinder`中进行绑定\n下面将以Slf4j + Logback来说明日志如何加载\n\n\n第一句话开始\nLogger logger = LoggerFactory.getLogger(Object.class);\nSLF4J只有接口,没有实现,所以各大厂商通过META-INFservicesorg.apache.commons.logging.LogFactory配置文件\n\n\n进入内部\n\n\n123456789101112public static Logger getLogger(Class&lt;?&gt; clazz) &#123;    Logger logger = getLogger(clazz.getName());    if (DETECT_LOGGER_NAME_MISMATCH) &#123;        Class&lt;?&gt; autoComputedCallingClass = Util.getCallingClass();        if (autoComputedCallingClass != null &amp;&amp; nonMatchingClasses(clazz, autoComputedCallingClass)) &#123;            Util.report(String.format(Detected logger name mismatch. Given name: %s; computed name: %s., logger.getName(),                            autoComputedCallingClass.getName()));            Util.report(See  + LOGGER_NAME_MISMATCH_URL +  for an explanation);        &#125;    &#125;    return logger;&#125;\n\n到bind方法\n\n123456789101112131415161718192021222324252627282930313233343536373839404142private final static void bind() &#123;    try &#123;        Set&lt;URL&gt; staticLoggerBinderPathSet = null;         skip check under android, see also         http:jira.qos.chbrowseSLF4J-328        if (!isAndroid()) &#123;            staticLoggerBinderPathSet = findPossibleStaticLoggerBinderPathSet();            reportMultipleBindingAmbiguity(staticLoggerBinderPathSet);        &#125;         the next line does the binding        StaticLoggerBinder.getSingleton();        INITIALIZATION_STATE = SUCCESSFUL_INITIALIZATION;        reportActualBinding(staticLoggerBinderPathSet);        fixSubstituteLoggers();        replayEvents();         release all resources in SUBST_FACTORY        SUBST_FACTORY.clear();    &#125; catch (NoClassDefFoundError ncde) &#123;        String msg = ncde.getMessage();        if (messageContainsOrgSlf4jImplStaticLoggerBinder(msg)) &#123;            INITIALIZATION_STATE = NOP_FALLBACK_INITIALIZATION;            Util.report(Failed to load class org.slf4j.impl.StaticLoggerBinder.);            Util.report(Defaulting to no-operation (NOP) logger implementation);            Util.report(See  + NO_STATICLOGGERBINDER_URL +  for further details.);        &#125; else &#123;            failedBinding(ncde);            throw ncde;        &#125;    &#125; catch (java.lang.NoSuchMethodError nsme) &#123;        String msg = nsme.getMessage();        if (msg != null &amp;&amp; msg.contains(org.slf4j.impl.StaticLoggerBinder.getSingleton())) &#123;            INITIALIZATION_STATE = FAILED_INITIALIZATION;            Util.report(slf4j-api 1.6.x (or later) is incompatible with this binding.);            Util.report(Your binding is version 1.5.5 or earlier.);            Util.report(Upgrade your binding to version 1.6.x.);        &#125;        throw nsme;    &#125; catch (Exception e) &#123;        failedBinding(e);        throw new IllegalStateException(Unexpected initialization failure, e);    &#125;&#125;\n\n第七行的findPossibleStaticLoggerBinderPathSet\n\n12345678910111213141516171819202122static Set&lt;URL&gt; findPossibleStaticLoggerBinderPathSet() &#123;     use Set instead of list in order to deal with bug #138     LinkedHashSet appropriate here because it preserves insertion order     during iteration    Set&lt;URL&gt; staticLoggerBinderPathSet = new LinkedHashSet&lt;URL&gt;();    try &#123;        ClassLoader loggerFactoryClassLoader = LoggerFactory.class.getClassLoader();        Enumeration&lt;URL&gt; paths;        if (loggerFactoryClassLoader == null) &#123;            paths = ClassLoader.getSystemResources(STATIC_LOGGER_BINDER_PATH);        &#125; else &#123;            paths = loggerFactoryClassLoader.getResources(STATIC_LOGGER_BINDER_PATH);        &#125;        while (paths.hasMoreElements()) &#123;            URL path = paths.nextElement();            staticLoggerBinderPathSet.add(path);        &#125;    &#125; catch (IOException ioe) &#123;        Util.report(Error getting resources from path, ioe);    &#125;    return staticLoggerBinderPathSet;&#125;\n\n第十二行代码\n\n其中STATIC_LOGGER_BINDER_PATH为orgslf4jimplStaticLoggerBinder.class\n注意:\n所有slf4j的实现，在提供的jar包路径下，一定是有&quot;orgslf4jimplStaticLoggerBinder.class&quot;存在的, 由于可能出现引用多个日志框架,所以reportMultipleBindingAmbiguity(staticLoggerBinderPathSet);方法会打印警告\n1paths = loggerFactoryClassLoader.getResources(STATIC_LOGGER_BINDER_PATH);\n参考: https:www.cnblogs.comxrq730p8619156.html\nJDBC的SPI设计\n\nDriver接口:\nSun公司提供了JDBC驱动的统一接口规范java.sql.Driver,各大厂商(oraclemysqldb2sqlserver)驱动只要实现其接口逻辑\nDriverManager管理类:\n主要是注册管理Driver实现类\n\n流程\n1.启动后,DriverManager有一个静态代码块,对Driver进行加载到内存\n1234static &#123;    loadInitialDrivers();    println(JDBC DriverManager initialized);&#125;\n2.loadInitialDrivers方法首先会尝试从系统变量中加载,若没有则通过SPI加载\n123456789101112131415161718192021222324252627282930313233343536373839404142 1.尝试获取JDBC驱动的系统变量try &#123;    drivers = AccessController.doPrivileged(new PrivilegedAction&lt;String&gt;() &#123;        public String run() &#123;            return System.getProperty(jdbc.drivers);        &#125;    &#125;);&#125; catch (Exception ex) &#123;    drivers = null;&#125; 如果系统变量存在则Class.forName进行加载,注意第二个参数为true,即加载时需要运行静态代码块;后面可以看到Driver实现类的静态代码块在进行注册到DriverManagerif (drivers == null || drivers.equals()) &#123;    return;&#125;String[] driversList = drivers.split(:);println(number of Drivers: + driversList.length);for (String aDriver : driversList) &#123;    try &#123;        println(DriverManager.Initialize: loading  + aDriver);        Class.forName(aDriver, true,                ClassLoader.getSystemClassLoader());    &#125; catch (Exception ex) &#123;        println(DriverManager.Initialize: load failed:  + ex);    &#125;&#125; 2.尝试SPI加载AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123;    public Void run() &#123;        ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class);        Iterator&lt;Driver&gt; driversIterator = loadedDrivers.iterator();        try&#123;            while(driversIterator.hasNext()) &#123;                 迭代遍历的时候,加载并初始化Driver实现类                driversIterator.next();            &#125;        &#125; catch(Throwable t) &#123;         Do nothing        &#125;        return null;    &#125;&#125;);\n3.Class.forName进行加载\nMySql驱动的Driver实现类会有一个静态代码块,在向DriverManager进行注册DriverInfo,info对象内部包含Driver实现类的实例\n123456789 com.mysql.cj.jdbc.Driver静态代码块static &#123;    try &#123;         注意new了一个Driver实例并注册到DriverManager        java.sql.DriverManager.registerDriver(new Driver());    &#125; catch (SQLException E) &#123;        throw new RuntimeException(Cant register driver!);    &#125;&#125;\n3.SPI进行加载\n截取上面的代码片段, 重点是ServiceLoader.load(Driver.class)\n1234567891011121314AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123;    public Void run() &#123;        ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class);        Iterator&lt;Driver&gt; driversIterator = loadedDrivers.iterator();        try&#123;            while(driversIterator.hasNext()) &#123;                driversIterator.next();            &#125;        &#125; catch(Throwable t) &#123;         Do nothing        &#125;        return null;    &#125;&#125;);\n再来看ServieLoader内部的迭代器如何初始化Driver并注册\n12345678910111213141516171819202122232425262728293031private S nextService() &#123;    if (!hasNextService())        throw new NoSuchElementException();    String cn = nextName;上一步找到的服务实现者全限定名    nextName = null;    Class&lt;?&gt; c = null;    try &#123;    加载字节码返回class对象.但并不去初始化（换句话就是说不去执行这个类中的static块与static变量初始化）            c = Class.forName(cn, false, loader);    &#125; catch (ClassNotFoundException x) &#123;        fail(service,             Provider  + cn +  not found);    &#125;    if (!service.isAssignableFrom(c)) &#123;        fail(service,             Provider  + cn  +  not a subtype);    &#125;    try &#123;        初始化这个实现类.将会通过static块的方式触发实现类注册到DriverManager(其中组合了一个CopyOnWriteArrayList的registeredDrivers成员变量)中        S p = service.cast(c.newInstance());                providers.put(cn, p);本地缓存 （全限定名，实现类对象）        return p;    &#125; catch (Throwable x) &#123;        fail(service,             Provider  + cn +  could not be instantiated,             x);    &#125;    throw new Error();           This cannot happen&#125;\n4.Class.forName(cn, false, loader)中的cn\n第22行实际在读取META-INFservicesjava.sql.Driver里的内容\n内容为: com.mysql.cj.jdbc.Driver\n1234567891011121314151617181920212223242526private boolean hasNextService() &#123;    if (nextName != null) return true;    if (configs == null) &#123;        try &#123;             SPI资源路径            String fullName = PREFIX + service.getName();            if (loader == null)                configs = ClassLoader.getSystemResources(fullName);            else                configs = loader.getResources(fullName);        &#125; catch (IOException x) &#123;            fail(service, Error locating configuration files, x);        &#125;    &#125;     第一次时,会去读取META-INF中的SPI资源里的配置信息    while ((pending == null) || !pending.hasNext()) &#123;        if (!configs.hasMoreElements()) &#123;            return false;        &#125;         读取文件内容        pending = parse(service, configs.nextElement());    &#125;    nextName = pending.next();    return true;&#125;","tags":[],"path":"2019/04/22/SPI(service provider interface 服务发现机制)/","external_link":""},{"title":"concurrent并发包讲解(三)","date":"2019-04-21T16:23:39.203Z","content":"AQS与Synchronized优化\nsynchronized偏向锁,轻量级锁,重量级锁\nsynchronized在之前一直是重量级悲观锁的代名词, 这种情况在java1.6时得到改善, 性能上已不输于Lock\n\n\n加锁代码块使用monitorenter, monitorexit;\n加锁:\n1.1 尝试获取monitor, 如果为0则说明锁可用, 加1\n1.2 同一线程再次尝试获取该锁, 加1, 表明可重入\n1.3 不同线程尝试获取该锁, 则阻塞, 等待monitor进入数为0\n解锁:\n1.1 monitor的进入数减1，如果减1后进入数为0，那线程退出monitor\n锁优化5种方式\n2.1 减少锁持有时间: 即减小锁范围\n2.2 减小锁粒度: 比如ConcurrentHashMap的Segment\n2.3 锁分离: 比如ReadWriteLock读写锁; LinkedBlockingQueue(使用了入队锁和出队锁)\n2.4 锁粗化: 在多个不连续同步代码块多次加解锁会很低效, 可以扩大为只加解锁一次\n2.5 锁消除: 在即时编译器时，如果发现不可能被共享的对象，则可以消除这些对象的锁操作; 比如StringBuffer是线程安全的, 如果变量sb本就是局部变量并非共享, 则JVM根据逃逸分析sb变量是否会超过作用域变得全局共有共享(其他线程可访问),\n\n\n\n对象存储结构, markword\n\n123对象头: markword klass length(如果是数组的话)数据区对齐填充\n如下图, 对象头\n哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等\n\n轻量级加锁:\n条件1: 是否偏向锁为&quot;0&quot;(无锁状态)\n条件2: 锁标志位为“01”状态\n步骤1: 开始在当前栈帧中创建Lock Record空间, 用于保存拷贝的Mark Word - 官方叫Displaced Mark Word\n步骤2: 拷贝对象头中的Mark Word复制到锁记录中; Mark Word -&gt; Lock Record, 开始CAS更新对象的Mark Record为指向Lock Record的指针; 成功则将锁标志位置为00\n失败说明CAS有竞争, 则直接升级为系统Mutex互斥量\n偏向锁加锁:\n步骤1: 对象头处于无锁状态, 将锁标志位置为01(偏向模式)\n步骤2: CAS操作将获得锁的线程ID记录到Mark Word中的偏向线程ID\n步骤3: 将是否偏向锁标记置为1\n以后每次进入同步代码块时都会检查线程ID是否和偏向线程ID是否一致, 一致则表明无竞争, 直接执行无须加锁; 否则转为轻量级锁流程\n\n\n\n\n偏向锁: 某些情况下只有一个线程在获取锁, 所以synchronized代码块所在临界区不存在竞争, 则默认进入偏向锁, 可以看作无锁\n轻量级锁: 一旦有其他线程加入竞争, 则立马不可逆的升级为轻量级锁, 即CAS自旋锁; 自适应自选锁即JVM在运行时搜集统计信息, 动态调整自选锁的自选次数上界.\n重量级锁: 一旦CAS自旋操作还是未成功, 则升级为系统级mutex互斥锁; 因为自旋会消耗cpu时间片\n\n\n锁升级的逻辑图:\n\nMarkWord是如何操作的, 可以参考如下文章:\nsynchronized优化\nAQS同步器\n是一个同步队列\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418public abstract class AbstractOwnAQS implements java.io.Serializable &#123;    protected AbstractOwnAQS() &#123; &#125;     维持一个双向队列    static final class Node &#123;         用于指示节点正在共享模式下等待的标记        static final Node SHARED = new Node();         用于指示节点正在独占模式下等待的标记        static final Node EXCLUSIVE = null;         表示当前节点从同步队列中取消        static final int CANCELLED =  1;         表示当前节点的的后继节点将要或者已经被阻塞, 在当前节点释放的时候需要unpark后继节点        static final int SIGNAL    = -1;         表示当前节点在等待condition, 即在condition队列中进行等待        static final int CONDITION = -2;         表示releaseShared需要被传播给后续节点（仅在共享模式下使用）        static final int PROPAGATE = -3;         节点状态(状态如上所示)        volatile int waitStatus;         前继节点        volatile Node prev;         后继节点        volatile Node next;         存储condition队列中的后继节点        Node nextWaiter;         当前线程        volatile Thread thread;         TODO        final boolean isShared() &#123;            return nextWaiter == SHARED;        &#125;         返回前继节点(注意处理为空, 因为? TODO )        final Node predecessor() throws NullPointerException &#123;            Node p = prev;            if (p == null)                throw new NullPointerException();            else                return p;        &#125;        Node() &#123;        &#125;         用于构造添加到等待队列的线程节点        Node(Thread thread, Node mode) &#123;            this.nextWaiter = mode;            this.thread = thread;        &#125;         TODO Used by Condition        Node(Thread thread, int waitStatus) &#123;            this.waitStatus = waitStatus;            this.thread = thread;        &#125;    &#125;    加锁的计数器, state=0表示无锁, 大于0表示有锁, 重入一次加1, 退出一次减1    private volatile int state;     获得独享锁的线程(如果获得锁成功, 即state变量CAS设置1成功, 则设置此变量为当前线程)    private transient Thread exclusiveOwnerThread;     获得独享锁线程的getter,setter    protected final void setExclusiveOwnerThread(Thread thread) &#123;        exclusiveOwnerThread = thread;    &#125;    protected final Thread getExclusiveOwnerThread() &#123;        return exclusiveOwnerThread;    &#125;     头结点不存储Thread, 仅保存next结点的引用    private transient volatile Node head;     尾节点    private transient volatile Node tail;     TODO    static final long spinForTimeoutThreshold = 1000L;    protected final int getState() &#123;        return state;    &#125;    protected final void setState(int newState) &#123;        state = newState;    &#125;     通用CAS自旋入队方法    private Node enq(final Node node) &#123;        for (;;) &#123;            Node t = tail;             如果尾节点是空, 表明队列还未创建, 则初始化队列头节点,同时尾节点也指向head: tail=head            if (t == null) &#123;                if (compareAndSetHead(new Node()))                    tail = head;            &#125; else &#123;                node.prev = t;                if (compareAndSetTail(t, node)) &#123;                    t.next = node;                    return t;                &#125;            &#125;        &#125;    &#125;     加入等待队列(获取锁不成功时)    private Node addWaiter(Node mode) &#123;        Node node = new Node(Thread.currentThread(), mode);         FIXME 这里意思是队列不为空就快速尝试一次入队的意思, 但enq入队也只是多了CAS自旋而已, 实在没看出来效率有很高提升        Node pred = tail;        if (pred != null) &#123;            node.prev = pred;             注意: 此处可能产生A线程tryAcquired失败后调用addWaiter入队前, B线程刚好释放锁, 且C线程刚好又进来, 判断锁空闲且队列也还是空的, 则会产生C线程先于A线程             说明公平锁也不是绝对的公平            if (compareAndSetTail(pred, node)) &#123;                pred.next = node;                return node;            &#125;        &#125;         尝试快速方式直接放到队尾(入队)失败后, 则CAS自旋入队        enq(node);        return node;    &#125;    **     * CAS更新state, 即独享锁的重入次数, 进入一次加1, 退出一次减1     *    protected final boolean compareAndSetState(int expect, int update) &#123;        return unsafe.compareAndSwapInt(this, stateOffset, expect, update);    &#125;     尝试再一次获取锁(子类实现)    protected boolean tryAcquire(int arg) &#123;        throw new UnsupportedOperationException();    &#125;     设置队列头节点(head的线程和前继节点都是空)    private void setHead(Node node) &#123;        head = node;        node.thread = null;        node.prev = null;    &#125;    **     * 1.ReentrantLock第一次设置state不成功,则开始调用acquire,开始第一次重试;     * 2.addWaiter加入等待队列后, 判断队列如果只有一个节点(head不算),说明只有一个线程在等待,开始第二次重试(acquireQueued);     * 3.第二次重试加锁不成功, 则开始判断是否中断线程, 只有前继节点的线程状态为SIGNAL时可以允许当前节点的线程被中断     *     (独占模式获取锁顶层入口)当调用lock.lock()时, CAS设置state不成功则会再调用一次acquire, 意味着再次尝试(有几率可能其他线程正好释放了锁, 也可能是重入)    public final void acquire(int arg) &#123;        if (!tryAcquire(arg) &amp;&amp;                 表明锁真没有获取到, 则开始加入等待队列                acquireQueued(addWaiter(Node.EXCLUSIVE), arg))             补上中断标记的意思            Thread.currentThread().interrupt();    &#125;     进入等待状态休息，直到其他线程彻底释放资源后唤醒自己，自己再拿到资源     1. 结点进入队尾后，检查状态，找到安全休息点     2. 调用park()进入waiting状态，等待unpark()或interrupt()唤醒自己     3. 被唤醒后，看自己是不是有资格能拿到号。如果拿到，head指向当前结点，并返回从入队到拿到号的整个过程中是否被中断过；如果没拿到，继续流程1    final boolean acquireQueued(final Node node, int arg) &#123;        boolean failed = true;        try &#123;            标记等待过程中是否被中断过            boolean interrupted = false;             自旋直到等待队列剩下最后一个线程(其实在等外部的unlockinterrupt)            for (;;) &#123;                 拿到前继节点                final Node p = node.predecessor();                 1. 如果是除了头节点后的第一个节点, 说明已经轮到自己被唤醒(可能是被前继节点唤醒, 也可能是自己被中断)                if (p == head &amp;&amp; tryAcquire(arg)) &#123;                     终于拿到锁了, 则等待队列里的节点已无效, 将自己设置为头节点head                     意思就是拿到资源了, 就可以出队了                     TODO 参考 https:www.jianshu.comp01f2046aab64                    setHead(node);                    p.next = null;  help GC                    表明已成功拿到资源                    failed = false;                    返回等待过程中是否被中断过                    return interrupted;                &#125;                 2.如果自己可以休息了，就进入waiting状态，直到被unpark()                if (shouldParkAfterFailedAcquire(p, node)                         在这里已经被park阻塞住, 等待被unparkinterrupt来唤醒,唤醒后继续执行此循环                        &amp;&amp; parkAndCheckInterrupt())                    如果等待过程中被中断过，哪怕只有那么一次，就将interrupted标记为true                    interrupted = true;            &#125;        &#125; finally &#123;             出现异常或者出现中断，就会执行finally的取消线程的请求操作, 主要是将 node.waitStatus = Node.CANCELLED;不参与竞争了            if (failed)                cancelAcquire(node);        &#125;    &#125;    private final boolean parkAndCheckInterrupt() &#123;         调用park()使线程进入waiting状态        LockSupport.park(this);         如果被唤醒, 查看自己是不是被中断唤醒的, 注意会清除线程中断标记        return Thread.interrupted();    &#125;     出现异常或者出现中断, 取消线程的请求操作    private void cancelAcquire(Node node) &#123;        if (node == null)            return;         不再关联任何线程        node.thread = null;         跳过CANCEL状态的前继节点, 找到一个有效节点(这里在调整prev指针)        Node pred = node.prev;        while (pred.waitStatus &gt; 0)            node.prev = (pred = pred.prev);         此节点可能是一个CANCEL节点        Node predNext = pred.next;         出现异常或者出现中断, 则设置线程为取消状态, 不再参与竞争        node.waitStatus = Node.CANCELLED;         1.自己是tail,则移除自己        if (node == tail &amp;&amp; compareAndSetTail(node, pred)) &#123;             断开pred变量的next引用, 因为pred已成为新的tail, 好让跳过的CANCEL节点进行GC            compareAndSetNext(pred, predNext, null);        &#125; else &#123;             2.不是head后继节点也不是tail, 则将node的前继节点的waitStatus置为SIGNAL, 并使node的前继节点指向node的后继节点             注意这里还有prev指针没有断开, 会不会内存溢出? 其实这里是其他线程调用cancelAcquireshouldParkAfterFailedAcquire时,             会自动调整prev指针, 以保证CANCEL节点的GC            int ws;            if (pred != head &amp;&amp;                    ((ws = pred.waitStatus) == Node.SIGNAL ||                            (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp;                    pred.thread != null) &#123;                Node next = node.next;                if (next != null &amp;&amp; next.waitStatus &lt;= 0)                     node的前继节点指向node的后继节点, 即将node前驱节点的next指针断开, prev指针会由其他线程断开, 即node出队                    compareAndSetNext(pred, predNext, next);            &#125; else &#123;                3. node是head的后继节点, 则直接唤醒node的后继节点(唤醒下一个线程, 注意是从队尾开始遍历的, 因为next指针链已被上面步骤2给破坏)                unparkSuccessor(node);            &#125;             断开node前驱节点的next指针, 但是node自身的next指针还指向node.next, 所以此处将node.next也断开引用, 让其只剩下prev引用链            node.next = node;  help GC        &#125;    &#125;     唤醒下一个节点    private void unparkSuccessor(Node node) &#123;        int ws = node.waitStatus;        置零当前线程所在的结点状态, 允许失败        if (ws &lt; 0)            compareAndSetWaitStatus(node, ws, 0);        找到下一个需要唤醒的结点s        Node s = node.next;        如果为空或已取消        if (s == null || s.waitStatus &gt; 0) &#123;            s = null;             注意这里是从队尾开始唤醒, 因为节点为CANCEL状态时, node.next已经设置指向了自己, next指针链已经被破坏, 现在只剩下prev指针链完整            for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev)                if (t.waitStatus &lt;= 0)                    s = t;        &#125;        if (s != null)             唤醒下一个节点            LockSupport.unpark(s.thread);    &#125;    **     * 此方法主要用于检查状态，看看自己是否真的可以去休息了(调用park进入waiting)     * 出队操作也是在此处真正的执行（破除了prev前置指针, 后置指针在cancelAcquire方法里已破除）     *     * 2次重试加锁都失败后, 判断是否可以阻塞线程     * waitStatus&gt;0表示取消状态; waitStatus&lt;0表示有效状态     * 判断条件:     *    1.允许被阻塞, 前继节点waitStatus=SIGNAL, 表示允许在自身释放锁时通知后继节点进行unpark; 用以证明后继节点允许被park阻塞     *      说白了, 就是处于唤醒状态, 只要前继结点释放锁, 就会通知标识为SIGNAL状态的后继结点的线程执行     *    2.不允许被阻塞, 前继节点waitStatus=CANCELLED, 表示将等待队列里为取消状态的线程进行移除     *    3.不允许被阻塞,     *    private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123;        int ws = pred.waitStatus;         如果已经告诉前驱拿完号后通知自己一下，那就可以安心休息了        if (ws == Node.SIGNAL)            return true;         表示ws = Node.CANCELLED, 如果前驱放弃了, 那就一直往前找，直到找到最近一个正常等待的状态, 并排在它的后边         放弃的结点, 由于被自己“加塞”到它们前边, 它们相当于形成一个无引用链, 稍后就会被保安大叔赶走了(GC回收)！        if (ws &gt; 0) &#123;            do &#123;                 A=B=C =&gt; A=C;B=C;                 这里是在调整prev指针, next指针是cancelAcquire做的, 以保证队列不会内存溢出, 即这里将会真正的GC                node.prev = pred = pred.prev;            &#125; while (pred.waitStatus &gt; 0);            pred.next = node;        &#125; else &#123;             如果前驱正常，那就把前驱的状态设置成SIGNAL，告诉它拿完号后通知自己一下。有可能失败，人家说不定刚刚释放完呢！             初始化的新节点waitStatus是0            compareAndSetWaitStatus(pred, ws, Node.SIGNAL);        &#125;        return false;    &#125;     释放排他锁    public final boolean release(int arg) &#123;         尝试释放锁, 其实就是state-1         Thread.currentThread() != getExclusiveOwnerThread() 如果没有加锁就开始释放锁, 会抛出异常         state=state-1 即可, 如果state为0说明释放锁, 则设置clusiveOwnerThread = null        if (tryRelease(arg)) &#123;            Node h = head;            if (h != null &amp;&amp; h.waitStatus != 0)                 唤醒后继节点                unparkSuccessor(h);            return true;        &#125;        return false;    &#125;     具体子类实现    protected boolean tryRelease(int arg) &#123;        throw new UnsupportedOperationException();    &#125;    ------------------------------------ 公平锁部分 ------------------------------------     在每次tryAcquired的时候,都会判断是否有等待线程, 若有则等待, 没有才能获取锁（返回false表明队列为空才能获取锁）    public final boolean hasQueuedPredecessors() &#123;        Node t = tail;        Node h = head;        Node s;        **         * 1. h.next为空表明表明已有线程在排队         *   1.1 当前线程进入hasQueuedPredecessors的同时，另一个线程已经更改了tail（在enq中），但还没有将head的next指向自己，这中情况表明队列不为空         *   1.2 当前线程将head赋予h后，head被另一个线程移出队列，导致h的next为空，这种情况说明锁已经被占用         * 2.head.next的线程不是当前线程，则表示队列不为空, 即已有线程在排队         * 队列不空则返回true, 导致进入等待队列（后面则和非公平锁一致）         *         * 问题:         * 步骤1: 线程A调用tryAcquire获取锁失败后, 并在调用addWaiter进入等待队列之前,         * 步骤2: 线程B释放了锁         * 步骤3: 此时C线程进来判断到锁空闲, 进入hasQueuedPredecessors返回false（等待队列为空）, C先于A获得锁         * 表明公平锁也不是绝对的公平         *         * 公平锁会导致后来线程一定会进入等待队列, 就算其他线程碰巧释放了锁也不允许越级获取锁, 并发效率将降低很多         * 一个入队等待可能耗时几十毫秒, 上千的线程将导致延时几十秒的数量级         *        return h != t &amp;&amp;                ((s = h.next) == null || s.thread != Thread.currentThread());    &#125;    ------------------------------------ 共享锁部分 ------------------------------------     这部分等查阅Semaphore(信号量)CountdownLatch(同步计数器)CyclicBarrier(循环屏障)时再补充     ====================== CAS支持 ============================    private static final Unsafe unsafe = Unsafe.getUnsafe();    private static final long stateOffset;    private static final long headOffset;    private static final long tailOffset;    private static final long waitStatusOffset;    private static final long nextOffset;    static &#123;        try &#123;            stateOffset = unsafe.objectFieldOffset                    (AbstractOwnAQS.class.getDeclaredField(state));            headOffset = unsafe.objectFieldOffset                    (AbstractOwnAQS.class.getDeclaredField(head));            tailOffset = unsafe.objectFieldOffset                    (AbstractOwnAQS.class.getDeclaredField(tail));            waitStatusOffset = unsafe.objectFieldOffset                    (Node.class.getDeclaredField(waitStatus));            nextOffset = unsafe.objectFieldOffset                    (Node.class.getDeclaredField(next));        &#125; catch (Exception ex) &#123; throw new Error(ex); &#125;    &#125;    **     * CAS更新头节点     *    private final boolean compareAndSetHead(Node update) &#123;        return unsafe.compareAndSwapObject(this, headOffset, null, update);    &#125;    **     * CAS更新尾节点     *    private final boolean compareAndSetTail(Node expect, Node update) &#123;        return unsafe.compareAndSwapObject(this, tailOffset, expect, update);    &#125;    **     * CAS更新节点内部状态     *    private static final boolean compareAndSetWaitStatus(Node node,                                                         int expect,                                                         int update) &#123;        return unsafe.compareAndSwapInt(node, waitStatusOffset,                expect, update);    &#125;    **     * CAS更新节点的后继节点     *    private static final boolean compareAndSetNext(Node node,                                                   Node expect,                                                   Node update) &#123;        return unsafe.compareAndSwapObject(node, nextOffset, expect, update);    &#125;&#125;","tags":["锁","队列","线程池"],"path":"2019/04/22/Concurrent并发包讲解(三)/","external_link":""},{"title":"SpringMCV","date":"2019-04-21T16:35:08.076Z","content":"什么是Servlet\nServlet是为了解决实现动态页面而衍生的东西;\n一个Web应用应该只有一个Servlet, 可以理解为Http请求的唯一入口, 实际上我们也是这么做的;\ntomcat容器与Servlet请求执行过程 :\n\n\n\n浏览器Http请求发送至Tomcat\nTomcat加载相应的Servlet并实例化(ServletContext+ServletConfig)\nTamcat解析Http协议为ServletRequest对象, 同时也把ServletResponse对象生成\n调用Servlet实例的service方法, 将ServletRequest和ServletResponse传递过去\nServlet实例处理后, 将ServletResponse填装并返回\nTomcat将ServletResponse解析为Http协议的响应,返回浏览器客户端\n\n\ntomcat就是servlet实例的容器, 负责servlet的生命周期, 一个应用只应有唯一的servlet, tomcat将对应的Http请求转换成request对象传递给Servlet实例进行处理, 完毕后再返回Response对象给tomcat, 最后由tomcat返回响应\nweb容器有两类 (其他还有EJB容器如jboss) :\n一类是servlet容器(tomcat, jetty…);\n一类是portlet容器(websphere);\n\n定义一个Servlet\n123456789101112131415161718192021222324252627282930313233343536373839404142434445public class MyServlet extends HttpServlet &#123;     tomcat,jetty等servlet容器会调用init(config)进行初始化, config是从web.config读取    @Override    public void init(ServletConfig config) throws ServletException &#123;        super.init(config);    &#125;     servlet销毁时, 为空实现, 需要自己重写    @Override    public void destroy() &#123;        super.destroy();    &#125;     Tomcat, Jetty等容器会加载此MyServlet类, 请求到达时会调用service方法, 传入req, resp     不需要重写此类, 此处只是为了做说明    @Override    protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        super.service(req, resp);    &#125;     重写get方法    @Override    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        System.out.println(GET);    &#125;     重写post方法    @Override    protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        System.out.println(POST);    &#125;     重写put方法    @Override    protected void doPut(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        System.out.println(PUT);    &#125;     重写delete方法    @Override    protected void doDelete(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        System.out.println(DELETE);    &#125;&#125;\n定义相应的web.xml\nspringmvc的DispatcherServletweb应用唯一servlet\ndurid链接池的StatViewServlet状态监控servlet\n说明tomcat, jetty等容器可以根据url映射到不同的servlet\n每个servlet都有一个ServletConfig,ServletContext,  &lt;load-on-startup&gt;值为0表示Tomcat在启动时就会去加载servlet, 大于0则表示第一次请求时才加载\n12345678910111213141516171819202122232425262728293031&lt;!-- SpringMVC的servlet请求调度中心,也叫前端控制器 --&gt;&lt;servlet&gt;\t&lt;servlet-name&gt;springmvc&lt;servlet-name&gt;\t&lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;servlet-class&gt;\t&lt;!-- 若不写则默认为WEB-INFspringmvc-servlet.xml, 可以自定义名称为[&lt;servlet-name&gt;]-servlet.xml，如springmvc-servlet.xml;         一旦自定义名字和位置,名字必须是contextConfigLocation --&gt;\t&lt;init-param&gt;\t\t&lt;param-name&gt;contextConfigLocation&lt;param-name&gt;\t\t&lt;param-value&gt;classpath:springmvc-servlet.xml&lt;param-value&gt;\t&lt;init-param&gt;\t&lt;!-- 小于0或不写表示该servlet被选择时才加载; 大于0表示应用启动立即加载,且数值越小优先级越高 --&gt;\t&lt;load-on-startup&gt;2&lt;load-on-startup&gt;&lt;servlet&gt;&lt;!-- 用于指定截获何种类型的请求 --&gt;&lt;servlet-mapping&gt;\t&lt;!-- 必须是上面指定的servlet --&gt;\t&lt;servlet-name&gt;springmvc&lt;servlet-name&gt;\t&lt;!-- 意思是所有请求都由smvc这个调度器分派 --&gt;\t&lt;url-pattern&gt;&lt;url-pattern&gt;&lt;servlet-mapping&gt;&lt;!-- druid数据库连接池监控Servlet --&gt;&lt;servlet&gt;    &lt;servlet-name&gt;DruidStatView&lt;servlet-name&gt;    &lt;servlet-class&gt;com.alibaba.druid.support.http.StatViewServlet&lt;servlet-class&gt;&lt;servlet&gt;&lt;servlet-mapping&gt;    &lt;servlet-name&gt;DruidStatView&lt;servlet-name&gt;    &lt;url-pattern&gt;druid*&lt;url-pattern&gt;&lt;servlet-mapping&gt;\nSpringMVC\n运行流程\nSpringMVC运行流程图\n\n流程 :\n\n\n用户发送请求至前端控制器DispatcherServlet (其实是先发送到tomcat, jetty等servlet容器, 再由容器通过web.xml的配置选择相应的servlet进行调用)\nDispatcherServlet收到请求调用HandlerMapping处理器映射器\n处理器映射器根据请求url找到具体的处理器(即Controller), 生成处理器对象及处理器拦截器(如果有则生成)一并返回给DispatcherServlet\n其实请求会先经过tomcat等容器的filterChain过滤链(基于回调), 然后才会到达servlet, 然后由HandlerMapping根据url找到HandlerIntercepter拦截器链(基于动态代理, 反射)\nDispatcherServlet通过HandlerAdapter处理器适配器调用处理器\n执行处理器(Controller，也叫后端控制器)\nController执行完成返回ModelAndView\nHandlerAdapter将controller执行结果ModelAndView返回给DispatcherServlet\nDispatcherServlet将ModelAndView传给ViewReslover视图解析器\nViewReslover解析后返回具体View\nDispatcherServlet对View进行渲染视图（即将模型数据填充至视图中）\nDispatcherServlet响应ServletResponse给tomcat容器, 由tomcat将之解析为http内容并返回\n\n\n关于过滤器Filter, 拦截器Interecpter, 如图 :\n\nFilter是Servlet规范定义的, 所以只能在容器(tomcat,jetty…)内使用, 本质是一个过滤器队列(链表);\nHandlerIntercepter是springmvc的定义, 使用的是动态代理 \n所以从表象上看, 有如下几个区别 :\n\n\n拦截器只能对action请求起作用，而过滤器则可以对几乎所有的请求起作用，因为资源的请求会被其他Servlet或者容器处理\n拦截器可以访问action上下文、值栈里的对象，而过滤器不能访问\n拦截器可以获取IOC容器中的各个bean，而过滤器就不行；因为拦截器本身就属于SpingMVC，所以可以在里面注入相应的service\n\n\n九大组件\n首先要了解Handler处理器, 它对应着Controller层, 可以是类也可以是其中的方法, 只要处理请求即可称为Handler, 这是一个广义的概念\n\n\n\n- springmvc组件\n- 作用\n\n\n\n\nHandlerMapping\n用于查找Handler, 主要是根据@RequestMapping注解的url地址来寻找\n\n\nHandlerAdapter\n是一个适配器\n\n\nHandlerExceptionResolver\n所有的组件都可能产生异常, 发生异常后需要一个专门角色进行处理, 并设置ModelAndView错误, render渲染后返回给浏览器\n\n\nViewResolver\n视图解析器, 用来将String类型的视图名和Locale解析为View类型的视图; 这里使用策略模式, 即用户可以配置不同的模板引擎, ViewResolver的工作就是找到对应模板引擎和对应的视图类型, 具体的渲染过程则交由不同的视图自己完成\n\n\nRequestToViewNameTranslator\n从request中获取ViewName就是RequestToViewNameTranslator要做的事情, 所有request到ViewName的转换规则都要在一个Translator里面全部实现, 即springmvc只允许配置一个转换器\n\n\nLocaleResolver\n解析视图需要两个参数：一是视图名, 另一个是Locale, 即zh-cn之类的本地化信息\n\n\nThemeResolver\n用于解析主题;  相关的类还有ThemeSource和Theme, 然后通过主题名称找到对应的主题（可以理解为一个配置）文件，这是ThemeSource的工作。最后从主题中获取资源就可以了\n\n\nMultipartResolver\n用于处理上传请求; 处理方法是将普通的request包装成MultipartHttpServletRequest，后者可以直接调用getFile方法获取File，如果上传多个文件，还可以调用getFileMap得到FileName-&gt;File结构的Map。此组件中一共有三个方法，作用分别是判断是不是上传请求，将request包装成MultipartHttpServletRequest、处理完后清理上传过程中产生的临时资源\n\n\nFlashMapManager\n用来管理FlashMap的, FlashMap主要用在redirect中传递参数\n\n\n\n手写SpringMVC\n\n可以看出SpringMVC本质就是一个Servlet\n定义三个注解\n1234567891011 同 @Controller注解@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface MyController &#123;    **     * 表示给controller注册别名     * @return     *    String value() default ;&#125;\n123456789101112  同 @RequestMapping注解@Target(&#123;ElementType.TYPE,ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface MyRequestMapping &#123;    **     * 表示访问该方法的url     * @return     *    String value() default ;&#125;\n123456789101112  同 @RequestParam注解, 这里只解析GET请求参数@Target(ElementType.PARAMETER)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface MyRequestParam &#123;    **     * 表示参数的别名，必填     * @return     *    String value();&#125;\n定义Servlet (类似DispatcherServlet)\ntomcat等类似的Servlet容器会加载此Servlet, 是否懒加载则是容器根据web.xml配置的内容为准, 当然web.xml还会初始化一些初始化数据\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210public class MyDispatcherServlet extends HttpServlet &#123;     保存web.xml配置    private Properties properties = new Properties();     保存用户指定扫描包路径下的所有类    private List&lt;String&gt; classNames = new ArrayList&lt;&gt;();     保存所有扫描到的类的实例化对象, 类似IOC注入    private Map&lt;String, Object&gt; ioc = new HashMap&lt;&gt;();     保存URL和Handler的映射 (狭义的Handler即Action, 也即Controller中的方法, 广义的Handler即只要能处理请求的都是)    private Map&lt;String, Method&gt; handlerMapping = new HashMap&lt;&gt;();     保存URL和Controller实例的映射, 以便可以反射调用    private Map&lt;String, Object&gt; controllerMap = new HashMap&lt;&gt;();    @Override    public void init(ServletConfig config) throws ServletException &#123;        1.加载配置文件        doLoadConfig(config.getInitParameter(contextConfigLocation));        2.初始化所有相关联的类,扫描用户设定的包下面所有的类        doScanner(properties.getProperty(scanPackage));        3.拿到扫描到的类,通过反射机制,实例化,并且放到ioc容器中(k-v  beanName-bean) beanName默认是首字母小写        doInstance();        4.初始化HandlerMapping(将url和method对应上)        initHandlerMapping();    &#125;    @Override    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        this.doPost(req, resp);    &#125;    @Override    protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123;        try &#123;            处理请求            doDispatch(req, resp);        &#125; catch (Exception e) &#123;            resp.getWriter().write(500!! Server Exception);        &#125;    &#125;    private void doDispatch(HttpServletRequest req, HttpServletResponse resp) throws Exception &#123;        if (handlerMapping.isEmpty()) &#123;            return;        &#125;        String url = req.getRequestURI();        String contextPath = req.getContextPath();        url = url.replace(contextPath, ).replaceAll(+, );        if (!this.handlerMapping.containsKey(url)) &#123;            resp.getWriter().write(404 NOT FOUND!);            return;        &#125;        Method method = this.handlerMapping.get(url);        获取方法的参数列表        Class&lt;?&gt;[] parameterTypes = method.getParameterTypes();        获取请求的参数        Map&lt;String, String[]&gt; parameterMap = req.getParameterMap();        保存参数值        Object[] paramValues = new Object[parameterTypes.length];        方法的参数列表        for (int i = 0; i &lt; parameterTypes.length; i++) &#123;            根据参数名称，做某些处理            String requestParam = parameterTypes[i].getSimpleName();            if (requestParam.equals(HttpServletRequest)) &#123;                参数类型已明确，这边强转类型                paramValues[i] = req;                continue;            &#125;            if (requestParam.equals(HttpServletResponse)) &#123;                paramValues[i] = resp;                continue;            &#125;            if (requestParam.equals(String)) &#123;                for (Entry&lt;String, String[]&gt; param : parameterMap.entrySet()) &#123;                    String value = Arrays.toString(param.getValue()).replaceAll([|], ).replaceAll(,s, ,);                    paramValues[i] = value;                &#125;            &#125;        &#125;        利用反射机制来调用        try &#123;            method.invoke(this.controllerMap.get(url), paramValues);第一个参数是method所对应的实例 在ioc容器中        &#125; catch (Exception e) &#123;            e.printStackTrace();        &#125;    &#125;    private void doLoadConfig(String location) &#123;        把web.xml中的contextConfigLocation对应value值的文件加载到流里面        InputStream resourceAsStream = this.getClass().getClassLoader().getResourceAsStream(location);        try &#123;            用Properties文件加载文件里的内容            properties.load(resourceAsStream);        &#125; catch (IOException e) &#123;            e.printStackTrace();        &#125; finally &#123;            关流            if (null != resourceAsStream) &#123;                try &#123;                    resourceAsStream.close();                &#125; catch (IOException e) &#123;                    e.printStackTrace();                &#125;            &#125;        &#125;    &#125;    private void doScanner(String packageName) &#123;        把所有的.替换成        URL url = this.getClass().getClassLoader().getResource( + packageName.replaceAll(., ));        File dir = new File(url.getFile());        for (File file : dir.listFiles()) &#123;            if (file.isDirectory()) &#123;                递归读取包                doScanner(packageName + . + file.getName());            &#125; else &#123;                String className = packageName + . + file.getName().replace(.class, );                classNames.add(className);            &#125;        &#125;    &#125;    private void doInstance() &#123;        if (classNames.isEmpty()) &#123;            return;        &#125;        for (String className : classNames) &#123;            try &#123;                把类搞出来,反射来实例化(只有加@MyController需要实例化)                 Class.forName是加载类, 且指定了需要执行static静态代码块, 但不会分配堆内存进行实例化                Class&lt;?&gt; clazz = Class.forName(className);                if (clazz.isAnnotationPresent(MyController.class)) &#123;                    ioc.put(toLowerFirstWord(clazz.getSimpleName()), clazz.newInstance());                &#125; else &#123;                    continue;                &#125;            &#125; catch (Exception e) &#123;                e.printStackTrace();                continue;            &#125;        &#125;    &#125;    private void initHandlerMapping() &#123;        if (ioc.isEmpty()) &#123;            return;        &#125;        try &#123;            for (Entry&lt;String, Object&gt; entry : ioc.entrySet()) &#123;                Class&lt;? extends Object&gt; clazz = entry.getValue().getClass();                if (!clazz.isAnnotationPresent(MyController.class)) &#123;                    continue;                &#125;                拼url时,是controller头的url拼上方法上的url                String baseUrl = ;                if (clazz.isAnnotationPresent(MyRequestMapping.class)) &#123;                    MyRequestMapping annotation = clazz.getAnnotation(MyRequestMapping.class);                    baseUrl = annotation.value();                &#125;                Method[] methods = clazz.getMethods();                for (Method method : methods) &#123;                    if (!method.isAnnotationPresent(MyRequestMapping.class)) &#123;                        continue;                    &#125;                    MyRequestMapping annotation = method.getAnnotation(MyRequestMapping.class);                    String url = annotation.value();                    url = (baseUrl +  + url).replaceAll(+, );                    handlerMapping.put(url, method);                    controllerMap.put(url, clazz.newInstance());                    System.out.println(url + , + method);                &#125;            &#125;        &#125; catch (Exception e) &#123;            e.printStackTrace();        &#125;    &#125;    **     * 把字符串的首字母小写     *     * @param name     * @return     *    private String toLowerFirstWord(String name) &#123;        char[] charArray = name.toCharArray();        charArray[0] += 32;        return String.valueOf(charArray);    &#125;&#125;\n测试Controller\n123456789101112131415161718192021222324@MyController@MyRequestMapping(test)public class TestController &#123;    @MyRequestMapping(doTest)    public void test1(HttpServletRequest request, HttpServletResponse response,                      @MyRequestParam(param) String param)&#123;        System.out.println(param);        try &#123;            response.getWriter().write( doTest method success! param:+param);        &#125; catch (IOException e) &#123;            e.printStackTrace();        &#125;    &#125;    @MyRequestMapping(doTest2)    public void test2(HttpServletRequest request, HttpServletResponse response)&#123;        try &#123;            response.getWriter().println(doTest2 method success!);        &#125; catch (IOException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;\n配置web.xml\n位于webappWEB-INFweb.xml\nwebapp和resource目录同级\n12345678910111213141516171819&lt;?xml version=1.0 encoding=UTF-8?&gt;&lt;web-app xmlns:xsi=http:www.w3.org2001XMLSchema-instance         xmlns=http:java.sun.comxmlnsjavaee xmlns:web=http:java.sun.comxmlnsjavaeeweb-app_2_5.xsd         xsi:schemaLocation=http:java.sun.comxmlnsjavaee http:java.sun.comxmlnsjavaeeweb-app_3_0.xsd         version=3.0&gt;    &lt;servlet&gt;        &lt;servlet-name&gt;MySpringMVC&lt;servlet-name&gt;        &lt;servlet-class&gt;com.doyo.springmvc.servlet.MyDispatcherServlet&lt;servlet-class&gt;        &lt;init-param&gt;            &lt;param-name&gt;contextConfigLocation&lt;param-name&gt;            &lt;param-value&gt;application.properties&lt;param-value&gt;        &lt;init-param&gt;        &lt;load-on-startup&gt;1&lt;load-on-startup&gt;    &lt;servlet&gt;    &lt;servlet-mapping&gt;        &lt;servlet-name&gt;MySpringMVC&lt;servlet-name&gt;        &lt;url-pattern&gt;*&lt;url-pattern&gt;    &lt;servlet-mapping&gt;&lt;web-app&gt;","tags":[],"path":"2019/04/22/SpringMCV/","external_link":""},{"title":"线程安全集合，数据结构","date":"2019-04-21T16:36:16.317Z","content":"因为讲数据集合容器就必须涉及数据结构, 以及查找算法, 排序算法; 所以这里就一起讲述了。\n\n\nHashMapConcurrentHashMap\n链表与红黑树的转化, Segment分段锁(和LongAdder类似)\nCopyOnWriteArrayListCopyOnWriteMapCopyOnWriteArraySet\n2.1 fail-fast机制的解决方案; 某一个线程A通过iterator去遍历某集合的过程中，若该集合的内容被其他线程所改变了；那么线程A访问集合时，就会抛出ConcurrentModificationException异常\n2.2 适用场景为多读少写的集合, 且能容忍脏读(无业务影响); 比如黑白名单,注册中心,商品类目\n2.3 由于每次add都会进行一次数组复制并扩容一位, 所以尽量避免使用addAll\n阻塞队列\n生产消费模型的典型场景就是线程池\naddremove: 是Collection接口的方法 (队列已空满会抛异常)\nofferpoll : 是Queue接口方法 (队列已空满会返回false)\nputtake: 是BlockingQueue接口方法, 空满会各自阻塞\n\nArrayBlockingQueue: 由数组支持的有界队列(单锁), 类似循环队列, 与Buffer或者ByteBuf类似\nLinkedBlockingQueue: 由链接节点支持的可选有界队列(双锁)\nPriorityBlockingQueue: 带优先级的无界有序阻塞队列, 由数组二叉排序树(堆)支持的无界优先级队列(完全二叉树)\nDelayQueue: 由优先级二叉排序树(堆)支持的、基于时间的调度队列(延期阻塞无界队列), 时间到了就会移动到队头并唤醒阻塞的线程来执行任务; 由于它是可扩容的, 所以无界\n添加或删除需要排序, siftUp(插入排序)siftDown(删除排序)\nSynchronousQueue: 并发同步队列, 类似管道pipeline; 这是最复杂的队列, 它不存储数据\n参考: DelayedWorkQueue原理分析\n跳表\n本质是一个链表, 使用&quot;先大步查找确定范围，再逐渐缩小迫近&quot;的思想, 效率和二叉排序树(红黑树VAL)差不多, 和B+树一样, 有Level个索引层级\nSkipList跳表基本原理\n完全二叉树: HashMap使用数组+单链表, 索引位置通过hash取模得到, 所以无序; 我们通常将TreeMapConcurrentHashMapConcurrentSkipListMap三者进行比较;\nConcurrentHashMap: 无序,且\nTreeMap: 使用红黑树,所以有序(可指定排序器), 但线程不安全\nConcurrentSkipListMap: 使用跳表(本质是链表,使用跳跃式查找,空间换时间O(logn))\nConcurrentSkipListMap\nConcurrentSkipListSet\nAmino无锁并行框架\n提供免锁集合,基于CAS\nLockFreeVector\nLockFreeListLockFreeOrderedListLockFreeSet\nLockFreeBlockQueueLockFreeDequeLockFreePriorityQueue\nLockFreeDictionary\n树  图\n同时提供并行计算模式\nMaster-Worker、Map-reduce、Divide and conquer, Pipeline\nJCTools mapqueue增强\n主要提供了map以及queue的增强数据结构;\n原来netty还是自己写的MpscLinkedQueueNode, 后来新版本就换成使用JCTools的增强并发队列\n6.1 增强Map:\nConcurrentAutoTable(后面几个mapset结构的基础)\nNonBlockingHashMap\nNonBlockingHashMapLong\nNonBlockingHashSet\nNonBlockingIdentityHashMap\nNonBlockingSetInt\n6.2 增强队列:\nSPSC - 单生产者单消费者 (Wait Free, bounded and unbounded)\nMPSC - 多生产者单消费者 (Lock less, bounded and unbounded)\nSPMC - 单生产者多消费者 (Lock less, bounded)\nMPMC - 多生产者多消费者 (Lock less, bounded)\nTreeMap\n由于链表LinkedList是基于链表,是乱序的, TreeMap使用堆(完全二叉树), 但是添加节点有rebalance操作, 对高并发效率很低, 同时没选择VAL也是折中的表现, 后面会对比; 所以才有上面的跳表出现;\njava的实现类似链表, 只是Entry&lt;K,V&gt;内部有三个引用 (parentleftright), 操作有: 着色左旋右旋\n7.1 满二叉树:\n度为2, 且达到最满\n7.2 完全二叉树:\n比完全二叉树弱一点, 允许最后一层不满, 且左边一定连续集中; 它是一种效率很高的数据结构, 迪杰斯特拉,普里姆算法,二叉排序树等 都使用了此结构; 堆就是一种完全二叉树, 但不是二叉排序树\n7.3 二叉排序树:\n所有节点遵循左中右依次增大, 且没有键值相等的节点 中序遍历即可得到有序数列, 高度决定查找效率O(logn) 在有序(中序遍历)情况下会退化为链表O(n)\n7.4 平衡二叉树-VAL:\n二叉排序树删除节点会导致树向左偏沉, 破坏类完全二叉树的平衡性; 所以引出平衡二叉树(自旋)\n7.5 平衡二叉树-红黑树:\n类似VAL平衡二叉排序树, 但它不是严格的高度平衡树; VAL查询更稳定, 红黑树插入删除更稳定;\n7.6 2-3树2-3-4树B树B+树B*树:\n和平衡二叉树不一样, 它们度允许大于2, 可称之为多路查找树 2-3树要么有2个子节点, 要么有3个子节点, 2-3-4树同理; 多路查找树可以在常数次找到目标(依赖树高度), 比如对于10亿个节点的2-3树，树的高度为18-30之间; 问题在于查找到后的插入和删除会导致自平衡的代价极高, 所以才有红黑树来折中 B+树,因为比较规整, 非叶子节点为稀疏索引, 叶子节点存储值, 叶子节点有链表指针, 非常适合文件索引系统 B*树为非叶子结点也增加链表指针，将结点的最低利用率从12提高到23, 其实就是节省空间\n平衡查找树之2-3树\nB树与B+树\nB树、B-树、B+树、B*树之间的关系\nMySQL索引背后的数据结构及算法原理\n7.7 字典树(Trie):\n7.6 哈夫曼树: 带权路径长度最短的树(最优)\n7.7 深度遍历(前序中序后序):\n树的定义本身就是递归定义,所以使用递归算法实现更易于理解 前序遍历：根结点 ---&gt; 左子树 ---&gt; 右子树 中序遍历：左子树---&gt; 根结点 ---&gt; 右子树 (二叉排序树) 后序遍历：左子树 ---&gt; 右子树 ---&gt; 根结点\n7.8 广度遍历(层次遍历):\n从上往下, 从左到右\n7.9 堆\n堆是完全二叉树, 但不是二叉排序树; 因为它不遵循左&lt;父&lt;右 它遵循的是左&lt;父, 父&gt;右, 所以小值在下, 大值在上, 查找效率低(因为不知道从左节点开始查找还是从右节点开始) 一般使用数组来实现, 由于是完全二叉树, 所以不存在数组空间的浪费\n7.10 应用\nd\n\n\n\n\nTree, 查找算法, 排序算法概念\n二叉堆\n\n特性\n\n\n\n是完全二叉树, 即除了最后一层节点不是满的, 其他层节点都是满的\n它不是二叉搜索树, 它要求父节点的值不能小于子节点的值, 所以堆遍历和查找都比较低效, 平均O(n)\n它可以实现快速的插入和删除, 效率都在(logN)左右; 所以它可以实现优先级队列\n堆是为了排序而设计的数据结构 [查找:O(n), 插入删除:O(logN)]\n二叉排序树是面向动态查找的数据结构 [查找:O(logN), 插入删除: 需要额外的旋转进行自平衡]\n\n\n\n堆的操作\n\n堆主要就是插入和删除, 前提是:\n\n是完全二叉树\n父节点的值不能小于子节点的值\n\n1234 对于n位置的节点来说：int left = 2 * n + 1;  左子节点int right = 2 * n + 2;  右子节点int parent = (n - 1)  2;  父节点，当然n要大于0，根节点是没有父节点的\n插入\n123456789101112131415161718public void insert(int value) &#123;      第一步将插入的值，直接放在最后一个位置。并将长度加一     store[size++] = value;      得到新插入值所在位置。     int index = size - 1;     while(index &gt; 0) &#123;          它的父节点位置坐标(index - 1)  2         int parentIndex = (index - 1)&gt;&gt;&gt;2;          如果父节点的值小于子节点的值，你不满足堆的条件，那么就交换值         if (store[index] &gt; store[parentIndex]) &#123;             swap(store, index, parentIndex);             index = parentIndex;         &#125; else &#123;              否则表示这条路径上的值已经满足降序，跳出循环             break;         &#125;     &#125; &#125;\n删除\n1234567891011121314151617181920212223public int remove() &#123;       将根的值记录，最后返回      int result = store[0];       将最后位置的值放到根节点位置      store[0] = store[--size];      int index = 0;       通过循环，保证父节点的值不能小于子节点。      while(true) &#123;          int leftIndex = index&lt;&lt;1 + 1;  左子节点          int rightIndex = index&lt;&lt;1 + 2;  右子节点           leftIndex &gt;= size 表示这个子节点还没有值。          if (leftIndex &gt;= size) break;          int maxIndex = leftIndex;          if (store[leftIndex] &lt; store[rightIndex]) maxIndex = rightIndex;          if (store[index] &lt; store[maxIndex]) &#123;              swap(store, index, maxIndex);              index = maxIndex;          &#125; else &#123;              break;          &#125;      &#125;      return result;  &#125;\nSkipList跳表\n其实RB-tree的性能和SkipList相差无几, 但是在并发环境就不同了;\n红黑树有一个自平衡(rebalance)过程, 涉及节点较多, 所以竞争锁的代价较高(当然还是比VAL要好, 因为删除节点波及的范围可能会更大);\nskiplist的操作显然更加局部性一些，锁需要盯住的节点更少\n核心思想如下图:\n主要是思想就是提取一些节点作为索引, “先大步查找确定范围，再逐渐缩小迫近”\n\n从上图可以看出, 跳表具有如下性质:\n\n\n由很多层结构组成\n每一层都是一个有序的链表\n最底层(Level 1)的链表包含所有元素\n如果一个元素出现在 Level i 的链表中，则它在 Level i 之下的链表也都会出现。\n每个节点包含两个指针，一个指向同一链表中的下一个元素，一个指向下面一层的元素。\n\n\n来看看查找过程:\n\n插入很简单, 主要是要决定元素要占据的(索引)层K, 需要完全随机采用丢硬币的形式，这里就不讲述, 可参考: SkipList跳表基本原理\n二叉排序树\n它不是完全二叉树, 但它满足中序遍历(左-&gt;根-&gt;右)结果是排好序的\n\n插入:\n插入顺序不同, 树结构是不一样的, 但中序遍历结果一样\n\n\n树为空, 则插入root根节点\n小于根节点, 则插入左子树\n大于根节点, 则插入右子树\n\n\n删除: \n\n\n为叶子节点, 直接删除\n为单支节点, 和单链表类似, parent.next = node.next; 即node的父节点指向node的子节点, 同时断开node的引用并删除\n左右子节点均不空, 将中序遍历的后继节点移动并覆盖掉需要被移除的节点, 因为其特性导致后继节点肯定没有左子树, 所以移动后继节点后可参考步骤2; 如下图\n\n\n特点:\n\n\n因为删除操作移动右子树, 右节点减少从而导致树偏左沉, 使之成为非完全二叉树(平衡性被破坏), 引出了平衡二叉树VAL(自平衡-旋转)\n二叉排序树查找的时间复杂度为O(log2n), 极端情况下, 比如是插入是有序的(中序), 则会退化为链表O(n), 也即树高度为n, 需要递归查询n次;  所以通常随机化建立二叉树排序树\n\n\n二叉排序树删除节点 (左右子节点不为空)\n\n参考:\n数据结构中各种树\n平衡二叉树-VAL\n查找效率: O(1) &gt; O(logn) &gt; O(n) &gt; O(n^2)\n1. 首先, 平衡二叉树类似完全二叉树, 只是不一定满足叶子节点左边连续, 但是高度差最大还是1; 所以叫高度平衡树\n\n其次, VAL和红黑树添加时都至多2次旋转, 但是删除则不同。 VAL在极端情况下需要维护从被删node到root这条路径上所有node的平衡性, 因此需要旋转的量级O(logN), 即树高; 红黑树至多3次旋转\n再者, 红黑树不是绝对的高度相差1, 但保证基本是高度平衡树, 所以查询效率可能略低于VAL, 但几乎可以忽略不计\n最后, VAL是高度平衡树, 插入删除更易引起自平衡rebalance, 所以红黑树适合增删频繁, VAL更适合不变的数据查询。但是查询的那点效率损耗和频繁插入删除比起来不在一个量级, 所以计算机领域基本都使用红黑树作为数据结构\n\n\n\n优点:\n二叉排序树每次增删节点都会进行自旋进行重新平衡, 所以O(n)退化为链表的极端情况永远不会发生\n缺点:\n频繁的自平衡(旋转)会浪费一定时间, VAL是高度平衡树\n\n\n一. 旋转操作, 首先需要知道不平衡的四种姿态\n\n\n左左右右: 进行单旋转 (LL  RR)\n左右右左: 进行双旋转 (RR-&gt;LL  LL-&gt;RR)\n\n\n\n二. LL单旋转操作(RR单旋转同理)\n只需要旋转一次, 可以用一种平衡玩具来联想\n\n三. LR双旋转操作(RL双旋转同理)\n即需要把子树先给&quot;掰&quot;成向一个方向&quot;沉&quot;, 统一方向后再向另外一个方向整体&quot;掰&quot;\n先左子树K1进行RR旋转, 再K2进行LL旋转\n\n平衡二叉树-红黑树\n它是计算机科学中用到的一种数据结构, 和VAL树一样保证最坏都是O(logn), 上面已经讲述了VAL和红黑树的对比\n\n\n节点是红色或黑色\n根是黑色\n所有叶子都是黑色\n每个红色节点必须有两个黑色的子节点\n从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点 (保证最长路径不超过最短路径的2倍, 而且每条路径的黑色个数&gt; h2)\n\n\n插入步骤\n\n\n将红黑树当作一颗二叉查找树, 将节点插入\n将插入节点着色为红色\n注意插入节点必须为红色, 为黑色会违背性质5; 但是添加红色节点后，可能会导致出现两个连续红色节点的冲突, 那么可以通过颜色调换（color flips）和树旋转来调整\n通过旋转和重新着色等方法来修正该树,旋转分为左旋右旋\n\n\n\n空树; 则插入的是根节点, 直接涂为黑色\n被插入节点父节点为黑色; 符合红黑树\n被插入节点父节点与叔父节点为红色, 违反性质4; 此时需要递归变色, 但无须旋转\n被插入节点父节点红色, 叔父节点黑色(或缺少), 且是其父节点的左子节点, 而父节点又是其祖父节点的左子节点; 此时需要旋转;\n被插入节点父节点红色, 叔父节点黑色(或缺少), 且是其父节点的右子节点, 而父节点又是其祖父节点的左子节点\n\n\n\n插入-情形3\n\n插入-情形4\n\n插入-情形5\n\n旋转步骤\n参考:\n数据结构中各种树\nTreeMap\nB树\n待续\nB+树\n待续\nB*树\n待续\nTire字典树\n哈夫曼树\n\n数据容器的实现\nHashMap\n主要采用拉链法, 每个数组元素为Entry单链表\n123456789101112 初始容量为16, 即数组长度为16static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; 数组最大长度static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; 填充因子, 因为数组不允许装满, 否则冲突概率很大, 0.75是实验出来的最好填充因子static final float DEFAULT_LOAD_FACTOR = 0.75f; 链表长度过大, 会造成查找链表节点效率低下, 所以限制链表长度为8, 超过则转化为红黑树static final int TREEIFY_THRESHOLD = 8; 链表长度低于6, 红黑树又退化为链表static final int UNTREEIFY_THRESHOLD = 6; 转为红黑树前的第二重判断条件, 同时键值对数量超过64才允许转化红黑树, 避免hash函数不合理造成初期就会转化为树static final int MIN_TREEIFY_CAPACITY = 64;\nConcurrentHashMap\n待续…\n","tags":[],"path":"2019/04/22/线程安全集合，数据结构/","external_link":""},{"title":"JVM","date":"2019-04-21T16:32:29.233Z","content":"JVM在性能优化时是必备知识点, 则必须知道JVM内存的结构, 如何GC回收, 如何使用工具和参数来实现调优;\n\nJVM内存结构\nGC回收机制与算法\n垃圾收集器,使用性能监控工具调优,参数调优\n动态字节码\n类加载器\n\n\n一 JVM内存结构\n(1)结构图\n注意区别于JMM内存模型\n图1\n\n根据线程私有还是公有, 给出一张图,\n注意程序计数器没有内存异常;\n注意:\n\n申请Heap堆空间内存不足, 或者栈允许动态扩容且申请内存不足时抛出OutOfMemeryError; 一般是大量创建对象时才会发生堆内存溢出\n只有栈才会抛出StackOverFlowError, 一般情况是入栈深度大于虚拟机所允许的深度, 常见的就是递归方法栈溢出(解决办法请见尾递归)\n图2\n\n\n(2)jvm内存的五大区域\n堆, 栈, 本地栈, 方法区(永久代), 程序计数器\n\n\n堆 Heap\n所有线程共享, JVM中最大的一块内存, 用于存储对象实例本身; 同时堆是垃圾搜集器管理的主要区域;\n所有对象以及数组都需要在堆上分配空间;\n堆的还有更具体的划分, 新生代, 老生代;\n堆大小可通过-Xmx 和 -Xms指定, 无法再扩展则会抛出OutOfMemoryError\nHeap堆里分为几块区域:\n方法区(永久代Meta-Area): 这块区域名字几经变化, java8叫做元数据空间; 主要存储jvm加载类的类信息，类变量，静态变量，方法信息，常量，即时编译器编译后的代码等数据\n运行时常量区: 它是方法区里的一部分, 存放编译器生成的各种字面量和符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中 (比如我们常说的字符串常量池)\n注意: jvm将方法区描述为Heap堆区的一个逻辑部分, 但实际上它的别名叫non-heap(非堆)\n\n\n\n\n栈 Stack\n单个线程私有, 每个方法执行时都会创建栈, 线程执行每个方法其实就是栈帧的出栈入栈 (一个栈帧对应一个方法), 栈帧用于存储局部变量表、操作数栈、动态链接、方法出口等信息\n局部变量表: 用于存储形参, 局部变量(基本类型对象引用返回类型); 它在编译期(class文件)完成局部变量表容量的计算, 运行期不会改变其大小\n操作数栈: 即方法执行期间出栈入栈操作, 栈的深度编译期就已确定; Java虚拟机的解释执行引擎称为“基于栈的执行引擎”，其中所指的“栈”就是操作数栈, 也称Java虚拟机是基于栈的; 优点是可移植性好, 缺点是执行速度相对慢一些 (相对Android基于寄存器的虚拟机)\n动态链接: 每个栈帧都包含一个指向运行时常量池(位于方法区)中该栈帧所属方法的引用, 持有这个引用是为了支持方法调用过程中的动态连接;\nClass文件的常量池中存在有大量的符号引用，字节码中的方法调用指令就以常量池中指向方法的符号引用为参数\n静态解析: 一部分符号引用会在类加载阶段或第一次使用的时候转化为直接引用（如 final、static 域等）\n动态连接: 另一部分将在每一次的运行期间转化为直接引用\n方法返回地址: 方法被执行后, 有两种方式退出该方法: 执行引擎遇到了任意一个方法返回的字节码指令或遇到了异常, 并且该异常没有在方法体内得到处理;\n方法退出后需要返回到方法被调用的位置, 如果是正常退出, 上层方法的栈帧会保存一些地址信息以便返回, 如果是异常退出, 则需要通过异常处理器来确定返回地址;\n退出方法需要做的操作: 恢复上层方法的局部变量表和操作数栈, 若有返回值则还需要压入调用者栈帧的操作数栈中\n\n\n\n\n本地方法栈 Native Static\n单个线程私有, 和java栈很类似, 只是它存的是JVM调用C++的方法局部变量等\n\n\n\n\n程序计数器\n单个线程私有, 记录了当前线程执行到哪一条指令, 因为每个线程都有一个独立的线程计数器, 目的是为了线程切换的时候能恢复到正常执行位置 (cpu时间片只能执行一个指令)\n注意它没有抛出内存异常, 查阅上图2\n\n\n\n\n堆外内存(直接内存)\n这个不属于JVM内存管理的范畴, 所以回收跟c和c++一样需要自己回收, 而不通过垃圾回收器\nNIO中就有一个DirectByteBuffer可以开辟堆外内存\n\n\n总结 :\n\n方法区：\n方法区称为持久代，因为GC会很少回收这块区域，但不代表不回收；\n比如运行时常量区，除了存储编译期常量外（字面常量、符号引用、翻译出来的直接引用），也可以存储在运行时间产生的常量，比如String类的intern()方法；\n针对持久代的回收一般是对常量池和已加载类的卸载进行回收；\n方法区可以设置大小：--XX:PermSize，--XX:MaxPermSize；方法区超出允许的大小会抛出OutOfMemory异常，一般来说无须调整方法区大小\n2. 运行时常量池和方法区的区别\n方法区包含两部分：\n其一，Class类信息(类的版本、字段、方法、接口等描述信息)\n其二，运行时常量池，主要是编译期生成的各种字面量和符号引用；它具有动态性，并不要求常量一定只有编译期才能产生，运行时也可产生，最常见的即String.intern()\n堆区：\n常将-Xms和-Xmx设置成一样。为了让内存回收更加高效\n\n(3) HotSpot逃逸分析\n这是HotSpot虚拟机比较前沿的优化技术, 一种全局的跨函数数据流分析算法;\n可以有效减少Java程序中同步负载, 降低内存堆分配压力和GC压力\n首先要了解java创建对象或数组一般是在Heap堆上, 但这不是绝对; 有两种方式导致创建出来的对象不在Heap堆上 :\n\n\n\nJava中的逃逸分析\nTLAB（Thread Local Allocation Buffer）线程私有的缓存区\n\n\n首先要了解什么是java逃逸分析?\n逃逸分析的基本行为就是分析对象动态作用域, 是否跨域了; 编译器能够分析出一个新的对象的引用的使用范围从而决定是否要将这个对象分配到堆上\n\n发生逃逸的2种情况\n\n\n当一个对象在方法中定义之后, 作为参数传递到其它方法中\n如类变量或实例变量, 可能被其它线程访问到\n\n\n\n若没有出现逃逸行为, 则可以通过如下行为进行优化:\n\n\n同步消除\n标量替换\n栈上分配\n\n\n1. 同步消除\n如果确定对象不会逃逸出线程, 无法被其他线程访问到, 那该对象的读写就不会存在竞争, 则可以消除对该对象的同步锁, 通过-XX:+EliminateLocks可以开启同步消除\n注意: 如果有逃逸行为, 但是线程永远只有一个(无锁竞争), 这时HotSpot不会做任何优化, 只是互斥锁会一直是偏向锁而已\n2. 标量替换\n\n1. 标量是指不可分割的量，如java中基本数据类型和reference类型，相对的一个数据可以继续分解，称为聚合量；\n2. 如果把一个对象拆散，将其成员变量恢复到基本类型来访问就叫做标量替换；\n3. 如果逃逸分析发现一个对象不会被外部访问，并且该对象可以被拆散，那么经过优化之后，并不直接生成该对象，而是在栈上创建若干个成员变量\n4. 通过-XX:+EliminateAllocations可以开启标量替换， -XX:+PrintEliminateAllocations查看标量替换情况\n\n3. 栈上分配\n其实目前Hotspot并没有实现真正意义上的栈上分配，实际上是标量替换;\n堆内存的开辟和GC回收都是耗时操作, 如果能优化为栈上(局部变量表)分配, 栈帧出栈即会销毁, 大大减少堆分配和GC压力\n4. 总结\n逃逸分析是一项耗时操作, 目前的实现都是采用不那么准确但是时间复杂度相对较小的算法来完成逃逸分析, 这就可能导致效果不稳定, 要慎用\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758** * HotSpot逃逸分析 (创建200w个对象, 查看Heap堆的对象分布情况) * * 即时编译（Just-in-time Compilation，JIT） * 是一种通过在运行时将字节码翻译为机器码，从而改善字节码编译语言性能的技术; * 1. C1编译速度快, 优化方式比较保守  (client) * 2. C2编译速度慢, 优化方式比较激进  (server) * 3. C1+C2在开始阶段采用C1编译, 当代码运行到一定热度之后采用G2重新编译 (分层编译) * 在1.8之前, 分层编译默认是关闭的, 可以添加-server -XX:+TieredCompilation参数进行开启 * * 1. java -cp . -Xmx3G -Xmn2G -server -XX:-DoEscapeAnalysis DoEscapeAnalysis  运行代码 *    (-XX:-DoEscapeAnalysis  关闭逃逸分析) *    jmap -histo [pid]  查看Heap堆对象分布情况 *    结果: 堆上200w个User对象 * * 2. java -cp . -Xmx3G -Xmn2G -server DoEscapeAnalysis  运行代码 *    jmap -histo [pid]  开启逃逸分析后, 查看Heap堆对象分布情况 *    结果: 堆上41w+个User对象 * * 3. java -cp . -Xmx3G -Xmn2G -server -XX:-TieredCompilation DoEscapeAnalysis 运行代码 *    (-XX:-TieredCompilation  关闭分层编译) *    jmap -histo [pid] *    结果: 堆上1w+个User对象 * * 总结: 开启JIT分层编译会阻碍逃逸分析 *     即时编译JIT只在代码段执行足够次数才会进行优化，在执行过程中不断收集各种数据， *     作为优化的决策，所以在优化完成之前，例子中的User对象还是在堆上进行分配 *public class DoEscapeAnalysis &#123;    static class User &#123;        private final int age;        public User(int age) &#123;            this.age = age;        &#125;        public int getAge() &#123;            return age;        &#125;    &#125;    public static void main(String[] args) throws Exception &#123;        int sum = 0;        int count = 1000000;        warm up        for (int i = 0; i &lt; count; i++) &#123;            sum += fn(i);        &#125;        Thread.sleep(500);        for (int i = 0; i &lt; count; i++) &#123;            sum += fn(i);        &#125;        System.out.println(sum);        System.in.read();    &#125;    private static int fn(int age) &#123;        User user = new User(age);        int i = user.getAge();        return i;    &#125;&#125;\n参考:\nJava 逃逸分析\n浅谈HotSpot逃逸分析\n\n二 GC回收机制与算法\n上面说过, JVM内存结构被描述为五大区域, 其中「程序计数器」,「native方法栈」,「虚拟机栈」三个是线程私有, 伴随线程的生命周期而生灭, 因此分配和回收具备确定性;\n垃圾收集器的工作场所主要是在Heap堆区\n(1) 堆内存分布\njvm堆内存分布图 : 所有回收器类型都是基于分代技术\n\n\n新生代 : 分为三个区域\n 原始区(Eden) : 对象绝大部分在此区分配 (除非对象太大放不下则会放到老年代);\n存活区s1(From) : s1和s2是两块大小相同的存活区\n存活区s2(To) : 回收结束后, s1和s2交换, 保证s2(To)为空\n总结 : 回收选型为Copy复制, 回收后原始区(Eden), s2(To)是空的\n原始区和两个存活区按照 8:1:1的比例分配空间\n老年代 :\n回收时, 标记（Mark）、清除（Sweep）、合并（Compact）, 回收选型为Compact合并\n\n\n\n\n永久代 :\n也叫做方法区, 现在叫做元数据区 (详情见上面)\n\n\n图1\n\n图2\n\n\n\n垃圾收集算法\n1.1 tracing算法 (标记-清除收集器)\n1.2 copying算法 (上面图中的s1, s2就是容量相等的两块区域)\n1.3 compacting算法\n1.4 generation算法\n常用垃圾收集器\n2.1 标记-清除收集器 Mark-Sweep\n2.2 复制收集器 Copying　　\n2.3 标记-压缩收集器 Mark-Compact\n2.4 分代收集器　　　Generational\n对象回收算法\n3.1 引用计数算法\n3.2 可达性分析算法\n\n\n(2) 垃圾回收算法\n1. tracing算法 (Mark-Sweep标记-清除收集器)\n它是最简单的算法, 效率也是最高, 但缺陷也是最大的\n\n\n标记(Mark) :\n从根集合（GC Roots）进行扫描, 对存活的对象进行标记\n清除(Sweep) :\n再扫描整个空间中未被标记的对象，进行回收\n注意: 标记清除没有移动对象, 所以不管存活对象多不多, 这都是效率最高的方式, 但严重缺陷是会有内存碎片;\n极端情况时, 碎片太多导致大对象(数组)无法分配, 提前触发新的一次垃圾收集动作, 再次无法分配直接抛出OutOfMemeryError异常\n\n\n\n2. copying算法 (Copying收集器)\n为解决内存碎片, 提出此算法\n\n它将可用内存按容量划分为大小相等的两块, 每次只使用其中的一块;\n当这一块的内存用完了, 就将还存活着的对象复制到另外一块上面, 然后再把已使用的内存空间一次清理掉;\n这样一来就不容易出现内存碎片的问题\n注意: 此方式高效且没有内存碎片, 但是内存空间却浪费了一半\n如果存活对象很多, 那么复制的数量大大增加, 效率直线下降\n\n可以看出, 新生代中Survivor1Survivor2就是两个相等的存活区, 所以jvm对于新生代的垃圾回收就是使用copying算法\n\n3. compacting算法 (Mark-Compact标记-压缩收集器)\n为解决空间浪费, 以及移动大量活动对象造成效率低下, 提出此算法\n\n为了解决Copying算法的缺陷，充分利用内存空间，提出了Mark-Compact算法。该算法标记阶段和Mark-Sweep一样，但是在完成标记之后，它不是直接清理可回收对象，而是将存活对象都向一端移动，然后清理掉端边界以外的内存\n\n4. Generation分代算法\n这是大部分HotSpot垃圾收集器采用的算法, 核心思想是根据对象生命后期进行分代, 将堆分为新生代, 老年代\n图3\n\n\n新生代\n\n其特点是每次GC都有大量对象被回收, 存活对象少;  所以新生代很适合copying算法, 因为复制的对象较少\n\n1 原始区 : 较大; 是绝大多数对象分配内存的地方(少数放不下可能直接放到老年代)\n2 两块存活区 : 较小,且一样大, 目的是为了符合copying算法\n3 minor gc : \n3.1 Eden区域的空间不足于分配新对象时, 首次触发minor gc\n3.2 将存活对象拷贝到s1(From), 清除Eden不可达对象, 同时年龄+1 (年龄就是minor gc的次数)\n3.3 当s1(From)也满了, 则第二次触发minor gc时, 将Eden, s1(From)中存活对象拷贝到s2(To), 各自对象年龄+1, 清空Eden, s1(From); 注意如果s2放不下则会直接放到老年代\n3.4 垃圾回收后Eden, s1(From)是空的; 此时交换s1和s2, 保证s2(To)是空的, 如此往复\n\n\n**注意 ：\n首先年轻代的默认空间配比: Eden:s1:s2--&gt;8:1:1, 可通过jvm参数调整(后续说明)\n\n年龄即为minor的次数, 每GC一次年龄+1 (默认超过8次minor gc还未回收则会进入老年代)\n每次回收触发原因是由于Eden或者s1(From)空间不足 (当然还有Full GC)\n**\n\n\n新生代垃圾回收流程\n\n123456789101112131415161. 在初始阶段，新创建的对象被分配到Eden区，survivor的两块空间都为空2. 当Eden区满了的时候，minor garbage 被触发3. 经过扫描与标记，存活的对象被复制到S1，不存活的对象被回收，清空Eden；首次回收完毕注意：当S1满了，则会触发第二次minor gc，和下面情形相同4. 当Eden再次满时，触发第二次年轻代GC，Eden和S1存活的对象将会被拷贝到S2（放不下的会被放到老年代）5. 清空Eden和S1，交换S1和S2，第二次回收完毕6. 此时Eden和S2是空的，再循环往复注意：1. 每次minor gc后，年龄+12. 若不指定，默认8次minor gc后进入老年代3. 如果触发gc后Eden还是无法分配内存，抛出OutOfMemery4. s2不足以放下Eden和s1的存活对象，直接放到老年代5. 老年代也满了则会触发Full GC，即新生代老年代都回收6. 这里涉及-Xmx -Xms -Xmn -Xss的堆大小指定，还有-XX:NewRatio -XX:SurvivorRatio -XX:MaxPermSize -XX:MaxPermSize 堆的比例等等，后续讲解\n\n老年代\n\n其特点是对象存活率很高，很少回收，所以很适合compacting算法（标记压缩）\n堆空间默认大致配比:\n1234原始区   存活区(from)   存活区(to)    老年代Eden    Survivor1     Survivor2    Tenured8       1             1            10\n\n标记出存活的对象， 并移动向一端以保证没有内存碎片，因为有移动，所以适合少量对象回收的情况（大量实践证明的确老年代很少有对象回收）\n\n从新生代晋升到老年代会先判断老年代的剩余空间大小，如果不够存放一个对象，则会触发Full GC\nXX:+Handle PromotionFailure是只要晋升到老年代就会触发Full GC，就算老年代还有很多内存富余也会触发，所以最好不要用\n\n永久代(方法区)\n\n一般情况下很少回收永久代，如下两种情况会触发永久代回收\n如果不想回收永久代，可以通过jvm参数设置\n甚至可以设置Eden区域对象不经过存活区直接到老年代\njvm规范的确不要求回收永久代，只是性价比很低，而且回收无用的类时条件十分苛刻；当然各个厂商的jvm实现也可以不回收；\n但是在大量使用反射、动态代理、CGLib等bytecode框架的场景，以及动态生成JSP和OSGi这类频繁自定义ClassLoader的场景都需要虚拟机具备类卸载的功能，以保证永久代不会溢出\n方法区(永久代)可回收的内容：\n\n\n常量池中的常量\n没有引用即可回收\n无用的类信息 (条件苛刻, 必须保证如下3点)\n2.1 类的所有实例都已经被回收\n2.2 加载类的ClassLoader已经被回收\n2.3 类对象的Class对象没有被引用（即没有通过反射引用该类的地方）\n\n\n\nMinor GC ，Full GC 触发条件\n\n1234567891.Minor GC触发条件 :    当Eden区满时，触发Minor GC2.Full GC触发条件 :    2.1 调用System.gc时，系统建议执行Full GC，但是不必然执行    2.2 老年代空间不足    2.3 永久代（方法区）空间不足    2.4 通过Minor GC后进入老年代的平均大小大于老年代的可用内存    2.5 由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小\n\n(3) 对象回收算法\n上面讲述了垃圾回收采用分代算法，组合使用了标记压缩和复制；\n\n问题1: 标记对象不可达是如何计算的呢？\n问题2: 释放对象又是如何做到的呢？\n问题3: finalize方法?\n\n1. finalize方法\njvm只会回收new出来的内存堆块，通过native方法调用操作系统函数创建的对象则无法回收；\nfinalize作用：\nfinalize用于在GC发生前事先调用去回收JNI调用中申请的特殊内存，下次GC发生时候保证GC后所有该对象的内存都释放了\n\n特点\n\n\n\nfinalize()是Object的protected方法，子类可以覆盖该方法以实现资源清理工作，GC在回收对象之前调用该方法\nfinalize()与C中的析构函数不是对应的。C中的析构函数调用的时机是确定的（对象离开作用域或delete掉），但Java中的finalize的调用具有不确定性\n不建议用finalize方法完成“非内存资源”的清理工作，但建议用于：① 清理本地对象(通过JNI创建的对象)；② 作为确保某些非内存资源(如Socket、文件等)\n\n\n当GC时，发现对象不可达，\n\n对象没有重写finalize方法，或者finalize已经被执行过（此方法只会被执行一次），则标记可清除\n对象重写了finalize方法，则不会直接回收，会判断对象是否执行过finalize方法 (因为此方法只允许执行一次)，没有执行过就会放入F-Queue队列，由一低优先级线程执行该队列中对象的finalize方法。执行finalize方法完毕后，GC会再次判断该对象是否可达，若不可达，则进行回收，否则，对象“复活”。\n\n所以，finalize被执行的不确定性太大，不要指望使用finalize来回收你的对象，它只会在系统进行GC的时候清理特殊内存，不受你的控制；因为它不是CC中的析构函数，而是Java刚诞生时为了使CC程序员更容易接受它所做出的一个妥协，运行代价高昂，不确定性大，无法保证各个对象的调用顺序\n\n对象通过finalize’自救’\n123456789101112131415161718192021222324252627282930313233343536373839404142public class FinalizeTest &#123;    public static FinalizeTest SAVE_HOOK = null;    public static void main(String[] args) throws InterruptedException &#123;        SAVE_HOOK = new FinalizeTest();         第一次断开强引用, 即删除 (通过finalize自救)        SAVE_HOOK = null;         建议系统Full GC        System.gc();         休眠半秒, 等待Full GC完成        Thread.sleep(500);        此时对象应该处于(reachable, finalized)状态        if (null != SAVE_HOOK) &#123;            System.out.println(Yes , I am still alive);        &#125; else &#123;            System.out.println(No , I am dead);        &#125;        第二次断开强引用, 即删除(finalize已执行过一次, 无法自救)        SAVE_HOOK = null;        System.gc();        Thread.sleep(500);        if (null != SAVE_HOOK) &#123;            System.out.println(Yes , I am still alive);        &#125; else &#123;            System.out.println(No , I am dead);        &#125;    &#125;    **     * 只会执行一次     * @throws Throwable     *    @Override    protected void finalize() throws Throwable &#123;        super.finalize();        System.out.println(execute method finalize());         只能自救一次, 重新添加引用, 第二次标记不可达时会从F-Queue队列移除        SAVE_HOOK = this;    &#125;\n2. 回收算法\n对象回收算法有两类：引用计数法，根搜索算法\n2.1 引用计数法\n有一个巨大缺陷：无法检测循环引用问题\n\n2.2 根搜索算法(GC Roots)\n根搜索是根据一系列作为root根的对象, 进行图遍历(引用链), 如果当一个对象到GC Roots没有任何引用链相连时, 则证明此对象是不可用的\n\n为GC Roots根对象\n\n可以为如下四类\n\n\nJava虚拟机栈中引用的对象\nUser user= new User()\n静态属性引用的对象\nprivate static User user = new User()\n常量引用的对象(final)\nprivate static final  User user = new User()\n本地方法栈中引用的对象(JNI)\n\n\n\n对象何时死亡\n如果遍历后对象不可达，也并非&quot;非死不可&quot;，会判断是否重写过``或者虚拟机执行过，没有则直接标记为可移除，没有则是另外一个流程\n详情请见上面 《finalize方法》小节\n参考:\n对象回收时finalize的作用\n\n三 常用垃圾收集器, jvm调优, 调优工具\n(1) 垃圾收集器(3类7种)\n大致分为3大类共7种垃圾收集器\n\n1. 新生代收集器\n\nSerial收集器（新生代单线程Client模式）\n\n\nSerial收集器是最基本、发展历史最悠久的单线程收集器\n\n是单线程的收集器\n它在进行垃圾收集时，必须暂停其他所有的工作线程\n采用复制算法进行垃圾收集\nSerial收集器依然是虚拟机运行在Client模式下默认新生代收集器\n\n\n\nParNew收集器（新生代多线程Server模式）\n\n\nSerial收集器的多线程版本\n附加说明:\n\nParNew 在单核 CPU 环境并不会比 Serial 收集器达到更好的效果\n它默认开启的收集线程数和 CPU 数量一致, 可通过-XX:ParallelGCThreads 来设置垃圾收集的线程数\n\n\n\nParallel Scavenge收集器（新生代并行回收）\n\n\n该收集器的目标是达到一个可控制的吞吐量\n\n也是基于多线程的复制算法\n提供两个参数用于精确控制吞吐量，分别是控制最大垃圾收起停顿时间的-XX:MaxGCPauseMillis，以及直接设置吞吐量大小的-XX:GCTimeRatio\n自适应调节策略 -XX:+UseAdaptiveSizePolicy，开启之后就无须设置如下3个参数:\n-Xmn (新生代大小),\n-XX:SurvivorRatio (Eden&amp;Survivor区的比例),\n-XX:PretenureSizeThreshold (晋升老年代年龄)\n和ParNew不太一样，ParNew追求的是尽可能缩短垃圾收集时用户线程的停顿时间，Parallel Scavenge的目标是达到一个可控制的吞吐量，可能单次回收时间还略高于ParNew\n\n\n2. 老年代收集器\n\nSerial Old 收集器（老年代单线程Client模式）\n\n\nSerial收集器的老年代版本\n基于单线程，标记合并算法\n与 Parallel Scavenge 收集器搭配；作为 CMS 收集器的后备预案\n\n\nParallel Old 收集器（老年代多线程）\n\n\n是Parallel Scavenge收集器的老年代版本\n使用 -XX:+UseParallelOldGC 来指定使用 Paralle Old 收集器\ndk7、jdk8 默认使用该收集器作为老年代收集器\n\n\nCMS收集器（老年代 最短回收停顿时间）\n\n很适合BS系统的服务端上\n\n老年代收集器唯一一个使用标记-清除算法的，所以有内存碎片\n\n以获取最短回收停顿时间为目标\n分为4个步骤：\n初始标记: 标记一下 GC Roots 能直接关联到的对象，速度较快\n并发标记: 进行 GC Roots Tracing，标记出全部的垃圾对象，耗时较长\n重新标记: 修正并发标记阶段引用户程序继续运行而导致变化的对象的标记记录，耗时较短\n并发清除: 用标记-清除算法清除垃圾对象，耗时较长\n耗时最长的并发标记和并发清除都是和用户线程一起工作，总体上来说，CMS收集器垃圾收集可以看做是和用户线程并发执行的\n\n\n\n缺点:\n\n对CPU资源敏感：默认分配的垃圾收集线程数为(CPU 数+3)4，随着 CPU 数量下降，占用 CPU 资源越多，吞吐量越小\n无法处理浮动垃圾： 在并发清理阶段，由于用户线程还在运行，还会不断产生新的垃圾，CMS当次无法清除；同时由于在垃圾收集阶段用户线程也在并发执行，CMS 收集器不能像其他收集器那样等老年代被填满时再进行收集，需要预留一部分空间提供用户线程运行使用。当 CMS 运行时，预留的内存空间无法满足用户线程的需要，就会出现 “ Concurrent Mode Failure ”的错误，这时将会启动后备预案，临时用 Serial Old 来重新进行老年代的垃圾收集。\n\n\n\n产生内存碎片：基于标记-清除算法\nXX:UserCMSCompactAtFullCollection开启碎片整理（默认开启），在 CMS 进行 Full GC 之前，会进行内存碎片的整理\n-XX:CMSFullGCsBeforeCompaction设置执行多少次不压缩的 Full GC 之后，跟着来一次带压缩的 Full GC（默认0）\nXX:+UserConMarkSweepGC 选择 CMS 作为老年代收集器\n\n3. 堆内存垃圾收集器\n\nG1收集器\n\nG1 收集器是 jdk1.7 才正式引用的商用收集器，现在已经成为 jdk9 默认的收集器。前面几款收集器收集的范围都是新生代或者老年代，G1 进行垃圾收集的范围是整个堆内存，它采用 “ 化整为零 ” 的思路，把整个堆内存划分为多个大小相等的独立区域（Region），在 G1 收集器中还保留着新生代和老年代的概念，它们分别都是一部分 Region\n\n每一个方块就是一个区域，每个区域可能是 Eden、Survivor、老年代，每种区域的数量也不一定。JVM 启动时会自动设置每个区域的大小（1M ~ 32M，必须是 2 的次幂），最多可以设置 2048 个区域（即支持的最大堆内存为 32M*2048 = 64G），假如设置 -Xmx8g -Xms8g，则每个区域大小为 8g2048=4M\n为了在 GC Roots Tracing 的时候避免扫描全堆，在每个 Region 中，都有一个 Remembered Set 来实时记录该区域内的引用类型数据与其他区域数据的引用关系（在前面的几款分代收集中，新生代、老年代中也有一个 Remembered Set 来实时记录与其他区域的引用关系），在标记时直接参考这些引用关系就可以知道这些对象是否应该被清除，而不用扫描全堆的数据。\nG1 收集器可以 “ 建立可预测的停顿时间模型 ”，它维护了一个列表用于记录每个 Region 回收的价值大小（回收后获得的空间大小以及回收所需时间的经验值），这样可以保证 G1 收集器在有限的时间内可以获得最大的回收效率。\n\n\n初始标记\n并发标记\n最终标记\n筛选回收\n\n(2) JVM参数调优\n垃圾收集器相关jvm参数\n\n-XX:+UseSerialGC：在新生代和老年代使用串行收集器\n-XX:+UseParNewGC：在新生代使用并行收集器\n-XX:+UseParallelGC ：新生代使用并行回收收集器，更加关注吞吐量\n-XX:+UseParallelOldGC：老年代使用并行回收收集器\n-XX:ParallelGCThreads：设置用于垃圾回收的线程数\n-XX:+UseConcMarkSweepGC：新生代使用并行收集器，老年代使用CMS+串行收集器\n-XX:ParallelCMSThreads：设定CMS的线程数量\n-XX:+UseG1GC：启用G1垃圾回收器\n\n(3) 调优工具的使用\n1. jvm调优(监控和故障处理)命令(6个)\n\n\n\n- 命令\n- 作用\n\n\n\n\njstat\n监视虚拟机运行时状态信息(类装载、内存、垃圾收集、JIT编译等运行数据)\n\n\njps\n显示指定系统内所有的HotSpot虚拟机进程\n\n\njmap\n内存映射工具, 用于生成heap dump文件\n\n\njhat\n与jmap搭配使用，用来分析jmap生成的dump，jhat内置了一个微型的HTTPHTML服务器，生成dump的分析结果后，可以在浏览器中查看; 注意，一般不会直接在服务器上进行分析，因为jhat是一个耗时并且耗费硬件资源的过程，一般把服务器生成的dump文件复制到本地或其他机器上进行分析\n\n\njstack\n生成java虚拟机当前时刻的线程快照; 目的是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等\n\n\njinfo\n实时查看和调整虚拟机运行参数\n\n\n\n12 查看gc情况 1000表示1秒展示一次, 10表示最多展示10次jstat -gc pid 1000 10","tags":[],"path":"2019/04/22/JVM/","external_link":""},{"title":"线程池","date":"2019-04-21T16:36:16.321Z","content":"类图结构\n\n线程池的工作原理\n\n原理:\n\n\n判断核心线程(core)是否已满, 没满则创建新线程, 满则步骤2\n判断队列是否已满, 没满则入队, 满则步骤3\n判断线程池(max)是否已满, 没满则继续创建线程, 满则步骤4\n按照拒绝策略拒绝任务\n\n\n线程池工作具体示意图:\n\n\nSynchronousQueue队列(补充)\n此队列实现比较复杂, 先看类继承结构和数据结构:\n\n\n\n不存储元素的队列, 每一个put操作必须等待一个take操作, 否则不能继续添加元素\n支持公平策略(双重队列-先进先出), 也支持非公平策略(双重栈–先进后出), 默认非公平策略\n双重QueueStack内部实现是单链表\n\n\n\n线程池的4种类型\n\n使用\n\n12345678 固定线程数为5的线程池Executors.newFixedThreadPool(5); 带时间策略调度的线程池Executors.newScheduledThreadPool(5); 线程可缓存的线程池Executors.newCachedThreadPool(); 单个线程的线程池Executors.newSingleThreadExecutor();\n\n内部如何构造\n\n12345678910111213141516171819202122 固定线程池: 默认线程数为5的线程池, 任务队列无界 由于队列无界, 永远不会创建第六个线程, 所以不会触发keepAliveTimenew ThreadPoolExecutor(5, 5,                0L, TimeUnit.MILLISECONDS,                new LinkedBlockingQueue&lt;Runnable&gt;()); 带时间调度的线程池: 由于队列是可扩容二叉堆(数组), 所以无界 同理, keepAliveTime是无效的new ThreadPoolExecutor(5,  Integer.MAX_VALUE,                0, NANOSECONDS,                new DelayedWorkQueue());new ThreadPoolExecutor(0, Integer.MAX_VALUE,                60L, TimeUnit.SECONDS,                new SynchronousQueue&lt;Runnable&gt;()); 单个线程池: 线程池只会有一个线程, 其他线程入队等待, 队列默认是无界的 如果队列无界, 则同理keepAliveTime是无效new ThreadPoolExecutor(1, 1,                0L, TimeUnit.MILLISECONDS,                new LinkedBlockingQueue&lt;Runnable&gt;());\n\n四种线程池的概念\n\n\n\n固定线程池 - Executors.newFixedThreadPool(5)\n核心线程数 与 最大线程数相等, 同时使用了LinkedBlockingQueue无界队列(默认无界), 所以任务永远不会被拒绝, 同理就永远不会创建多余线程;\n所以**maximumPoolSize和keepAliveTime将无效, 适合任务并发量少且稳定的情况**\n\n\n延时定时线程池 - Executors.newScheduledThreadPool(5)\nDelayQueue是基于二叉堆(数组)的可扩容队列(内部封装了一个PriorityQueue), 是基于时间先后排序的, 若time相同则根据sequenceNumber排序; 也即无界队列;\n执行效果是: 从队列取已到期的任务去执行, 完毕后重新设置任务到期时间, 再次放回DelayQueue\n由于队列无界, 同理maximumPoolSize和keepAliveTime是无效的, 适合定时或周期性任务, 可用以替代Timer(基于单线程且有并发缺陷)\n\n\n线程可缓存的线程池 - Executors.newCachedThreadPool()\n这个比较难以理解, 由于使用了SynchronousQueue同步等待队列, 它没有存储空间, 意味着请求到来就必须找到线程处理, 若没有空闲线程就新创建;\n注意:\n3.1 corePoolSize为0，maximumPoolSize为无限大，意味着线程数量可以无限大\n3.2 keepAliveTime为60S，意味着线程空闲时间超过60S就会被杀死; 这里核心线程为0, 意味着所有线程一旦从空闲算起,超时了都会被杀掉\n3.3 这是一个理论上可无限扩大的线程池, 没空闲线程就创建, 有则复用, 所以叫可缓存的线程池; 但空闲超时也会销毁, 提高效率 \n3.4 SynchronousQueue队列类似一个通道, A线程添加任务, 线程池里的子线程B获取任务执行;\n(1).若线程池没有可用线程, 则会立刻启动一个线程来执行, 同时生产者线程必须同步等待子线程的创建\n3.5 它适合耗时小的任务, 因为一旦任务耗时长, 而且任务并发量大(或波峰期)的话会创建大量线程, 任务并发波谷期会频繁GC空闲线程\n\n\n单线程池 - Executors.newSingleThreadExecutor()\n只会创建一个核心线程, 同时队列使用了LinkedBlockingQueue无界队列(不填容量默认无界),\n所以**maximumPoolSize和keepAliveTime将无效; 适合任务量极少的情况, 且由于单线程, 所以没有并发问题\n注意: Executors.newFixedThreadPool(1) 和 Executors.newSingleThreadExecutor()是等价的**\n\n\n使用一张图来示意线程池:\n\n参考: 线程池的使用\n\n线程池的重要内容\n\n\n空闲过期时间 keepAliveTime\n这个上面已经讲述过, 这个和使用的队列有界无界息息相关\n队列无界, 则无效\n队列有界, 则和最大线程数maximumPoolSize有关\n\n\n线程组 ThreadGroup\n多线程机制是由java虚拟机支持的, 目的是通过组的概念批量管理线程;\n它是树形结构:\n所以创建线程可以继承父线程组的优先级, 是否Daemon守护线程, 有唯一根节点祖先线程组; 数组初始化为4, 2倍速扩容\n本质目的是为了方便管理\n\n\n\n线程工厂接口 ThreadFactory\n位于Executors工具类\n\n\n\nDefaultThreadFactory(默认线程工厂)\n线程名遵循pool-{index}-thread-\n不继承父线程组的daemon, priority属性, 即默认创建非守护线程,同时优先级为普通\nPrivilegedThreadFactory\n通过这种方式创建出来的线程，将与创建privilegedThreadFactory的线程拥有相同的访问权限、 AccessControlContext、ContextClassLoader。如果不使用privilegedThreadFactory， 线程池创建的线程将从在需要新线程时调用execute或submit的客户程序中继承访问权限\n可以自己实现ThreadFactory接口来定制自己的线程工厂方法\n这里可以自定义线程池如何创建线程, 比如自定义的Thread类\n甚至可以在线程里加入业务逻辑, 比如日志统计\n\n\n拒绝策略\n都继承自RejectedExecutionHandler接口\n\n\n\nAbortPolicy: 直接抛出异常, 这是JDK默认策略\nCallerRunsPolicy: 如果线程池没有Shutdown, 则由提交任务的线程主动执行这个任务;\n意味着这是同步阻塞执行的;\n意味着阻(延)塞(缓)新任务的提交\n意味着不想丢弃任何一个任务\n\n\n12345public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123;    if (!e.isShutdown()) &#123;        r.run();    &#125;&#125;\n\n\n\nDiscardPolicy: 是一个空实现, 意思是丢弃当前任务\nDiscardOldestPolicy: 丢弃队头的任务(最老旧)\n这种拒绝策略要非常小心, 因为一旦任务提交过快, 会连续的丢掉最早(旧)的任务, 如果任务无关紧要则无所谓\n\n\n123456public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123;    if (!e.isShutdown()) &#123;  如果线程池没有Shutdown        e.getQueue().poll();  出(丢)队(弃)        e.execute(r);  提交当前任务    &#125;&#125;\n\n\n继承重写ThreadPoolExecutor类的beforeExecute, afterExecute, terminated等钩子方法\n这个主要用于日志统计, 运行时间之类的, 比如netty内部重写线程池\n\n\n\nbeforeExecute:\n任务执行前 (抛出运行时异常, afterExecute不会被执行)\nafterExecute\n任务执行后\nterminated\n当线程池在关闭的时候\n注意重写钩子方法后, 里面的参数必须是ThreadLocal或者同步的, 毕竟每个线程的变量不能互相影响\n\n\n\n如何设置核心线程数, 最大线程数\n\n\n\n通常情况下, corePoolSize设置为CPU核数的1倍, maximumPoolSize设置为CPU核数的两倍\n理论上的计算可以根据下面几个维度来衡量\n2.1 每秒任务数量\n2.2 每个任务执行时间\n2.3 容忍每个任务从提交到开始执行的最大响应时间\n从上面的维度可以很容易算出核心线程数, 最大线程数, 队列容量\n参考: ThreadPoolExecutor线程池参数设置技巧\n\n\n\nFutureCallable\n通过下面的接口概览, 可以看出Future和Callable是配对使用的\n本质是将主调线程阻塞, 等待子任务执行完毕得到结果\n\nCallable\n\n下面接口预览可以看到call()是带返回值的\n\nFutureTask概念\n\n它是Future接口的唯一实现, 同时它还实现了Runnable接口\n再来看构造函数:\n12public FutureTask(Callable&lt;V&gt; callable) &#123;&#125;public FutureTask(Runnable runnable, V result) &#123;&#125;\n第一个构造函数是对Callable的包装\n第二个构造函数是为了兼容之前的Runnable, 使用适配器模式使之拥有Future的特性 (可以查阅Executors内部的RunnableAdapter适配器类)\n\nFuture接口解析\n\n重点说明一下cancel, isCancelled, isDone, 其余请查阅下面的接口概览\n\n\ncancel(mayInterruptIfRunning)\n如果任务执行完毕, 则肯定是返回false;\n如果还未执行, 则肯定是返回true\n如果正在执行中则和参数有关系, 参数是true则返回true, 是false则返回false\n(注意cancel只是发出了中断, 无法确保线程真正退出)\nisCancelled\nCANCELLED, INTERRUPTING, INTERRUPTED都认为是取消状态\nisDone\nstate != NEW, 即任务执行后的任意状态都认为是已完成\n\n\n\nFutureTask源码解析\n\n1.state状态机:\n内部维护了Task的任务四种状态迁移, 初始状态为NEW\n1234567891011121314** * NEW -&gt; COMPLETING -&gt; NORMAL 正常的状态转移 * NEW -&gt; COMPLETING -&gt; EXCEPTIONAL 异常 * NEW -&gt; CANCELLED 取消 * NEW -&gt; INTERRUPTING -&gt; INTERRUPTED 中断 *private volatile int state;private static final int NEW          = 0;private static final int COMPLETING   = 1;private static final int NORMAL       = 2;private static final int EXCEPTIONAL  = 3;private static final int CANCELLED    = 4;private static final int INTERRUPTING = 5;private static final int INTERRUPTED  = 6;\n2.run\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public void run() &#123;    如果当前不是new状态，或者当前cas设置当前线程失败则返回，只有一个线程可以成功。    if (state != NEW ||        !UNSAFE.compareAndSwapObject(this, runnerOffset,                                     null, Thread.currentThread()))        return;    try &#123;        当前状态为new 则调用任务的call方法执行任务        Callable&lt;V&gt; c = callable;        if (c != null &amp;&amp; state == NEW) &#123;            V result;            boolean ran;            try &#123;                result = c.call();                ran = true;            &#125; catch (Throwable ex) &#123;                result = null;                ran = false;                setException(ex);完成NEW -&gt; COMPLETING -&gt; EXCEPTIONAL 状态转移            &#125;            执行任务成功则保存结果更新状态，unpark所有等待线程            if (ran)                set(result);        &#125;    &#125; finally &#123;        runner = null;        int s = state;        if (s &gt;= INTERRUPTING)            handlePossibleCancellationInterrupt(s);    &#125;&#125;protected void set(V v) &#123;    状态从new-&gt;COMPLETING    if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) &#123;        outcome = v;        状态从COMPLETING-》NORMAL        UNSAFE.putOrderedInt(this, stateOffset, NORMAL);  final state        unpark所有等待线程。        finishCompletion();    &#125;&#125;protected void setException(Throwable t) &#123;    if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) &#123;        outcome = t;        设置为异常状态        UNSAFE.putOrderedInt(this, stateOffset, EXCEPTIONAL);        finishCompletion();    &#125;&#125;\n3.cancel\n只有NEW才可取消, 这里比较难以理解; 因为一旦为其他状态, 则是正在执行中, 或者已完毕(异常中断已取消);\n“只有NEW才可取消”这句话表示未执行的任务永远返回true\n已完成的则永远返回false(异常中断已取消)\n注意: 状态机的状态是终态, 它无法表示过程\nCOMPLETING在这里只是瞬态, 可以直接认为: NEW-&gt;NORMAL, NEW-&gt;EXCEPTIONAL\nrun方法没有一进入就设置为COMPLETING, 而是真正完成后作为一个瞬态出现\n123456789101112131415161718192021public boolean cancel(boolean mayInterruptIfRunning) &#123;    只有任务是new的才能取消    if (state != NEW)        return false;   运行时允许中断    if (mayInterruptIfRunning) &#123;       完成new-&gt;INTERRUPTING        if (!UNSAFE.compareAndSwapInt(this, stateOffset, NEW, INTERRUPTING))            return false;        Thread t = runner;        if (t != null)            t.interrupt();        完成INTERRUPTING-&gt;INTERRUPTED        UNSAFE.putOrderedInt(this, stateOffset, INTERRUPTED);  final state    &#125;   不允许中断则直接new-&gt;CANCELLED    else if (!UNSAFE.compareAndSwapInt(this, stateOffset, NEW, CANCELLED))        return false;    finishCompletion();    return true;&#125;\n参考: FutureTask 原理\n\nThreadPoolExecutor源码解析\n参考: ThreadPoolExecutor源码解析\n\n池\n\n\n接口概览\nRunable任务接口, 无返回值的任务\n1234@FunctionalInterfacepublic interface Runnable &#123;    public abstract void run();&#125;\nCallable任务接口, 可携带返回值的任务\n123public interface Callable&lt;V&gt; &#123;    V call() throws Exception;&#125;\nFuture接口\n对于具体的Runnable或者Callable任务的执行结果进行取消、查询是否完成、获取结果。必要时可以通过get方法获取执行结果，该方法会阻塞直到任务返回结果\n123456789public interface Future&lt;V&gt; &#123;     boolean cancel(boolean mayInterruptIfRunning);     boolean isCancelled();     boolean isDone();     V get()        throws InterruptedException, ExecutionException;     V get(long timeout, TimeUnit unit)        throws InterruptedException, ExecutionException, TimeoutException;&#125;\n这里进行接口说明\n\n\nboolean cancel(boolean mayInterruptIfRunning)\ncancel取消任务; 取消成功返回true, 失败返回false;\nmayInterruptIfRunning 表示是否取消正在执行中的任务\n意思是如果任务执行完毕(取消异常都算完成), 则肯定是返回false;\n如果还未执行, 则肯定是返回true\n如果正在执行中则和参数有关系, 参数是true则返回true, 是false则返回false\n注意: 正在执行的任务就算允许被取消, 返回了true, 只是保证发送了中断信号(thread.interrupt), 但是发送了中断信号却不一定能触发线程的中断异常 (因为只有在线程处于阻塞态才会触发中断异常, 即waitjoinsleep远程或本地IO(也即数据库,文件,RPC…));\n所以cancle(true)正在执行的线程, 线程不保证一定能退出(参考线程优雅退出的两种方式)\nboolean isCancelled()\n表示任务是否被取消成功\n和上面一样, 返回true不保证线程真正退出\nboolean isDone()\n表示任务是否已经完成\n包括正常完毕执行异常任务取消, 都认为完成; 同上一样, cancle取消的任务不一定真正的退出了\nV get()\n用于获取执行结果, 但会阻塞主调方线程(一般是主线程), 直到任务执行完毕并得到结果返回后才会唤醒主线程(暂且认为是主线程, 方便理解)\n当前状态是new或者COMPLETING则等待, 其他状态甚至异常状态都认为结束, 且只有NORMALEXCEPTIONAL两种可以获取值, 其他都会抛出异常\nV get(long timeout, TimeUnit unit)\n同上, 只是指定了过期时间, 过期还未拿到结果就返回null\n\n\n1. Executor接口, 运行无返回值的新任务\n123public interface Executor &#123;    void execute(Runnable command);&#125;\n2. ExecutorService接口\n增加了管理「执行器生命周期」,「任务生命周期」的方法\n\n\nshutdownshutdownNowawaitTermination\nshutdown: 置为SHUTDOWN; 停止接收外部commit的任务; 直到队列里任务执行完毕才停止\nshutdownNow: 同上, 只是不再接收任务, 而且还会尝试中断正在执行的线程 (但是如果线程未被sleepwaitjoin…阻塞,则不会产生中断异常), 所以也有可能不会立即停止, 最后返回未执行的任务列表\nawaitTermination: 阻塞主线程, 超时后会检测线程池是否Terminated状态, 如果不是则返回false\nisShutdownisTerminated\nShutdown是主动关闭后都是此状态;\nTerminated是等所有任务都执行完毕后才是此状态\nsubmitexecute\nsubmit: 允许提交RunnableCallable任务\nexecute: 实现于Executor接口, 只能提交Runnable任务\nCallableRunnable\nCallable允许返回结果, 且可抛出异常;\nRunnable更像沙箱, 内部错误无法向外抛, 无返回值;\nCallable若要获得返回值, 调用FutureTask.get(), 此方法会阻塞主线程直到任务结束并返回结果\n\n\n12345678910111213141516171819202122232425262728293031323334public interface ExecutorService extends Executor &#123;    **     * 线程池执行器相关的管理接口     *    线程池状态SHUTDOWN,停止接收外部commit的任务;直到队列里任务执行完毕, 停止所有线程(优雅停止)    void shutdown();    同上;只是会忽略队列里等待的任务, 甚至会interrupt尝试中断正在执行的线程(但是如果线程未被sleepwaitjoin...阻塞,则不会产生中断异常),则必须等待当前正在执行的任务执行完毕, 也可能不会立即停止; 最后返回未执行的任务列表 (尝试强制停止)    List&lt;Runnable&gt; shutdownNow();     阻塞主线程指定时间, 超时后检测线程池是否Terminated(即所有任务执行完毕), 并返回布尔值 (一般用于检查是否执行完任务)    boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException;     shutdown标记(主动shutdownshutdownNow都会为true)    boolean isShutdown();     任务全部执行完毕才会Terminated=true    boolean isTerminated();    **     * 单任务的提交, 可提交RunnableCallable, 即是否有返回值     *    &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task);    &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result);     如果想要返回值, 则必须是FutureTask(实现了RunableFuture两个接口的功能)    Future&lt;?&gt; submit(Runnable task);    **     * 批量任务的提交, 只支持Callable     *    &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException;    &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException;    &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException;    &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125;\n3. ScheduledExecutorService接口\n支持了Future和定时器\n\n\n支持指定时延后执行任务, 可以是RunnableCallable\n支持指定时间间隔定期执行任务;  定时器是在一个子线程执行任务, 此处是线程池执行, 可以避免并发问题\n回顾定时器\n\n\n\n\n注意事项:\n\n\n12345678public interface ScheduledExecutorService extends ExecutorService &#123;    public ScheduledFuture&lt;?&gt; schedule(Runnable command, long delay, TimeUnit unit);    public &lt;V&gt; ScheduledFuture&lt;V&gt; schedule(Callable&lt;V&gt; callable, long delay, TimeUnit unit);    public ScheduledFuture&lt;?&gt; scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit);    public ScheduledFuture&lt;?&gt; scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit);&#125;","tags":[],"path":"2019/04/22/线程池/","external_link":""},{"title":"字节码","date":"2019-04-21T16:35:38.484Z","content":"一 字节码概要\njava编译后形成.class文件, 我们称之为字节码文件, 它可以被JIT(即时编译器)直接解释执行\n字节码技术被广泛应用, 比如Lombok, cglib, Javassist, ASM, AspectJ\nSpring AOP还扩展了两个概念: Advice增强 (织入的代码), Advisor切面(指定给什么类什么方法增强), 这个和AspectJ的理念一样\n\n\n\n- AOP类型\n- 代理形式\n- 特点\n\n\n\n\njdk1.3动态代理\n动态\njdk内置实现(InvocationHandler,Proxy), 它是基于接口方式反射实现代理类(代理模式), 所以要使用则必须实现接口, 由于使用反射, 性能最差\n\n\nASM\n动态\n低级的字节码生成工具, 近乎在于使用Javabytecode编程, 短小精悍, 性能最高, 但可读性很差, 对使用者要求过高; , 同时Kryo字节码序列化也是使用ASM\n\n\nCGLIB\n动态\n基于ASM的高级实现, 抽象出方便使用的api, 本质是对类的代理, 通过字节码实现子类并重写方法并织入新功能, 所以final类无法代理; 且生成类比较耗时, 尽量是单例对象; 运行时性能是jdk动态代理2倍 (接口和类均可代理)\n\n\nJavassist\n动态\n和CGLIB类似, 只不过CGLIB考虑了很多因素, 以及继承或包装了自己的一些类, 所以生成的字节码非常大; 而Javassist则是手工生成的字节码 (相对小很多), 相对比CGLIB快;  Spring框架目前使用的CGLIB,Hibernate已经使用Javassist代替了CGLIB; 不支持jdk5的新语法, 比如: 范型,枚举, 注解, 内部类匿名类, continuebreak, 继承(接口和类均可代理)\n\n\nAspectJ\n静态\n也是使用字节码技术, 但它是基于静态代理, 因为它采用的是编译器植入; 需要写相应的xml, 定义切面, 织入点等, 然后由aspectj的编译器来编译出新的字节码文件 (即编译期就已经生成好字节码.class文件)\n\n\n\njava自带序列化字节码遵循如下规范\n图1\n\n参考:\n一文让你明白Java字节码\n参考: 动态代理解释-JDK,CGLIB,JAVASSIST,ASM\n(1) Bean拷贝复制\n一般Apache的效果最差, 其次是Spring的工具类, 效果最好的是cglib的BeanCopier\n\n\n\n- 拷贝方式\n- 特点\n\n\n\n\nApache BeanUtil.copyProperties\n效率最差\n\n\nApache PropertyUtils.copyProperties\n效率比BeanUtil好, 10个对象拷贝大概相差10倍, 1万个对象相差3倍\n\n\nSpring BeanUtils.copyProperties\n1万个对象拷贝比PropertyUtils还低一半\n\n\nCGLIB BeanCopier.create\n效率最高, 使用了ASM字节码技术, 比Apache BeanUtil低200倍\n\n\n\n执行效率对比\n12345678910111213141516171819202122232425############### 性能测试10个对象拷贝 ############### Apache [BeanUtil.copyProperties]开始进行测试 Apache [BeanUtil.copyProperties] 耗时173毫秒 -------------------------------------------- Apache [PropertyUtils.copyProperties]开始进行测试 Apache [PropertyUtils.copyProperties] 耗时17毫秒 -------------------------------------------- springframework [BeanUtils.copyProperties]开始进行测试 springframework [BeanUtils.copyProperties] 耗时276毫秒 -------------------------------------------- CGLIB [BeanCopier.create]开始进行测试 CGLIB [BeanCopier.create] 耗时0毫秒 ############### 性能测试10000个对象拷贝 ############### Apache [BeanUtil.copyProperties]开始进行测试 Apache [BeanUtil.copyProperties] 耗时399毫秒 -------------------------------------------- Apache [PropertyUtils.copyProperties]开始进行测试 Apache [PropertyUtils.copyProperties] 耗时122毫秒 -------------------------------------------- springframework [BeanUtils.copyProperties]开始进行测试 springframework [BeanUtils.copyProperties] 耗时60毫秒 -------------------------------------------- CGLIB [BeanCopier.create]开始进行测试 CGLIB [BeanCopier.create] 耗时2毫秒\n(2) java序列化\n序列化框架很多, 有使用字节码的, 也有使用json的, 有的跨平台, 有的局限于java\n\n\n针对java语言\nKryo,FST, 基于JSON的三种\n跨语言\nProtoBuf,Thrift,Hessian,Avro,Protostuff,MsgPack\n\n\n下面对比下各种序列化框架的优缺点:\n\n\n\n- 序列化方式\n- 优点\n- 缺点\n\n\n\n\njava序列化\n没啥优点, 除了无须引用额外的三方包, 全是缺点\n1.无法跨语言(内部私有协议); 2.序列化码流太大, 很多无用信息(序列化前后5倍差距); 3.性能太低\n\n\nProtobuf (谷歌)\n1.结构化数据存储格式(xml,json等)2.高性能编解码技术3.语言和平台无关, 扩展性好4.支持java,c++,python三种语言\n需要编写Protobuf文件生成三方代码, 用以屏蔽协议问题, 导致使用稍难\n\n\nThrift (脸书)\n1.主流语言基本都支持2.很适合内部大型数据交换, 比如RPC; 对于Json和xml在性能有很大提升3.支持三种典型的编码方式(通用二进制编码,压缩二进制编码,优化的可选字段压缩编解码)\n同Protobuf一样, 需要编写thrift文件, 导致使用稍难\n\n\nkryo\n使用了ASM, 速度快, 序列化后体积小 (变长存储特性)\n跨语言很复杂, 不支持缓存功能(如果class增删字段则会反序列化报错), 后面进行了兼容 Kryo官方文档-中文翻译\n\n\nhessian\n支持跨语言\n较慢\n\n\nfst\n完全兼容JDK序列化协议, 序列化速度大概是JDK的4-10倍，大小是JDK大小的13左右\n\n\n\nJackson, Gson(谷歌), FastJson(阿里)\nJackson不建议使用, Gson功能最全面且无可挑剔,性能上稍弱于阿里的FastJson; 若同时对性能和正确性都有要求, 建议Bean-&gt;JSON使用Gson, JSON-&gt;Bean使用FastJson\n1.Jackson对于复杂集合如Map,List会出现问题, 复杂类型转换JSON也非标准格式2.Gson目前功能最全, 且无可挑剔, 性能上稍弱于FastJson3.FastJson复杂类型的Bean转换Json上会出现一些问题, 可能会出现引用的类型, 导致Json转换出错, 需要制定引用; 但是parse的速度是最高的\n\n\n\n二 JIT与AOT\n\n\n\n- 编译方式\n- 优缺点\n\n\n\n\nAOT静态编译\nC, C++采用静态编译为机器码, cpu可以直接执行\n\n\nJIT动态编译\njava号称&quot;一次编写，随处运行&quot;, 但本地静态编译是特定于平台的, 需要考虑一种能兼顾跨平台+高性能的编译方式; \n\n\n\nJIT特性\n\n\n编译线程与应用线程分离互不影响\n编译过程在程序执行时, 且以方法为单位进行编译; 所以可以保证平台无关性 (不同平台编译出来也会有所不同, 但差异已经封装在了动态编译中)\n通过周期性地对线程取样找出频繁执行的方法, 用来存储程序的此次执行中可能不会改变的动态值 (前期可能会慢一些, 长时间运行则会很快)\n运行时编译会非常耗时, 因为编译代码耗时将计入程序执行时间, 所以通常只是集中编译少量的热方法\n\n\n参考:\nJIT（动态编译）和AOT（静态编译）编译技术比较\n三 Javassist与CGLIB\n(1) Javassist手工实现动态代理\n有两种实现方式\n\n\n使用javassist内部的ProxyFactory, 此种方式可以代理接口和类\n手工实现类似JDK动态接口代理\n\n\n方式1 :\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162** * 代理工厂方式创建动态代理 (代理的是class, interface的方法也可以代理) * @param &lt;T&gt; *public class JavassistProxyFactory&lt;T&gt; &#123;    private T target;    public JavassistProxyFactory(T target) &#123;        this.target = target;    &#125;    public T getProxy() throws InstantiationException, IllegalAccessException &#123;         代理工厂        ProxyFactory proxyFactory = new ProxyFactory();         设置需要创建子类的父类        proxyFactory.setSuperclass(target.getClass());        **         * 定义一个拦截器。在调用目标方法时，Javassist会回调MethodHandler接口方法拦截，         * 来实现你自己的代理逻辑，         * 类似于JDK中的InvocationHandler接口。         *        proxyFactory.setHandler(new MethodHandler() &#123;            **             * @param self        self为由Javassist动态生成的代理类实例，             * @param thisMethod  thisMethod为当前要调用的方法             * @param proceed     proceed 为生成的代理类对方法的代理引用。             * @param args        Object[]为参数值列表，             * @return            从代理实例的方法调用返回的值。             *             * 其中，proceed.invoke(self, args);             * 调用代理类实例上的代理方法的父类方法（即实体类ConcreteClassNoInterface中对应的方法）             *             *            public Object invoke(Object self, Method thisMethod, Method proceed, Object[] args) throws Throwable &#123;                System.out.println(--------------------------------);                System.out.println(代理类全路径限定名 + self.getClass());                class com.javassist.demo.A_$$_javassist_0                System.out.println(要调用的方法名:  + thisMethod.getName());                System.out.println(代理类方法名:  + proceed.getName());                System.out.println(开启事务(统一织入钩子)-------);                Object result = proceed.invoke(self, args);                下面的代码效果与上面的相同, 本质是一个是目标对象本身invoke, 一个是代理对象invoke, 效果一样                Object result = thisMethod.invoke(target, args);                System.out.println(执行结果为:  + JSON.toJSONString(result));                System.out.println(提交事务(统一织入钩子)-------);                return result;            &#125;        &#125;);         通过字节码技术动态创建子类实例        return (T) proxyFactory.createClass().newInstance();    &#125;&#125;\n方式2 :\n12345678910111213 1. 定义工厂接口public interface IProxyFactory &#123;    &lt;T&gt; T getProxy(Object target, InvocationHandler handler) throws Throwable;&#125; 2. 定义工厂实现public class ProxyFactory implements IProxyFactory &#123;    @Override    public &lt;T&gt; T getProxy(Object target, InvocationHandler handler) throws Throwable &#123;        return (T) ProxyGenerator.newProxyInstance(Thread.currentThread().getContextClassLoader(),                target.getClass(), handler);    &#125;&#125;\nProxyGenerator生成字节码文件\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156 3. 生成字节码文件的类public class ProxyGenerator &#123;    private static final AtomicInteger counter = new AtomicInteger(1);    private static ConcurrentHashMap&lt;Class&lt;?&gt;, Object&gt; proxyInstanceCache = new ConcurrentHashMap&lt;&gt;();    public static Object newProxyInstance(ClassLoader classLoader, Class&lt;?&gt; targetClass, InvocationHandler invocationHandler)            throws Exception &#123;        if (proxyInstanceCache.containsKey(targetClass)) &#123;            return proxyInstanceCache.get(targetClass);        &#125;        ClassPool pool = ClassPool.getDefault();        生成代理类的全限定名        String qualifiedName = generateClassName(targetClass);         创建代理类        CtClass proxy = pool.makeClass(qualifiedName);        接口方法列表        CtField mf = CtField.make(public static java.lang.reflect.Method[] methods;, proxy);        proxy.addField(mf);        CtField hf = CtField.make(private  + InvocationHandler.class.getName() +  handler;, proxy);        proxy.addField(hf);        CtConstructor constructor = new CtConstructor(new CtClass[]&#123;pool.get(InvocationHandler.class.getName())&#125;, proxy);        constructor.setBody(this.handler=$1;);        constructor.setModifiers(Modifier.PUBLIC);        proxy.addConstructor(constructor);        proxy.addConstructor(CtNewConstructor.defaultConstructor(proxy));         获取被代理类的所有接口        List&lt;Class&lt;?&gt;&gt; interfaces = ClassUtils.getAllInterfaces(targetClass);        List&lt;Method&gt; methods = new ArrayList&lt;&gt;();        for (Class cls : interfaces) &#123;            CtClass ctClass = pool.get(cls.getName());            proxy.addInterface(ctClass);            Method[] arr = cls.getDeclaredMethods();            for (Method method : arr) &#123;                int ix = methods.size();                Class&lt;?&gt; rt = method.getReturnType();                Class&lt;?&gt;[] pts = method.getParameterTypes();                StringBuilder code = new StringBuilder(Object[] args = new Object[).append(pts.length).append(];);                for (int j = 0; j &lt; pts.length; j++) &#123;                    code.append( args[).append(j).append(] = ($w)$).append(j + 1).append(;);                &#125;                code.append( Object ret = handler.invoke(this, methods[ + ix + ], args););                if (!Void.TYPE.equals(rt))                    code.append( return ).append(asArgument(rt, ret)).append(;);                StringBuilder sb = new StringBuilder(1024);                sb.append(modifier(method.getModifiers())).append( ).append(getParameterType(rt)).append( ).append(method.getName());                sb.append(();                for (int i = 0; i &lt; pts.length; i++) &#123;                    if (i &gt; 0)                        sb.append(,);                    sb.append(getParameterType(pts[i]));                    sb.append( arg).append(i);                &#125;                sb.append());                Class&lt;?&gt;[] ets = method.getExceptionTypes();    方法抛出异常                if (ets != null &amp;&amp; ets.length &gt; 0) &#123;                    sb.append( throws );                    for (int i = 0; i &lt; ets.length; i++) &#123;                        if (i &gt; 0)                            sb.append(,);                        sb.append(getParameterType(ets[i]));                    &#125;                &#125;                sb.append(&#123;).append(code.toString()).append(&#125;);                CtMethod ctMethod = CtMethod.make(sb.toString(), proxy);                proxy.addMethod(ctMethod);                methods.add(method);            &#125;        &#125;        proxy.setModifiers(Modifier.PUBLIC);        Class&lt;?&gt; proxyClass = proxy.toClass(classLoader, null);        proxyClass.getField(methods).set(null, methods.toArray(new Method[0]));         持久化class到硬盘        proxy.writeFile(Usersappleideadoyo-learnsrcmainjavacomdoyolearnproxyjavassistthree_jdk_way);        Object instance = proxyClass.getConstructor(InvocationHandler.class).newInstance(invocationHandler);        Object old = proxyInstanceCache.putIfAbsent(targetClass, instance);        if (old != null) &#123;            instance = old;        &#125;        return instance;    &#125;    private static String modifier(int mod) &#123;        if (Modifier.isPublic(mod)) return public;        if (Modifier.isProtected(mod)) return protected;        if (Modifier.isPrivate(mod)) return private;        return ;    &#125;    **     * 数组类型返回 String[]     *     * @param c     * @return     *    public static String getParameterType(Class&lt;?&gt; c) &#123;        if (c.isArray()) &#123;   数组类型            StringBuilder sb = new StringBuilder();            do &#123;                sb.append([]);                c = c.getComponentType();            &#125; while (c.isArray());            return c.getName() + sb.toString();        &#125;        return c.getName();    &#125;    private static String asArgument(Class&lt;?&gt; cl, String name) &#123;        if (cl.isPrimitive()) &#123;            if (Boolean.TYPE == cl)                return name + ==null?false:((Boolean) + name + ).booleanValue();            if (Byte.TYPE == cl)                return name + ==null?(byte)0:((Byte) + name + ).byteValue();            if (Character.TYPE == cl)                return name + ==null?(char)0:((Character) + name + ).charValue();            if (Double.TYPE == cl)                return name + ==null?(double)0:((Double) + name + ).doubleValue();            if (Float.TYPE == cl)                return name + ==null?(float)0:((Float) + name + ).floatValue();            if (Integer.TYPE == cl)                return name + ==null?(int)0:((Integer) + name + ).intValue();            if (Long.TYPE == cl)                return name + ==null?(long)0:((Long) + name + ).longValue();            if (Short.TYPE == cl)                return name + ==null?(short)0:((Short) + name + ).shortValue();            throw new RuntimeException(name +  is unknown primitive type.);        &#125;        return ( + getParameterType(cl) + ) + name;    &#125;    private static String generateClassName(Class&lt;?&gt; type) &#123;        return String.format(%s$Proxy%d, type.getName(), counter.getAndIncrement());    &#125;&#125;\n(2) CGLIB动态代理使用\n代理的是class\n123456789101112131415161718192021222324252627public class CglibProxy implements MethodInterceptor&#123;\tprivate Enhancer enhancer = new Enhancer();\tpublic Object getProxy(Class&lt;?&gt; clazz) &#123;\t\t设置为哪个类产生代理(子类)\t\tenhancer.setSuperclass(clazz);\t\tenhancer.setCallback(this);\t\t 针对接口\t\tenhancer.setInterfaces(new Class[]&#123;IDBQuery.class&#125;);\t\treturn enhancer.create();\t&#125;\t**\t * object 目标类实例\t * method 目标方法反射对象\t * args   方法参数\t * proxy  代理类实例\t *\t@Override\tpublic Object intercept(Object object, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123;\t\tSystem.out.println(日志开始...);\t\tObject result = proxy.invokeSuper(object, args);\t\tSystem.out.println(日志结束...);\t\treturn result;\t&#125;&#125;\n测试类\n12345678public class Client &#123;\tpublic static void main(String[] args) &#123;\t\tCglibProxy proxy = new CglibProxy();\t\t Train为需要代理的类, 随意定义即可\t\tTrain train = (Train)proxy.getProxy(Train.class);\t\ttrain.move();\t&#125;&#125;\n四 ClassLoader\n\n\n\n首先通过java源码编译器, 通过词法分析语法分析语义分析形成抽象语法树, 最后通过字节码生成器生成.class字节码文件\n载入是通过ClassLoader或Class.forName()将字节码文件加载到jvm\n链接 (分为三步)\n3.1 验证 :\n主要验证字节码是否符合java语言规范和jvm规范, 比较耗时 (文件格式验证, 元数据验证, 字节码验证, 符号引用验证)\n3.2 准备 :\n正式为类变量分配内存并设置类变量初始值的阶段, 都将在方法区中进行分配; 注意方法区内存分配的仅包括类变量(static 修饰的变量),而不包括实例变量; 初始值“通常情况”下是数据类型的零值, 比如\nstatic int value = 12, 初始化时为0, 但是特殊情况下如: static final int value = 12, 编译时javac将会为value生成ConstantValue属性，在准备阶段虚拟机就会根据ConstantValue的设置将value设置为12\n3.3 解析 :\n把类常量池中所有的符号引用转为直接引用\n初始化\n(1).&lt;clinit&gt;所有的类变量初始化语句和类型的静态初始化器\n意味着只能是static静态的才会被初始化, 如上面在准备阶段初始化为零值, 这里则会被初始化为12; 触发的时机:\n1.创建某个类的新实例时new, 反射, 克隆 或 反序列化;\n2.调用某个类的静态方法时;\n3.使用某个类或接口的静态字段或对该字段(final 字段除外)赋值时\n4.调用java的某些反射方法时\n5.初始化某个类的子类时\n6.在虚拟机启动时某个含有 main() 方法的那个启动类\n也并非所有类都会拥有一个方法 (没有静态初始化语句, 声明了类变量但没有初始化, 仅仅有final的类变量且是字面量常量 )\n(2).&lt;init&gt;是对象的初始化器\n1.new,2.反射,3.克隆,4.反序列化四种情况会实例化类\n\n\n(1) 类加载机制与初始化\n\n这里特别需要说明类初始化的顺序 (其实通过上面&lt;clinit&gt;, &lt;init&gt;的讲解已经能推导)\n类变量或静态变量(代码块)首先会初始化, 其次是&lt;init&gt;实例化\n\n无父类(继承关系)\n\n\n静态变量初始化\n静态代码块\n非静态变量初始化\n非静态代码块\n构造器\n\n\n有继承关系\n\n\n父类静态变量\n父类静态代码块\n子类静态变量\n子类静态代码块\n父类非静态变量\n父类非静态代码块\n父类构造器\n子类非静态变量\n子类非静态代码块\n子类构造器\n\n注意:\n\n非法前置引用 (Illegal forward reference)\n变量必须定义在代码块前\n\n123456789101112131415public class InitializationOrderTest2 &#123;    static &#123;        a = 2;        System.out.println(a);  非法前置引用    &#125;    static &#123;        a = 3;    &#125;    static int a = 1;    public static void main(String[] args) &#123;        a++;        System.out.println(a);    &#125;&#125;\n@PostConstruct\n它是jdk5增加了两个影响Servlet生命周期的注解\n它用于解决@Autowred, @Resource注入发生在构造函数之后\n如果想在对象构造时初始化某些操作, 由于服务未注入导致无法完成, @PostConstruct则保证在注入之后, init之前\n如下图 :\n\n\n后置定义变量可能造成意外\n\n12345678910111213public class InitializationOrderTest2 &#123;    static &#123;        a = 2;    &#125;    static &#123;        a = 3;    &#125;    static int a = 1;    public static void main(String[] args) &#123;        a++;        System.out.println(a);  值不是3, 而是1    &#125;&#125;\n(2) ClassLoader与Class.forName()区别\n\nClass.forName(&quot;className&quot;)\n\n实际上调用的是forName0(className, true, ClassLoader.getClassLoader(caller), caller);\n意味着 需要初始化\n12345678** * 这是一个native本地方法 * @name       需要加载的类的全路径限定名 * @initialize 是否初始化 * @loader     对应的类加载器 * @caller     调用者类, caller = Reflection.getCallerClass(); *Class.forName0(name, initialize, loader, caller)\n\nClassLoader.laodClass(&quot;className&quot;)\n\n实际调用的是ClassLoader.loadClass(name, false);\n意味着 无需link链接 (验证,准备,解析), 仅仅加载到jvm, 更别提下一步的初始化\n123456** * * @name    需要加载的类的全路径限定名 * @resolve 否进行链接(验证,准备,解析) *ClassLoader.loadClass(String name, boolean resolve)\n(3) java安全模型\n在 Java 中将执行程序分成本地和远程两种，本地代码默认视为可信任的，而远程代码则被看作是不受信的。对于授信的本地代码，可以访问一切本地资源。而对于非授信的远程代码在早期的 Java 实现中，安全依赖于沙箱 (Sandbox) 机制。\n(1). 远程代码沙箱(SandBox)模式\n\n(2). 远程代码带安全策略的沙箱(SandBox)模式\n\n(3). 本地代码也带安全策略的沙箱(SandBox)模式\n\n(4). 引入了域 (Domain)\n\n(5). 如何安全控制\n\n\n调用链 : MethodA-&gt;MethodB-&gt;MethodC\n如果doPrivileged在MethodB中, 会跳过MethodC的权限检查\n如果doPrivileged在MethodA中, 会跳过MethodB和MethodC的权限检查\n\n\njava栈如下\n123456789101112 每个线程会创建一个Stack, 栈元素称为栈帧, 其实就是方法 权限检查是和调用链相反的, 即从栈顶开始 如果[MethodB]带有doPrivileged, 则[MethodC]跳过检查 如果[MethodA]带有doPrivileged, 则[MethodB], [MethodC]跳过检查-----------| MethodC |   栈顶-----------| MethodB |   doPrivileged, 表明[MethodC]跳过检查-----------| MethodA |   doPrivileged, 表明[MethodB], [MethodC]跳过检查-----------| ... ... |\n(6). 特殊情况\n\n\n访问控制上下文的继承问题\n总之, 要保证让子线程自动继承父线程的安全性上下文，这样子线程中的后续 AccessController.checkPermission 调用就会考虑所继承的父线程的安全特性\n安全检查横跨不同上下文\n使用AccessControlContext acc = AccessController.getContext();\n反射生成代码提升代码权限漏洞\n对象A -&gt; 反射1次(A’) -&gt; 反射2次(A’’)\n注意反射相关类权限很高, 反射两次导致A’看到的是A’的权限 (权限已经变得很高);\n@CallerSensitive注解是为了解决上面的问题, 以前反射只检查固定深度的调用者的类, 看它有没有特权; 现在是只要标记了@CallerSensitive注解就会忽略中间多次反射出来的类, 最终找到对象A为Caller\n\n\n(4) Reflection.getCallerClass()与@CallerSensitive\n首先来看一段代码, 里面涉及两个重要的东西\n1.@CallerSensitive\n2.Class&lt;?&gt; caller = Reflection.getCallerClass()\n12345678@CallerSensitivepublic static Class&lt;?&gt; forName(String className)            throws ClassNotFoundException &#123;     先通过反射，获取调用进来的类信息，从而获取当前的 classLoader    Class&lt;?&gt; caller = Reflection.getCallerClass();     调用native方法进行获取class信息    return forName0(className, true, ClassLoader.getClassLoader(caller), caller);&#125;\n\n\n\nReflection.getCallerClass()\n获取其最终调用者的类(因为有可能是反射行为)\n若是反射行为, 配合@CallSensitive用来找到真正发起反射请求的类, 用以避免双重反射权限提供漏洞\n注意 : 只有BootStrapClassLoader, ExtentionClassLoader加载的类才允许调用此方法, 意味着用户自定义的一些类中无法调用此方法\nReflection.getCallerClass(int i)\n若为&lt;0, 返回Reflection自身\n若为1, 返回调用者类\n…\n此方法已过时, 因为查找固定深度的调用者会产生双重反射提升权限的漏洞, 可配合@CallerSensitive来解决\n\n\n五 热部署与热加载\n都是通过ClassLoader特性来加载\n\n\n\n- 方式\n- 特点\n\n\n\n\n热加载\n1.在容器启动的时候起一条后台线程, 定时的检测类文件的时间戳变化2.如果变化了则重新加载此类, 不会全部加载, 也不会清空内存整个应用重启3.一般没有应用, 因为直接修改jvm中字节码的方式是难以监控的, 同时对注重安全的应用这种方式是不会使用的, 这好比给飞行中的飞机更换发动机\n\n\n热部署\n使用也很少, springboot中spring-boot-devtools和springloaded就是其中的应用, 虽然只是加载变化的类(使用了两个ClassLoader), 但是应用是需要重启的\n\n\n\n\n什么是双亲委派机制?\n\n双亲委托机制, 当jvm要加载Test.class的时候\n\n\n首先到CustomClassLoader自定义加载器查找, 若已加载过则返回字节码\n若没有加载过，则询问上一层加载器(AppClassLoader)是否已经加载过Test.class\n若没有, 则询问上一层加载器(ExtClassLoader)是否已经加载过\n若没有, 则询问上一层加载器(BoopStrapClassLoader)是否已经加载过\n若都没有加载, 则到自己指定类加载路径下(“sun.boot.class.path”)查看是否有Test.class字节码, 有则返回, 没有则通知下一层加载器ExtClassLoader到自己指定的类加载路径下(java.ext.dirs)查看\n依次类推, 直到CustomClassLoader自定义类加载器指定classpath下还未找到Test.class, 则抛出异常ClassNotFoundException\n\n双亲委派优势是什么?\n\n\n加载的类随着各自的类加载器一起具备了优先级的层次关系, 可以避免重复加载相同的类\n可以防止外部篡改内部核心类, 比如外部想加载自己的java.lang.Integer, 经过层层委派发现已有, 则直接返回;\n如果在类路径下没找到, 则层层通知下一级加载器在各自类路径下进行查找, 最后都没找到则抛出异常ClassNotFoundException\n\n\n四个重要的方法(loadClassfindClassdefineClassresolveClass)\n12345678910111213141516171819202122232425262728293031323334protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123;    synchronized (getClassLoadingLock(name)) &#123;         首先, 查看类是否已被加载        Class&lt;?&gt; c = findLoadedClass(name);        if (c == null) &#123;            long t0 = System.nanoTime();            try &#123;                 如果找不到, 则委托给父类加载器去加载                if (parent != null) &#123;                    c = parent.loadClass(name, false);                &#125; else &#123;                     如果没有父类, 则委托给启动加载器去加载                    c = findBootstrapClassOrNull(name);                &#125;            &#125; catch (ClassNotFoundException e) &#123;            &#125;             如果都没有找到，则通过自定义实现的findClass去查找并加载 (需要自己重写findClass方法)            if (c == null) &#123;                long t1 = System.nanoTime();                c = findClass(name); sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0);                sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1);                sun.misc.PerfCounter.getFindClasses().increment();            &#125;        &#125;         是否需要在加载时进行解析 (链接的第三阶段)         否则就只能在实例化对象时进行解析和初始化        if (resolve) &#123;            resolveClass(c);        &#125;        return c;    &#125;&#125;\n在jdk1.2之后建议重写findClass而非loadClass\nfindClass()方法是在loadClass()方法中被调用的, 当loadClass()方法中父加载器加载失败后, 则会调用自己的findClass()方法来完成类加载, 这样就可以保证自定义的类加载器也符合双亲委托模式;\n需要注意的是findClass()默认是抛出ClassNotFoundException异常, 需要重写自己的逻辑, 一般是配合defineClass一起使用\n一个重写findClass简单例子\n1234567891011protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123;       获取类的字节数组, 这个需要自己实现       除非自定义ClassLoader继承于URLClassLoader(通过URLClassPath类负责找到要加载的字节码, 再读取成字节流, 默认已实现好了)      byte[] classData = getClassData(name);      if (classData == null) &#123;          throw new ClassNotFoundException();      &#125; else &#123;          使用defineClass生成class对象        return defineClass(name, classData, 0, classData.length);    &#125;&#125;\n通过上面代码示例, 可以看出如果继承于抽象类ClassLoader, 在重写findClass时, 需要自己手工实现类的字节码流获取, 所以经常我们重写ClassLoader是继承于URLClassLoader, 这些工作它已经帮我们做好了;\n在sun.misc.Launcher类里, 除了C++代码写的BootStrapClassLoader, 其他两个jdk自带的类加载器ExtClassLoader, AppClassLoader都继承于URLClassLoader, 并且最终都是调用ClassLoader的loadClass;  这表明它们都遵循双亲委托模型\nclass对象相等的两个必要条件\n\n\n类的完整类名必须一致，包括包名\n加载这个类的ClassLoader(指ClassLoader实例对象)必须相同\n\n\n由于不同的ClassLoader实例对象都拥有不同的独立的类名称空间，所以加载的class对象也会存在不同的类名空间中；\n一般我们不会重写也不建议重写loadClass，而loadClass会检查所有类加载器的缓存，同类名则会阻止再次加载，所以不会出现第二个条件的限制，一般只要类全路径限定名相同，默认认为是同一个类实例\n自定义类加载器\n\n\n继承于ClassLoader抽象类\n需要自己实现findClass的加载逻辑, 以及class文件加载转换成字节码流的代码\n继承于URLClassLoader\n可以免去上面的步骤, 因为内置实现好了\n\n\n意义与应用场景\n\n\n当class文件不在ClassPath路径下，默认系统类加载器无法找到该class文件\n当一个class文件是通过网络传输并且可能会进行相应的加密操作时，需要先对class文件进行相应的解密后再加载到JVM内存中\n当需要实现热部署功能时(一个class文件通过不同的类加载器产生不同class对象从而实现热部署功能)\n\n\n双亲委派模型的破坏者-线程上下文类加载器\nSPI(服务提供者接口), 类似一种门面模式, 由jdk提供统一服务接口, 具体实现则由第三方公司提供具体服务实现, 比如 :\nJDBC, JNDI, Slf4j(这个只能算门面模式)\n问题在于服务接口在rt.jar中, 由BootstrapClassLoader加载, 但第三方公司的实现导致其他类加载器都无法加载 (classpath问题), 所以出现了contextClassLoader上下文类加载器\n它默认情况下是AppClassLoader, 可通过ClassLoader.getSystemClassLoader()得到, 但是在不同环境, 比如javaweb容器tomcat,jetty...或者CS模式的EJB容器JBoss, 它们的线程上下文类加载器并非默认的AppClassLoader,\n所以很少直接使用ClassLoader.getSystemClassLoader(), 可以认为不同容器使用的默认类加载器可能是不同的\ncontextClassLoader永远取得的是当前系统默认的类加载器, jdk默认是AppClassLoader, 但是不同容器可能会使用自定义的类加载器作为默认加载器;\n所以尽量不使用ClassLoader.getSystemClassLoader()\n同时上下文加载器的加载方式破坏了“双亲委派模型”, 如下图：\n\n总结\n\n关键类\nClassLoader 下面三个jdk自带类加载器的顶级父类\nURLClassLoader 它默认实现了类的字节码流获取\nExtClassLoader 继承于URLClassLoader, 且未重写loadClass\nAppClassLoader 同ExtClassLoader\nLauncher 是定义ExtClassLoader, AppClassLoader的地方\n自定义类加载器几个关键方法\nloadClass 无需重写, 意味着必须遵循双亲委托模型\nfindClass 需要重写, 自定义类加载器的重点方法\ndefineClass 位于ClassLoader, 创建类的方法, 调用了native代码\nresolveClass 位于ClassLoader, 表示是否解析(链接第三阶段)\njdk类加载器关系\n启动类加载器，由C++实现，没有父类\n拓展类加载器(ExtClassLoader)，由Java语言实现，父类加载器为null\n系统类加载器(AppClassLoader)，由Java语言实现，父类加载器为ExtClassLoader\n自定义类加载器，父类加载器肯定为AppClassLoader\ncontextClassLoader 线程上下文类加载器, 默认是AppClassLoader, 但不同容器可能使用的默认类加载器不一定相同, 可能是自己实现的, 所以尽量不使用ClassLoader.getSystemClassLoader(), 避免不必要的问题\n\n附加说明\n\nEJB\n\n这是CS模式, 客户端软件通过RMI这种远程调用方式直接调用服务端代码, 它是基于RMI远程调用\n现代的服务通信模型基本经历了RMI, WebService, RPC, JMS的历程, 现在的对外服务基本上基于RESTful接口(基于Http), 内部微服务之间使用RPC通信(JSONByte)\n\n远程调用\n\n1.RMI(EJB的通信基础)\n它是基于面向对象的java-rpc, 只支持java, 本质上传递的是对象, 通过生成的代理类可以进行编译期检查\n\n\ntcp协议\n传递可序列化java对象\n由于是对象, 所以可以通过代理类进行静态检查\n缺陷\n只支持java, 无法跨平台; 对象传输太大, 效率不高\n\n\n2.WebService\n它是基于Http的, 只不过消息传递方式是基于XML结构\n\n\nHttp协议\n传递XML格式数据\n封装SOAP协议\nWSDL描述\n缺陷\n基于XML格式, 包装与解析太过繁琐, 效率低下\n\n\n3.JMS\n它是基于消息的异步通知模型, 不是同步应答模型\n它是java接口规范, 和JMX, SPI等是一个级别的概念\n比如第三方的消息队列ActiveMQ, 就是根据JMS规范写的实现\n4.RPC\n\n\nTCP协议, 也有使用Http2协议的\n传递byte字节码数据, 也有基于JSON格式字符串数据的\n跨平台, 数据传输小, 数据发送与解析也比较高效\n所以现代RPC基本取代了RMI, Restful基本取代了WebService\n\n\n","tags":[],"path":"2019/04/22/字节码/","external_link":""},{"title":"concurrent并发包讲解(二)","date":"2019-04-21T16:23:39.188Z","content":"知识要点\n写此篇只记录一些自己觉得比较重要的知识点, 其余查阅之前的篇幅\n\n\n\n分类\n知识点\n\n\n\n\nThreadRunable\n线程状态机  joinwait  sleep  suspendresume  interuptinterruptedisInterrupted  notifynotifyAll  yield \n\n\njava内存模型\n原子性CAS  有序性指令重排  可见性volatile(内存屏障)  Happen-Before\n\n\nAtomic包CAS\nAtomicInteger  AtomicReference  AtomicStampedReference  AtomicMarkableReference  AtomicIntegerArray, AtomicReferenceArray   AtomicIntegerFieldUpdater  LockFreeVector LongAdder(JDK8)  ABA问题 \n\n\nsyncthroizedwaitnotify\n常用并发控制\n\n\nConcurrent并发包\nReentrantLock Condition Semaphore ReadWriteLock,ReentrantReadWriteLock CountDownLatch CyclicBarrier CountDownLatchForkJoinAQSLockSupport\n\n\nAmino(并发线程组件)\nMaster-Worker模式  Map-reduce模式  Divide and conquer模式  Pipeline模式 \n\n\nJCTool\n增强型数据结构\n\n\nGuava Concurrent\n谷歌并发编程工具包\n\n\nDisruptor\n高并发循环事件队列\n\n\nReactor与Proactor\n涉及操作系统IO模型, 同步与异步阻塞与非阻塞\n\n\n\nThreadRunnable\nThread只能单继承, Runnable可以多继承, 内部都是重写run()方法\n状态机\n线程有6种状态, 请查阅java多线程基础（一）\n12345678public enum State &#123;    NEW,      初始态    RUNNABLE, 就绪态运行态    BLOCKED,  阻塞态    WAITING,  等待态    TIMED_WAITING, 超时等待态    TERMINATED; 终止态&#125;\nRUNNABLE状态在jvm里可以认为是运行态, 但对于操作系统来说, RUNNABLE=Runnable+Running; 只有分配到cpu时间片才叫Running, 对于java来说不用关心\n同时线程有三个队列:\n1. 就绪队列:\n处于Runnable状态, 随时等待cpu调度; 调用yelid, sleep到期, join等待完毕后即处于此状态;\n注意:yelid是谦让cpu时间片; sleep和join也不会释放锁, 更不会进入「等待队列」。难理解的地方在于join, 它是由wait实现的, 居然不进入「等待队列」?这是由于join的是当前主线程, 而非调用线程, 主线程等待子线程调用完毕后由内部native方法去notify唤醒\n参考: Java多线程里面join方法会使被阻塞线程释放对象锁吗？\n2. 锁池队列:\n处于竞争锁状态, synchorized, Lock, ...\n3. 等待队列:\nwait调用后即进入此队列, 一旦被唤醒则进入锁池队列去竞争锁, 一旦竞争到锁则进入等待队列, 等待被cpu时间片调度\n\n\nnotifynotifyAll, wait\nnotify是随机唤醒阻塞在锁(monitor)上的线程, 有可能会出现唤醒的线程竞争不到锁资源(进入临界区)而失败;\nnotifyAll则是唤醒所有阻塞在其上的线程, 也可能出现惊群效应, 可以理解为活锁, 大家都竞争不到锁而往复的释放自己持有的资源\n\n\n\ninteruptinterruptedisInterrupted\nsuspendresume已不推荐使用, stop由于其强杀会导致不一致性问题, 也不推荐使用\n\n\ninterrupt():\n线程状态被置为&quot;中断&quot;状态\ninterrupted():\n静态方法, 内部返回当前执行线程是否中断, 同时清除中断标记\nisInterrupted() :\n实例方法, 判断指定线程的中断状态, 但不一定是当前线程, 可以是A线程去调用B线程的isInterrupted()方法; 不会清除中断标记\n中断线程的两种方式:\n阻塞的定义是可能在访问磁盘IO,可能访问网络IO(HTTP请求),或者正在访问数据库, 也有可能调用了waitsleepjoin\n\n\n如果子线程不会进入阻塞态, 则使用volatile修饰的布尔变量来控制子线程的退出\n如果有阻塞, 则通过拦截异常进行退出\n注意如果调用了waitsleepjoin, 一旦再调用interrupt会出现中断异常, 同时JVM会清除中断标记, 所以再使用isInterrupted会得到false\n\nJava内存模型\n这个请查阅之前写的篇幅, 这里只记录大纲\n\n\n可见性: 明白工作内存和主存\n有序性: CPU指令流水, 为了减少时钟, 出现了指令重排序\n原子性: CAS(cmpxchg汇编指令)\nHappen-Before, 规约哪些是不能重排序的\n4.1 顺序原则: 有数据相关性, 重排不能改变语义(as-if-serial)\n4.2 监视器锁规则: 解锁必须先加锁\n4.3 volatile域规则: 写了才能读\n4.4 传递性规则: 通俗讲, 调用线程的joinwaitinterrupt, 必须先start线程\njava的内在实现: 八条内存屏障指令\nlock：作用于主内存，把变量标识为线程独占状态。\nunlock：作用于主内存，解除独占状态。\nread：作用主内存，把一个变量的值从主内存传输到线程的工作内存。\nload：作用于工作内存，把read操作传过来的变量值放入工作内存的变量副本中。\nuse：作用工作内存，把工作内存当中的一个变量值传给执行引擎。\nassign：作用工作内存，把一个从执行引擎接收到的值赋值给工作内存的变量。\nstore：作用于工作内存的变量，把工作内存的一个变量的值传送到主内存中。\nwrite：作用于主内存的变量，把store操作传来的变量的值放入主内存的变量中\njava的外在体现: volatile, Atomic(CAS)\n总结\n\n\n\n避免死锁的方式: 不要在锁代码块里再获取其他锁, 这是死锁的前提\nsynchronized保证了原子性可见性; 但volatile只保证可见性(内部采用禁止重排序和内存屏障,每次都会读取主存而非寄存器的缓存), 所以volatile不适合getAndSet操作\n1\n\nAtomic包CAS\n\nUnsafe\n它类似直接操作C语言, 可以获取变量在对象中的偏移量并赋值, 类似struct结构体\nAtomicInteger\n从下面可以看出, 主要使用了unsafe.compareAndSwapInt, CAS使用了原子汇编指令cmpxchg, 失败重试机制(乐观锁)\n\n123public final boolean compareAndSet(int expect, int update) &#123;    return unsafe.compareAndSwapInt(this, valueOffset, expect, update);&#125;\n\nAtomicIntegerArray\n保证数组的每个元素操作都是线程安全, 比起Collections.synchronizedList使用syncthorized悲观锁性能要好一些。\n\n123456789101112131415161718public final int getAndSet(int i, int newValue) &#123;    return unsafe.getAndSetInt(array, checkedByteOffset(i), newValue);&#125; 最终使用了如下代码private static long byteOffset(int i) &#123;    **     * - base为数组在内存的基地址     * int base = unsafe.arrayBaseOffset(int[].class);     * - shift为数组每个元素在内存的偏移量bit     * - scale指Integer的宽度, 4个字节(byte)     * int scale = unsafe.arrayIndexScale(int[].class);     * numberOfLeadingZeros计算前导零的个数     * shift = 31 - Integer.numberOfLeadingZeros(scale);     *     *    return ((long) i &lt;&lt; shift) + base;&#125;\n\nAtomicIntegerFieldUpdater\n主要用于普通变量的原子操作, 但是它有四点前提:\n可见且可变的非静态volatile变量\n\n\n\n可见: 即不能private\n可变: 即不能以final修饰, 因为使用了反射不允许修改final已经初始化的值\n非静态: 即不能使用static, 因为CAS不支持静态堆数据的赋值\n\n\n\nLongAdder\n采用了热点分离的思想,采用了Cell[], 将value值分离为一个数组; 结果即数组的累加求和。\n和ConcurrentHashMap的Segment分段锁很类似;\n因为CAS是自旋方式, 所以可能会出现经常失败而导致cpu白白浪费(‘空转’)\n\n\n\n用long类型的base字段存储值\ncasBase()方法进行CAS递增\n如果CAS失败,不会自旋, 会立即创建Cell[]\n单个Cell上面出现了cell更新冲突，那么会尝试创建新的Cell, 当Cell[]数组不够了, 则扩容\nAtomicLong效率比较, 在线程1000,10000次循环递增,大概差距在100+ms; 当1000线程,100w次大循环递增, 差距大致6倍\nJDK8-LongAdder代替AtomicLong\n\n\n  12345678910111213public void add(long x) &#123;      Cell[] as; long b, v; int m; Cell a;       2. 对base字段进行CAS      if ((as = cells) != null || !casBase(b = base, b + x)) &#123;          boolean uncontended = true;          if (as == null || (m = as.length - 1) &lt; 0 ||              (a = as[getProbe() &amp; m]) == null ||               单个Cell上CAS失败, 新建Cell或者扩容数组              !(uncontended = a.cas(v = a.value, v + x)))               初始化Cell[]数组新建Cell扩容数组              longAccumulate(x, null, uncontended);      &#125;  &#125;\n\n\n\nThreadLocalRandom\n解决了Random类在多线程下多个线程竞争内部唯一的原子性种子变量而导致大量线程自旋重试的不足;\n如下代码所示, 虽然采用了AtomicLong, 解决了多线程计算出相同新种子的问题(获取了相同的随机数), 但是新种子是CAS运算, 线程堆积后则可能出现大量自旋;\nThreadLocalRandom重写了nextInt, 利用ThreadLocal, 初始化Thread线程实例里的``threadLocalRandomSeed变量ThreadLocalRandom.current()`就是在初始化线程里的种子\n123456789101112131415161718192021 Random的nextInt方法public int nextInt(int bound) &#123;     1. 检查区间是否负数    if (bound &lt;= 0)        throw new IllegalArgumentException(BadBound);     2.计算新种子     此处在多线程下可能会产生多个一样的种子     所以seed采用了CAS原子类AtomicLong    int r = next(31);    int m = bound - 1;     3.开始生成随机数, seed=f(seed), 所以概率相等, 分布均匀    if ((bound &amp; m) == 0)   i.e., bound is a power of 2        r = (int)((bound * (long)r) &gt;&gt; 31);    else &#123;        for (int u = r;             u - (r = u % bound) + m &lt; 0;             u = next(31))            ;    &#125;    return r;&#125;\n\n\nRandom类的实现原理如下:\n\n\n构造函数带种子或不带种子\n默认采用系统当前纳秒时间,因为代码执行速度在[几百纳秒, 几十毫秒]这个区间,整体递增, 所以精准(this(seedUniquifier() ^ System.nanoTime()))\n种子的意义\n随机的起源数字, 目的就是为了足够&quot;随机&quot;\nnextInt(100)\n返回[0,100)左闭右开内的一个随机数, 注意数字是一个线性函数生成出来的, 所以数字是均匀分布, 等概率事件这在数学上不能称之为随机, 所以我们称为伪随机数\nMath.random 生成[0,1)之间的double类型随机数, 它是Random的实例\n\n\n\nLockFreeVector\n由Amino并发库实现, 大部分为无锁CAS设计;\n其存储结构为一个AtomicReferenceArray二维数组结构, 首个数组容量为8, 一共30个数组, 每次扩容都是前一个的2倍, 所以最大容量固定为8*(2^30-1)\n目的是避免扩容时修改之前的数据\n其数据形状很类似九九乘法表, 高度30, 长度为前一个元素2倍\n\n1private final AtomicReferenceArray&lt;AtomicReferenceArray&lt;E&gt;&gt; buckets = new AtomicReferenceArray(30);\n\n1.存储结构\n定义为了CAS的二维数组AtomicReferenceArray&lt;AtomicReferenceArray&lt;E&gt;&gt;\n一共30个数组, 首个数组长度为8, 数组往后成倍递增, 8&lt;&lt;1, 8&lt;&lt;2 … 8&lt;&lt;29; 最大容量为8*(2^30-1)\n2.Descriptor静态内部类\n目的是为了更好的有序读写数组, 是一个内部辅助类\n3.总结\n为何存储定义为二维数组, 由于一维数组必定会进行扩容, 扩容必定不是原子操作, 所以为了避开扩容来符合CAS, 所以如此设计。\n第一个数组装满, 则往第二个数组追加, 此时的重点就在于计算二维坐标\n\n我们来看一下最重要的方法, 主要是计算二维坐标\n1234567891011121314151617181920212223242526272829public void push_back(E e) &#123;    Descriptor&lt;E&gt; desc;    Descriptor&lt;E&gt; newd;    do &#123;        desc = descriptor.get();        预防上一个线程在设置完descriptor后(while语句块), 还没来得及执行最后一句话completeWrite, 预防性的措施        desc.completeWrite();        desc.size   Vector 本身的大小        FIRST_BUCKET_SIZE  第一个一位数组的大小        int pos = desc.size + FIRST_BUCKET_SIZE;        int zeroNumPos = Integer.numberOfLeadingZeros(pos);   取出pos 的前导零        zeroNumFirst  为FIRST_BUCKET_SIZE 的前导零        int bucketInd = zeroNumFirst - zeroNumPos;  哪个一位数组        判断这个一维数组是否已经启用        if (buckets.get(bucketInd) == null) &#123;            newLen  一维数组的长度            int newLen = 2 * buckets.get(bucketInd - 1).length();            if (debug)                System.out.println(New Length is: + newLen);            buckets.compareAndSet(bucketInd, null,                    new AtomicReferenceArray&lt;E&gt;(newLen));        &#125;        int idx = (0x80000000&gt;&gt;&gt;zeroNumPos) ^ pos;   在这个一位数组中，我在哪个位置        newd = new Descriptor&lt;E&gt;(desc.size + 1, new WriteDescriptor&lt;E&gt;(                buckets.get(bucketInd), idx, null, e));    &#125; while (!descriptor.compareAndSet(desc, newd));    descriptor.get().completeWrite();&#125;\n代码难点分析:\n\n\ndesc.completeWrite()\n预防上一个线程在设置完descriptor后(while语句块里), 还没来得及执行最后一句话completeWrite(保存真正的值), 所以在do里预先执行一次, 预防出现没保存值的情况\n计算第一维索引bucketIndex\n即计算进位后前导零位数差值来作为bucketIndex; 当第一个组数(长度为8), 则pos = 8+8 = 16, 会导致进位, 通过前导零差值则可计算出第一维的索引下标\n计算第二维索引iIndex\n(0x80000000&gt;&gt;&gt;zeroNumPos) ^ pos;\n这个比较难理解, 我们看如下分析:\n\n\n  12345678910111213141516171819202122232425262728290x80000000 32位如下:1000 0000 0000 0000 0000 0000 0000 0000无符号右移动zeroNumPos位(pos的前导零个数)比如pos=17,代表第二个数组的第一位,坐标为(1,0)17已进位,则前导零个数为27,无符号右移27位,高位补27个零:0000 0000 0000 0000 0000 0000 0001 0000^异或pos (相等为0, 不等为1):0000 0000 0000 0000 0000 0000 0001 0001结果为:0000 0000 0000 0000 0000 0000 0000 0001表明可以存入的索引为1 (注意索引从0开始, 即第二位)=======================================比如pos=13, 代表第一个数组第五位, 坐标为(0,4)前导零个数为28,无符号右移28位,高位补28个零:0000 0000 0000 0000 0000 0000 0000 1000^异或pos0000 0000 0000 0000 0000 0000 0000 1101结果为:0000 0000 0000 0000 0000 0000 0000 0101表明可以存入的索引为5 (注意索引从0开始, 即第六位)=======================================比如pos=15, 代表第一个数组第七位, 坐标为(0,6)前导零个数为28,无符号右移28位,高位补28个零:0000 0000 0000 0000 0000 0000 0000 1000^异或pos0000 0000 0000 0000 0000 0000 0000 1111结果为:0000 0000 0000 0000 0000 0000 0000 0111表明可以存入的索引为7 (注意索引从0开始, 即第八位)\n为何这样设计? 这个需要对二进制数据结构比较敏感, 可能10进制已经固化到思维, 二进制反而很不直观, 采用二进制进位和前导零的关系, 可以直接映射坐标\n\n\n每次会判断数组是否存在, 不存在表示前一个数组已满, 需要扩容(创建后一个新数组), 长度为前一个的2倍\n\n\n\nABA问题\nCAS无法解决ABA问题, 即A线程讲i改为2, 然后又恢复原值, 造成B线程无法得知其中的过程;\n如果是值类型可能没有问题, 但是某些业务可能出现问题, 比如充值, 所以提出了带时间戳的CAS\n\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class AtomicStampedReferenceTest &#123;    private static AtomicStampedReference&lt;Integer&gt; money =            new AtomicStampedReference&lt;&gt;(19, 0);    public static void main(String args[]) &#123;        **         * 3个充值线程         *        for (int i = 0; i &lt; 3; i++) &#123;            final int timestamp = money.getStamp();            new Thread(() -&gt; &#123;                while (true) &#123;                    Integer m = money.getReference();                    if (m &lt; 20) &#123;                        if (money.compareAndSet(m, m + 20, timestamp, timestamp + 1)) &#123;                            System.out.println(余额小于20元,充值成功,余额: + money.getReference() + 元);                            break;                        &#125;                    &#125; else &#123;                        System.out.println(余额大于20,无需充值);                        break;                    &#125;                &#125;            &#125;).start();        &#125;         1个模拟消费线程        new Thread() &#123;            public void run() &#123;                for (int i = 0; i &lt; 100; i++) &#123;                    while (true) &#123;                        int timestap = money.getStamp();                        Integer m = money.getReference();                        if (m &gt; 10) &#123;                            System.out.println(金额大于10元);                            if (money.compareAndSet(m, m - 10, timestap, timestap + 1)) &#123;                                System.out.println(成功消费10元,余额: + money.getReference() + 元);                                break;                            &#125;                        &#125; else &#123;                            System.out.println(没有足够的金额);                            break;                        &#125;                    &#125;                    try &#123;                        Thread.sleep(100);                    &#125; catch (InterruptedException e) &#123;                        e.printStackTrace();                    &#125;                &#125;            &#125;        &#125;.start();    &#125;&#125;\n\nAtomicMarkableReference\n适合只修改一次, 因为它的stamp是boolean布尔, 所以只有「未标记」「已标记」两种状态\n\nConcurrent并发包\n\n\nReentrantLock\n这里重点讲一下锁的可重入：\nReentrantLock和synchronized都是可重入的, 意思是同一个获得锁的线程, 不管进入临界区几次, 都是允许进入的；\n可重入机制: 每一个锁(monitor)关联一个线程持有者和计数器，当计数器为 0 时表示该锁没有被任何线程持有，那么任何线程都可能获得该锁而调用相应的方法；当某一线程请求成功后，JVM会记下锁的持有线程，并且将计数器置为 1；此时其它线程请求该锁，则必须等待；而该持有锁的线程如果再次请求这个锁，就可以再次拿到这个锁，同时计数器会递增；当线程退出同步代码块时，计数器会递减，如果计数器为 0，则释放该锁。\n\n我们来模拟不可重入锁\n123456789101112131415161718192021222324** * 不可重入锁 (使用CAS实现) * 同一线程, 当两次调用lock, 而不调用unlock时, 会产生死锁 * 原因是第二次lock会永远更新不成功, 则永远在死循环 *public class UnreentrantLockByCAS &#123;      private AtomicReference&lt;Thread&gt; owner = new AtomicReference&lt;&gt;();      AtomicInteger      public void lock() &#123;          Thread current = Thread.currentThread();          这句是很经典的“自旋”语法          for (; ; ) &#123;              if (owner.compareAndSet(null, current)) &#123;                  return;              &#125;          &#125;      &#125;      public void unlock() &#123;          Thread current = Thread.currentThread();          owner.compareAndSet(current, null);      &#125;  &#125;\n123456789101112131415161718192021222324  ** * 不可重入锁 (使用CAS实现) * 同一线程, 当两次调用lock, 而不调用unlock时, 会产生死锁 * 原因是第二次lock会永远更新不成功, 则永远在死循环 *public class UnreentrantLockByCAS &#123;        private AtomicReference&lt;Thread&gt; owner = new AtomicReference&lt;&gt;();        AtomicInteger        public void lock() &#123;            Thread current = Thread.currentThread();            这句是很经典的“自旋”语法            for (; ; ) &#123;                if (owner.compareAndSet(null, current)) &#123;                    return;                &#125;            &#125;        &#125;        public void unlock() &#123;            Thread current = Thread.currentThread();            owner.compareAndSet(current, null);        &#125;&#125;\n当然我们改动一下, 增加Thread判断, 同时增加计数\n1234567891011121314151617181920212223242526 可重入 (synchronized实现)public class ReentrantLockBySync &#123;      boolean isLocked = false;      Thread lockedBy = null;      int lockedCount = 0;      public synchronized void lock() throws InterruptedException &#123;          Thread thread = Thread.currentThread();          while (isLocked &amp;&amp; lockedBy != thread) &#123;              wait();          &#125;          isLocked = true;          lockedCount++;          lockedBy = thread;      &#125;      public synchronized void unlock() &#123;          if (Thread.currentThread() == this.lockedBy) &#123;              lockedCount--;              if (lockedCount == 0) &#123;                  isLocked = false;                  notify();              &#125;          &#125;      &#125;  &#125;\n1234567891011121314151617181920212223242526272829303132333435  ** * 可重入 (使用CAS实现) * 两要素: 若是当前线程, 重入时state计数器加1, 释放时减1 *  1.持有当前线程 *  2.计数器 *public class ReentrantLockByCAS &#123;        private AtomicReference&lt;Thread&gt; owner = new AtomicReference&lt;&gt;();        private int state = 0;        public void lock() &#123;            Thread current = Thread.currentThread();            if (current == owner.get()) &#123;                state++;                return;            &#125;            这句是很经典的“自旋”语法            for (; ; ) &#123;                if (owner.compareAndSet(null, current)) &#123;                    return;                &#125;            &#125;        &#125;        public void unlock() &#123;            Thread current = Thread.currentThread();            if (current == owner.get()) &#123;                if (state != 0) &#123;                    state--;                &#125; else &#123;                    owner.compareAndSet(current, null);                &#125;            &#125;        &#125;    &#125;\n总结:\n\n\n\n可重入:\n同一线程, 加几次锁, 就要释放几次\n可中断:\nlock.lockInterruptibly();\n只有声明为可中断加锁, 则线程是可以发起中断thread.interrupt()\n可限时:\n意思是超时后若还未获得锁(monitor),则放弃锁竞争\nlock.tryLock(5, TimeUnit.SECONDS)\n公平锁:\nnew ReentrantLock(true)\n默认是非公平锁, 所谓公平即先来则先获得锁; 但是公平锁会维持队列, 且没有优先级的概念,非公平锁具有更高的吞吐量\n\n\nCondition\n\nCondition(awaitsingnalsingnalAll)和ReentrantLock的关系\n就好比\nObject(waitnotifynotifyAll)与synchonized的关系\n它提供了一个awaitUninterruptibly, 和wait一样, 但是不会响应中断, 即会一直等待signal唤醒\n具体就不细说,看一个例子\n12345678910111213141516171819202122232425262728293031323334353637public class ConditionTest implements Runnable &#123;    private static ReentrantLock lock = new ReentrantLock();    private static Condition condition = lock.newCondition();    @Override    public void run() &#123;        try &#123;            lock.lock();  类似synchronized            condition.await();  类似obj.wait(); 注意await和object.wait一样是会释放锁的             注意如果唤醒的是多个线程, 这里也会如同notifyAll一样, 出现锁竞争            System.out.println(thread is going on);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125; finally &#123;            lock.unlock();        &#125;    &#125;    public static void main(String[] args) throws InterruptedException &#123;        ConditionTest r = new ConditionTest();        Thread t = new Thread(r);        t.start();        Thread.sleep(5000);         开始唤醒await的线程        try &#123;            lock.lock();            System.out.println(begin signal thread);            condition.signal();        &#125;finally &#123;            lock.unlock();        &#125;    &#125;&#125;\n\nSemaphore信号量\n\n[ˈseməfɔ:®] 信号量, 也可以称呼为共享锁\n它可以允许多个线程进入临界区, 但是一旦许可耗尽, 则其他线程也需要等待许可的释放,即退化为Lock锁;\nSemaphore和Lock的区别:\n\n\n锁只允许一个线程进入临界区, 信号量允许多个线程进入临界区, 类似广义的独享锁\n信号量会指定许可permission的数量, 一旦许可耗尽则退化为独享锁\n一般一个线程只会持有一个permission许可, 但也可以一个线程持有多个许可\n\n\n我们来看一个例子:\n  123456789101112131415161718192021222324252627282930313233343536373839404142434445public class SemaphoreTest implements Runnable &#123;      final Semaphore semaphore = new Semaphore(5);      @Override      public void run() &#123;          try &#123;               获取一个permission许可(可以多个, 但消费一个则少一个)              semaphore.acquire();              模拟2s耗时操作              Thread.sleep(2000);              System.out.println(Thread_ + Thread.currentThread().getId() +  done!);          &#125; catch (InterruptedException e) &#123;              e.printStackTrace();          &#125;finally &#123;              semaphore.release();          &#125;      &#125;      public static void main(String[] args) &#123;           创建容量固定为20的线程池          ExecutorService excutorService = Executors.newFixedThreadPool(20);          final SemaphoreTest semaphoreTask = new SemaphoreTest();          **           * 20个线程任务立马提交完毕, 但是任务里有2s耗时操作, 所以一次最多允许执行5个线程, 2s后再执行5个线程, 依次之           * 注意: execute 和 submit 区别           *      1. submit有三个重载           *         &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task)           *         &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result)           *         Future&lt;?&gt; submit(Runnable task)           *      2. submit有返回值, 但execute没有           *      3. submit可以处理Exception异常, 捕获Future.get()即可           *           *           *          for (int i = 0; i &lt; 20; i++)&#123;              excutorService.*execute*submit(semaphoreTask);          &#125;      &#125;  &#125;\n\nReentrantReadWriteLock读写锁\n\n它要解决的是synchronized在「读读」互斥串行的情况\n\n\n读写锁是可重入的\n读-读: 不互斥, 是共享锁, 内部使用了AQS\n写-写: 互斥, 类似Lock\n读-写: 互斥, 同上; 即不支持锁升级\n写-读: 互斥, 但是支持锁降级, 即线程获取写锁, 在不释放写锁的情况下, 当前线程还可以获取读锁; 然后释放写锁后, 此时还剩下读锁, 则称为锁降级\n内部有WriteLock和ReadLock, 采用了AQS(实现阻塞锁和一系列依赖FIFO等待队列的同步器的框架)\n\n\n来看一个例子\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152** * 读写互斥 (测试锁降级) * * 结论: ReentrantReadWriteLock支持锁降级, 但不支持锁升级 *    1. 写锁降级为读锁, 但是不会释放当前线程获得的写锁; 仍需要手动释放写锁, 否则其他线程永远无法获得写锁 *    2. 首先读写锁是互斥的; *       2.1 获取读锁 -&gt; 获取写锁 *           发现无法获取写锁了, 这表明读写锁互斥, 且不支持锁升级 (即读锁升级为写锁) *       2.2 获取写锁 -&gt; 获取读锁 *           发现写锁加锁后还能获取读锁, 这表明互斥情况下, 支持锁降级 (写锁降级为读锁) * *       2.3 当有读锁时，写锁就不能获得；而当有写锁时，除了获得写锁的这个线程可以获得读锁外，其他线程不能获得读锁 *public class LockDownTest implements Runnable &#123;    static ReentrantReadWriteLock rwLock = new ReentrantReadWriteLock();    @Override    public void run() &#123;        **         * 先获取写锁, 在不释放写锁的前提下, 再获取读锁, 发现可以成功; 表明支持锁降级         * 先获取读锁, 发现不能再获取写锁, 证明不支持锁升级         *        rwLock.writeLock().lock();        System.out.println(Thread_ + Thread.currentThread().getId() + get writeLock);        rwLock.readLock().lock();        System.out.println(Thread_ + Thread.currentThread().getId() + get readLock);         释放写锁, 完成锁降级为读锁        rwLock.writeLock().unlock();         最后释放降级的读锁        rwLock.readLock().unlock();    &#125;    public static void main(String[] args) throws InterruptedException &#123;        LockDownTest r = new LockDownTest();        Thread t1 = new Thread(r);        Thread t2 = new Thread(r);        t1.start();        t2.start();        t1.join();        t2.join();        System.out.println(FINISH);    &#125;&#125;\n\nCountDownLatch 倒数计时器(闭锁)\n闭锁, 类似一个门最初是关闭的, 比如等到10人(线程)到齐了才会开门, 所有人(线程)才可通过, 但是门打开之后就不能再关上, 所以不能重复利用\n\n\n\n它允许一个或多个线程一直等待, 直到其他线程的操作执行完后再执行, 类似join的功能\n和Semaphore信号量一样, 提供一个count计数, 且只能初始化一次,不能修改; 当计数为0则唤醒阻塞的线程\nCountDownLatch 和 join的区别\n其实两者的功能完成一样,都是阻塞线程等待其他线程执行完毕,然后继续执行; 但是join只能等待其他线程任务整体完成, 而CountDownLatch则是通过计数器count来作为标准, 所以粒度更细, 所以控制力更强\n总结\n在需要等待的线程里调用countDownLatch.countDown();\n在受控主线程调用countDownLatch.await();\n直到内部count耗尽为0, 则会继续执行受控主线程\n适用场景\n一般用于启动服务任务前, 等待其他预检测线程反馈OK, 然后再继续启动\n很适合做MasterWorker, MapReduce等架构模式\n\n\n123456789101112131415161718192021222324252627282930313233public class CountDownLatchTest1 implements Runnable &#123;    static final CountDownLatch countDownLatch = new CountDownLatch(10);    @Override    public void run() &#123;        try &#123;             模拟随机耗时任务            Thread.sleep(new Random().nextInt(10) * 1000);            System.out.println(Thread_ + Thread.currentThread().getId() +  complete.);             每次都会count-1,直到为零,就会notifysignal唤醒主线程            countDownLatch.countDown();        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;    &#125;    public static void main(String[] args) throws InterruptedException &#123;        ExecutorService service = Executors.newFixedThreadPool(10);        CountDownLatchTest1 test = new CountDownLatchTest1();        for (int i = 0; i &lt; 10; i++)&#123;            service.submit(test);        &#125;         注意不是调用Object的wait(), 这里很容易手误        countDownLatch.await();        System.out.println(Main Thread Finish.);        service.shutdown();    &#125;&#125;\n\nCyclicBarrier 循环屏障(闭锁)\n\n它可以实现让一组线程等待至某个状态之后再全部同时执行\n\n\ngetNumberWaiting() 有几个线程已经到达屏障点\ngetParties()取得parties个数\nreset() 将屏障重置为其初始状态\nisBroken() 查询此屏障是否处于损坏状态, 即查询阻塞的线程是否被中断\n和CountDownlatch区别\nCountDownlatch是使用countDown进行count-1操作, 再使用await阻塞主线程, 直到count为零再唤醒继续执行;\nCyclicBarrier是利用await进行count+1, 当count==parties时则表明都到达屏障点\n特点\n3.1\n如果在线程处于等待状态时barrier被reset()或者在调用await()时 barrier 被损坏，将抛出BrokenBarrierException异常\n3.2\n如果当前线程在进入此方法时已经设置了该线程的中断状态或者在等待时被中断，将抛出InterruptedException，并且清除当前线程的已中断状态\n3.3\n如果任何线程在等待时被中断，则其他所有等待线程都将抛出 BrokenBarrierException 异常，并将 barrier 置于损坏状态。\n3.4\n如果当前线程是最后一个将要到达的线程，并且构造方法中提供了一个非空的屏障操作(barrierAction), 那么在允许其他线程继续运行之前，当前线程将运行该操作。如果在执行屏障操作过程中发生异常，则该异常将传播到当前线程中, 并将 barrier 置于损坏状态\n(即Commander发生了异常, 则会将barrier置于损坏状态, 同时将异常抛出到主线程)\n\n\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192public class CyclicBarrierTest &#123;    public static class Commander implements Runnable &#123;         是集合还是完成任务        volatile boolean flag;         人数        volatile int count;        public Commander(boolean flag, int count) &#123;            this.flag = flag;            this.count = count;        &#125;        @Override        public void run() &#123;            if (flag) &#123;                System.out.println(指挥官接到消息:[士兵 + count + 个, 任务完成!]);            &#125;else &#123;                System.out.println(指挥官接到消息:[士兵 + count + 个, 集合完毕!]);                System.out.println(指挥官发布执行任务命令... ...);                flag = true;            &#125;        &#125;    &#125;    public static class Soldier implements Runnable &#123;        private String soldier;        private final CyclicBarrier barrier;        public Soldier(String soldier, CyclicBarrier barrier) &#123;            this.soldier = soldier;            this.barrier = barrier;        &#125;        @Override        public void run() &#123;            try &#123;                 ------------ 等待所有士兵集合 ------------                int waitCount = barrier.getParties() - barrier.getNumberWaiting() - 1;                if (waitCount == 0) &#123;                    System.out.println(soldier + , 所有士兵已集合完毕, 开始通知指挥官...);                &#125;                barrier.await();                 ------------ 集合完毕后开始各自执行任务 ------------                doWork();                 ------------ 等待所有士兵完成任务 ------------                waitCount = barrier.getParties() - barrier.getNumberWaiting() - 1;                if (waitCount == 0) &#123;                    System.out.println(soldier + 已完成, 所有士兵已完成任务, 开始通知指挥官...);                &#125;else&#123;                    System.out.println(soldier + 已完成, 开始等待其他 + waitCount + 人完成任务);                &#125;                barrier.await();            &#125; catch (InterruptedException | BrokenBarrierException e) &#123;                e.printStackTrace();            &#125;        &#125;        public void doWork() &#123;            try &#123;                Math.abs(new Random().nextInt() % 10000);                Thread.sleep(new Random().nextInt(10000));            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;    &#125;    public static void main(String[] args) &#123;        final int count = 10;        Thread[] solders = new Thread[count];        boolean flag = false;        CyclicBarrier barrier = new CyclicBarrier(count, new Commander(flag, count));        System.out.println(队伍开始集合!);        for (int i = 0; i &lt; count; i++) &#123;            System.out.println(士兵 + i + 报到);            solders[i] = new Thread(new Soldier(士兵 + i, barrier));            solders[i].start();            if (i == 5)&#123;                solders[0].interrupt();            &#125;        &#125;    &#125;&#125;\n\nLockSupport 锁支持源语\n\n之前讲过, suspendresume已经被淘汰, 因为可能导致死锁\nwaitnotify(notifyAll)则比前者更进一步, 解决了死锁问题, 但还是有一个问题存留, 先notify, 后wait,虽然不会导致死锁, 但是会导致wait的线程一直hang在那\n1234567这里再备注一下suspendresume的缺陷suspend和sleep很像, 也和wait很像, 但也有不同:1. suspend也会持有监视器(锁), 和sleep很像, 但是sleep可以被中断, 也可以过期策略, 所以不会死锁2. suspend也可以通过resume唤醒, 和waitnotify很像, 但是wait是释放了监视器(锁)的, 只是需要等待唤醒而已, 所以不会死锁3. suspend一没有释放锁, 二没有中断机制, 三没有过期策略, 所以只能被resume唤醒   如果resume被先调用, suspend后执行, 则会导致锁一直不被释放, 从而死锁\n\n\nLockSupport可以解决两大问题\n1.1 解决suspendresume的死锁问题\n1.2 解决waitnotify(notifyAll)的线程悬挂阻塞问题(虽然不会导致死锁了)\nLockSupport两大优势\n2.1 LockSupport不需要在同步代码块里;所以线程间也不需要维护一个共享的同步对象了，实现了线程间的解耦\n2.2 unpark函数可以先于park调用，所以不需要担心线程间的执行的先后顺序\nunpark将许可permit置为1, park将permit置为0\nunpark-&gt;park; 会导致线程不会被阻塞\npark-&gt;unpark; 线程阻塞后被唤醒\n多次调用unpark, 由于只是重置为1,所以不影响\n多次调用park, 由于LockSuport是不可重入锁, 所以会死锁\n广泛的应用\nThreadPoolExecutor内部使用LockSupport\n阻塞:\n典型的 future.get() 同步阻塞等待线程池的执行结果; submit提交Callable任务后会返回FutureTask, 此方法会有get方法, 继而调用awaitDone进行阻塞, 内部实则调用了LockSupport.park()\n唤醒:\nCallable被包装成了FutureTask, 内部会c.call()执行任务, 继而调用set方法, 内部调用finishCompletion, 而finishCompletion会通过CAS取出所有等待的线程, 循环唤醒 LockSupport.unpark(t)\n注意事项\n\n\n\nThreadLocal\n\n线程本地变量\n\n\nThreadLocal不是用来解决对象共享访问问题的; 反其道而行, 解决某个对象需要一直跟随某线程(同生共死), 从而解决对象如何传递的问题\n典型的Session会话管理,多线程需要避免Session的调用混乱\n2.1 首先不加锁, 铁定出现多线程问题(openSession多次正在写入数据库却被其他线程关闭close)\n2.2 加独享锁, 显然问题能解决, 但是一个操作正在进行,则其他操作必须等待, 性能有问题\n3.3 在DAO层做如下操作:\nopenSession() -&gt; 数据库操作 -&gt; close()\n也能解决问题, 但是session频繁的打开关闭这也是性能问题\nThreadLocal正好利用线程的生命周期, 将需要使用的副本对象附加其上, 这样session对象的调用就不会错乱\nThreadLocalMap总结:\n4.1 ThreadLocalMap解决hash采用了线性探测(开发地址法), 如果冲突则加1; 这种算法比起链地址法效率低很多, 所以建议一个线程只保存一个变量(即一个ThreadLocal)\n4.2 ThreadLocalMap的key是弱引用, 而Value是强引用; 这导致ThreadLocal在没有外部对象强引用时，发生GC时弱引用Key会被回收, 而Value不会回收; 如果创建ThreadLocal的线程一直持续运行，那么这个Entry对象中的value就有可能一直得不到回收，发生内存泄露; 但线程结束时总会释放掉;\n但如果线程是使用的线程池, 由于线程池里的线程结束是不会销毁的, 这时候就发生了真正意义上的内存泄漏\n\n\n\nThreadLocal使用场景为 用来解决 数据库连接、Session管理\n1234567891011121314151617181920212223private static ThreadLocal &lt; Connection &gt; connectionHolder = new ThreadLocal &lt; Connection &gt; () &#123;    public Connection initialValue() &#123;        return DriverManager.getConnection(DB_URL);    &#125;&#125;;public static Connection getConnection() &#123;    return connectionHolder.get();&#125;private static final ThreadLocal threadSession = new ThreadLocal();public static Session getSession() throws InfrastructureException &#123;    Session s = (Session) threadSession.get();    try &#123;        if (s == null) &#123;            s = getSessionFactory().openSession();            threadSession.set(s);        &#125;    &#125; catch (HibernateException ex) &#123;        throw new InfrastructureException(ex);    &#125;    return s;&#125;\n\n\nForkJoin\n\nJDK原生的单机版的MapReduce归并计算, Amino里也有类似的MasterWorker模式的实现\n主要思想:\n\n对比MapReduce1.0原理\n\n\n\n\n\n\n类图:\n\n\n一 特性:\n\n计算资源共享\n高性能队列\n避免伪共享 (Disruptor也有类似的实现, 采用补位对齐缓存行)\n它的实现是使用了@sun.misc.Contendedjdk8的注解\n工作窃取机制 (特有)\n二 对比ThreadPoolExecutor\n线程池ThreadPoolExecutor公用任务队列, ForkJoinPool则每个线程单独一个任务队列\n线程池支持RunnableCallable两种类型的任务, 同理ForkJoinPool也支持带返回值不带返回值的任务\nRecursiveTask(带返回值)  RecursiveAction(不带返回值)\n三 对应关系\nThreadPoolExecutor --&gt; Thread --&gt; RunnableCallable\nForkJoinPool --&gt; ForkJoinWorkerThread --&gt; RecursiveActionRecursiveTask\n注意不是为了替代ExecutorService, 而仅仅作为补充, 比如补充了work-stealing逻辑\n四 工作窃取(work stealing)\n1. 因为任务队列是进行了拆分 (拆到什么粒度需要我们指定拆分的临界值), 即线程会各自独享一个子任务队列;\n\n\n\n当其中线程A先执行完毕, 线程B还未执行完, 则A会从B偷取一个任务;\n如何偷? 拆分的线程子任务队列是一个线程安全的双端队列, 被窃取线程永远从头部取, 窃取线程永远从队尾取, 避免并发导致的竞争, 但是只有一个任务的极端情况还是无法避免竞争\n\n\n五 优缺点\n优点: 类似单机版本的MapReduce归并计算, 比线程池更加充分利用CPU资源\n缺点: 编码复杂, 而且需要大量队列, 线程…的创建与销毁, 导致效率无法明显的提升, 貌似Netty5.0就是基于此原因之一放弃发布\n六 注意事项\n1. ForkJoinPool 也有submit, execute, 同时多了一个invoke\n非阻塞:\nexecute不带返回值, submit带返回值, 这和ThreadPoolExecutor类似\nsubmit返回了Future的子类ForkJoinTask, 调用task.get()才会阻塞\n阻塞:\ninvoke会阻塞调用线程 (主线程), 直到有结果并返回\n\n\nfork是分配任务\nleftTask.fork(); rightTask.fork();\n替换为\ninvokeAll(leftTask, rightTask);\n使用fork, 假如程数量固定, 当前线程会将leftTaskrightTask分配下去,自身并不会做任何事情, 会浪费一个线程\n\n\n示例:\n123456789101112131415161718192021222324252627282930313233343536373839404142public class ForkJoinCalcTask extends RecursiveTask&lt;Long&gt; &#123;    private Long start;起始值    private Long end;结束值    public static final Long critical = 100000L;临界值10w (即划分的区间段大小)    public ForkJoinCalcTask(Long start, Long end) &#123;        this.start = start;        this.end = end;    &#125;    @Override    protected Long compute() &#123;        判断是否是拆分完毕        Long lenth = end - start;        if (lenth &lt;= critical) &#123;            如果拆分完毕就相加            Long sum = 0L;            for (Long i = start; i &lt;= end; i++) &#123;                sum += i;            &#125;            return sum;        &#125; else &#123;            没有拆分完毕就开始拆分 (递归拆分的意思)            Long middle = (end + start)  2;计算的两个值的中间值            ForkJoinCalcTask leftTask = new ForkJoinCalcTask(start, middle);            ForkJoinCalcTask rightTask = new ForkJoinCalcTask(middle + 1, end);             方式1            right.fork();拆分，压入线程队列            left.fork();拆分，压入线程队列             方式2 更好的做法             方式1的缺点是: 假如程数量固定, 当前线程会将leftTaskrightTask分配下去,             自身并不会做任何事情, 会浪费一个线程            invokeAll(leftTask, rightTask);             等待任务执行结束合并其结果            return leftTask.join() + rightTask.join();        &#125;    &#125;&#125;\n测试类:\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class Test &#123;    ForkJoin实现    public static void test1() &#123;        long l = System.currentTimeMillis();        ForkJoinPool forkJoinPool = new ForkJoinPool();实现ForkJoin 就必须有ForkJoinPool的支持        ForkJoinTask&lt;Long&gt; task = new ForkJoinCalcTask(0L, 10000000000L);参数为起始值与结束值 (100亿)         注意invoke是阻塞方法         submit和execute是非阻塞方法, submit是异步的, 返回了ForkJoinTask(继承了Future),         通过Future接口的get可以阻塞获取结果        Long invoke = forkJoinPool.invoke(task); 压入线程队列        long l1 = System.currentTimeMillis();        System.out.println(invoke =  + invoke +   time:  + (l1 - l));        invoke = -5340232216128654848  time: 4661    &#125;    普通线程实现    public static void test2() &#123;        Long x = 0L;        Long y = 10000000000L;        long l = System.currentTimeMillis();        Long i;        for (i = 0L; i &lt;= y; i++) &#123;            x += i;        &#125;        long l1 = System.currentTimeMillis();        System.out.println(invoke =  + x +   time:  + (l1 - l));        invoke = -5340232216128654848  time: 75901    &#125;    Java 8 并行流的实现    public static void test3() &#123;        long l = System.currentTimeMillis();        long reduce = LongStream.rangeClosed(0, 10000000000L).parallel().reduce(0, Long::sum);        long l1 = System.currentTimeMillis();        System.out.println(invoke =  + reduce +   time:  + (l1 - l));        invoke = -5340232216128654848  time: 4366    &#125;    public static void main(String[] args) &#123;        test1();        test2();        test3();    &#125;&#125;\n源码分析\n待续…\n","tags":["锁","队列","线程池"],"path":"2019/04/22/Concurrent并发包讲解(二)/","external_link":""},{"title":"SpringCloud初体验","date":"2019-04-21T16:34:21.445Z","content":"SpringBoot1.x升级2.x\n1.spring-boot-starter-parent依赖改为2.x版本\n2.启动类修改SpringBootServletInitializer包名\n3.全局错误控制器ErrorController更换包名\n重写error路由\n12345678910111213141516@RequestMapping(value = &#123;error&#125;)@ResponseBodypublic Object error(HttpServletRequest request) &#123;\treturn getResponse(HttpCode.URI_NOT_FOUND, null, uri not found.);\tint status = (Integer) request.getAttribute(javax.servlet.error.status_code);\tif(status == 401) &#123;\t\treturn getResponse(HttpCode.LOGIN_FAIL, null, 未登陆);\t&#125; else if(status == 403) &#123;\t\treturn getResponse(HttpCode.PERMISSION_DENY, null, 未授权);\t&#125; else if(status == 404) &#123;\t\treturn getResponse(HttpCode.URI_NOT_FOUND, null, 资源未找到);\t&#125;  else if(status == 500) &#123;\t\treturn getResponse(HttpCode.INTERNAL_SERVER_ERROR, null, 系统异常);\t&#125;\treturn getResponse(HttpCode.INTERNAL_SERVER_ERROR, null, 系统异常);&#125;\n4.config配置~~WebMvcConfigurerAdapter~~已过时, 替换为WebMvcConfigurationSupport\n5.Pageable在SpringBoot2.x无法注入\n1234@Overridepublic void addArgumentResolvers(List&lt;HandlerMethodArgumentResolver&gt; argumentResolvers) &#123;\targumentResolvers.add(new PageableHandlerMethodArgumentResolver());&#125;\n6.application.yml的配置变更\n123server:  servlet: # 添加servlet节点    context-path: \n7.javax.validation替换org.hibernate.validator\nRibbon\n它是客户端负载均衡器, Eureka是基于AP的客户端发现, Ribbon会从注册中心(Eureka Server)拉取注册的服务列表到Client, 然后Ribbon通过剔除无效服务后再进行负载均衡策略, 选取一个服务进行直接调用\n\n\n服务发现\n主要是基于Eureka注册中心实现客户端发现服务列表, 即根据服务名找出所有服务实例列表\n服务选择规则\n根据策略从多个有效服务实例中选取一个进行调用,\n服务监听\n检测失效服务并进行剔除, 通过IPing接口的PingTask定时器任务, 默认pingIntervalSeconds=10, 即每10秒钟向Eureka Server发送一次ping包\n五大组件\n每个接口都可以自己实现并配置替换内置实现, 且经常会自定义IRule策略规则\nILoadBalancer\nServiceList 服务器列表的处理类, 用来维护服务器列表\nServerListFilter 服务器的过滤类\nIRule 我们经常会自定义策略规则\nIPing 查看服务器是否存活, 是定时器任务, 默认10sping一次\n流程:\n通过ServiceList获取有效的服务实例列表;\n再通过ServerListFilter过滤一些服务实例, 比如剔除负载高的或者通讯故障率高(短路)的;\n最后通过IRule负载均衡策略选取一个进行调用\n\n\n配置五大接口自定义实现\n配置可以通过ConfigurationManager配置实例类进行代码配置, 也可以通过application.yml配置\n\n\n\n- 自定义接口实现配置\n- 描述\n\n\n\n\n&lt;clientName&gt;.ribbon.NFLoadBalancerClassName\n需实现ILoadBalancer接口\n\n\n&lt;clientName&gt;.ribbon.NFLoadBalancerRuleClassName\n需实现IRule接口, 这个是我们可能经常需要自定义负载均衡策略规则\n\n\n&lt;clientName&gt;.ribbon.NFLoadBalancerPingClassName\n需实现IPing, 一般很少重写, 默认10s发送一次ping\n\n\n&lt;clientName&gt;.ribbon.NIWSServerListClassName\n需实现ServerList, 一般很少重写\n\n\n&lt;clientName&gt;.ribbon.NIWSServerListFilterClassName\n需实现ServerListFilter, 一般很少重写\n\n\n\n七个负载均衡策略规则\n随机 (Random), 轮询 (RoundRobin), 一致性哈希 (ConsistentHash), 哈希 (Hash), 加权（Weighted）…\n\n\n\n- Ribbon负载均衡规则\n- 规则描述\n\n\n\n\nRoundRobinRule(轮询-默认)\n简单轮询服务列表来选择服务器(默认)\n\n\nAvailabilityFilteringRule(排除高负载和短路)\n以下两种情况会被过滤掉 : 情况1 : 默认3次连接失败, 这台服务器就会被设置为&quot;短路&quot;状态, 短路持续30s, 再次连接失败则几何递增情况2 : 并发数过高的服务器, &lt;clientName&gt;.&lt;clientConfigNameSpace&gt;.ActiveConnectionsLimit配置并发连接上限\n\n\nWeightedResponseTimeRule(加权)\n为每一个服务器赋予一个权重值。服务器响应时间越长，这个服务器的权重就越小。这个规则会随机选择服务器，这个权重值会影响服务器的选择。\n\n\nZoneAvoidanceRule(区域划分)\n以区域可用的服务器为基础进行服务器的选择。使用Zone对服务器进行分类，这个Zone可以理解为一个机房、一个机架等\n\n\nBestAvailableRule(并发请求数最少)\n忽略哪些短路的服务器，并选择并发数较低的服务器。\n\n\nRandomRule(随机)\n随机选择一个可用的服务器\n\n\nRetryRule(重试)\n重试机制的选择逻辑\n\n\n\n附上AvailabilityFilteringRule规则的三个配置\n\n\n设置为短路的连接失败次数, 默认3次\nniws.loadbalancer.&lt;clientName&gt;.connectionFailureCountThreshold\n状态短路的持续时间, 默认30s\nniws.loadbalancer.&lt;clientName&gt;.circuitTripMaxTimeoutSeconds\n服务并发访问数量上限, 默认Integer.MAX_VALUE\n&lt;clientName&gt;.&lt;clientConfigNameSpace&gt;.ActiveConnectionsLimit\n\n\n自定义负载均衡策略\n123456789101112131415161718192021222324252627282930313233343536 自定义策略, 需要实现IRule接口 构建一个60%的概率选择8091端口, 40%概率选择8092端口的规则public class MyProbabilityRandomRule implements IRule &#123;\tILoadBalancer balancer = new BaseLoadBalancer();\t@Override\tpublic Server choose(Object key) &#123;\t\tList&lt;Server&gt; allServers = balancer.getAllServers();\t\tRandom random = new Random();\t\tfinal int number = random.nextInt(10);\t\tif (number &lt; 7) &#123;\t\t\treturn findServer(allServers,8091);\t\t&#125;\t\treturn findServer(allServers,8092);\t&#125;\tprivate Server findServer(List&lt;Server&gt; allServers, int port) &#123;\t\tfor (Server server : allServers) &#123;\t\t\tif (server.getPort() == port) &#123;\t\t\t\treturn server;\t\t\t&#125;\t\t&#125;\t\tSystem.out.println(NULL port=+port);\t\treturn null;\t&#125;\t@Override\tpublic void setLoadBalancer(ILoadBalancer lb) &#123;\t\tthis.balancer = lb;\t&#125;\t@Override\tpublic ILoadBalancer getLoadBalancer() &#123;\t\treturn this.balancer;\t&#125;&#125;\n测试类\n12345678910111213141516171819202122232425public class MyRuleClientApplication &#123;\tpublic static void main(String[] args) throws Exception &#123;\t\t 1、设置请求的服务器\t\tConfigurationManager.getConfigInstance().setProperty(happybks-client.ribbon.listOfServers,\t\t\t\tlocalhost:8091,localhost:8092);  1\t\t 2、 配置规则处理类\t\t本示例略，先默认使用其默认负载均衡策略规则\t\tConfigurationManager.getConfigInstance().setProperty(happybks-client.ribbon.NFLoadBalancerRuleClassName,MyProbabilityRandomRule.class.getName());\t\t 3、获取 REST 请求客户端\t\tRestClient client = (RestClient) ClientFactory.getNamedClient(happybks-client);\t\t 4、创建请求实例\t\tHttpRequest request = HttpRequest.newBuilder().uri(carsInfoonsale).build();\t\t 5、发 送 10 次请求到服务器中\t\tfor (int i = 0; i &lt; 10; i++) &#123;\t\t\tSystem.out.println(the +(i+1)+th: );\t\t\tHttpResponse response = client.executeWithLoadBalancer(request);\t\t\tString result = response.getEntity(String.class);\t\t\tSystem.out.println(result);\t\t&#125;\t&#125;&#125;\n配置\n1234# 配置自定义负载均衡规则: &lt;clientName&gt;.ribbon.NFLoadBalancerRuleClassName: &lt;自定义类限定名&gt;product-server:  ribbon:    NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RoundRobinRule\n参考 :\nRibbon负载均衡器\nFeign\n这是一个类似Retrofit的http客户端调用组件, 因为和Dubbo RPC调用不同, SpringCloud采用了Http Restful形式进行服务调用;\nFeign使用HttpClient和OkHttp3\nSpringCloud的使用到Ribbon客户端负载均衡调用有三类 :\n\n\nRestTemplate\nFeign\nZuul服务网关 (现已使用SpringCloud GateWay替换)\n\n\n首先说明几者逻辑关系 :\n\nZuul服务网关 底层使用了Ribbon客户端负载均衡\nRibbon有两个实现: HttpClient和OkHttp3, 默认使用的前者, 当然你可以配置使用后者\n\n1234&lt;dependency&gt;\t&lt;groupId&gt;com.squareup.okhttp3&lt;groupId&gt;\t&lt;artifactId&gt;okhttp&lt;artifactId&gt;&lt;dependency&gt;\n123456# application.yml添加ribbon配置ribbon:  httpclient:     enabled: false # 默认开启需要禁用  okhttp:     enabled: true\n2. Fegin 也使用了Ribbon, 当然可以直接使用上述配置来更改Ribbon的默认配置, 但更推荐使用Fegin的配置来替换;\n默认有四种实现:\n(1) Default: 使用HttpURLConnection构建\n(2) LoadBalancerFeignClient: 使用Apache HttpClient构建\n(3) OkHttpClient: 使用OkHttp3构建\n(4) TraceFeignClient: 这是sleuth实现的\n12345&lt;!-- feign整合OkHttp --&gt;&lt;dependency&gt;\t&lt;groupId&gt;io.github.openfeign&lt;groupId&gt;\t&lt;artifactId&gt;feign-okhttp&lt;artifactId&gt;&lt;dependency&gt;\n123456# 在application.yml文件配置feginfeign:  httpclient:      enabled: false #关闭, 重点还是在于依赖了哪个jar包  okhttp:      enabled: true\nFeign使用步骤\n(1)定义服务对外暴露接口\n比如拿product-server服务举例 :\n首先添加maven依赖\n12345&lt;!-- 注意老版本叫做spring-cloud-starter-feign --&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework.cloud&lt;groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;artifactId&gt;&lt;dependency&gt;\n提供对外调用接口jar包, 这和RPC形式上一致, 但有所区别\n123456789@FeignClient(name = product-server)public interface ProductClient &#123;    @PostMapping(productlistForOrder)    List&lt;ProductInfoOutput&gt; listForOrder(@RequestBody List&lt;String&gt; productIdList);    @PostMapping(productdecreaseStock)    void decreaseStock(@RequestBody List&lt;DecreaseStockInput&gt; decreaseStockInputList);&#125;\n(2)调用方添加服务方接口依赖\n1234&lt;dependency&gt;    &lt;groupId&gt;org.doyo&lt;groupId&gt;    &lt;artifactId&gt;product-client&lt;artifactId&gt;&lt;dependency&gt;\n注意启动类上需要添加一个注解@EnableFeignClients\n123456789@SpringBootApplication@EnableDiscoveryClient 注意添加接口包扫描路径, 否则不会扫描并注入@EnableFeignClients(basePackages = org.doyo.product.client)public class OrderApplication &#123;    public static void main(String[] args) &#123;        SpringApplication.run(OrderApplication.class, args);    &#125;&#125;\n安装rabbitmq\n由于docker.hub速度太慢, 先设置仓库镜像加速\n123456789101112vim etcdockerdaemon.json# 添加如下代码# &#123;#  registry-mirrors: [https:fy707np5.mirror.aliyuncs.com]# &#125;#systemctl daemon-reloadsystemctl restart docker---# 如果是mac版本# preferences-&gt;daemon-&gt;registry mirrors 内添加镜像地址即可\n拉取rabbitmq镜像, 并启动\n1234docker pull rabbitmq:3.7.14-management# 不指定账号密码默认都是guestdocker run -itd --hostname my-rabbit --name my-rabbit -e RABBITMQ_DEFAULT_USER=user -e RABBITMQ_DEFAULT_PASS=password -p 5672:5672 -p 15672:15672 rabbitmq:3.7.14-management\n端口说明 :\n\n4369：epmd，RabbitMQ节点和CLI工具使用的对等发现服务\n5672,5671：AMQP 0-9-1和1.0客户端使用没有和使用TLS\n25672：用于节点间和CLI工具通信（Erlang分发服务器端口），并从动态范围分配（默认情况下限于单个端口，计算为AMQP端口+ 20000）。除非确实需要这些端口上的外部连接（例如，群集使用联合或CLI工具在子网外的计算机上使用），否则不应公开这些端口。有关详情， 请参阅网络指南\n35672-35682：由CLI工具（Erlang分发客户端端口）用于与节点通信，并从动态范围（计算为服务器分发端口+ 10000到服务器分发端口+ 10010）进行分配。有关详情， 请参阅网络指南\n15672：HTTP API客户端，管理UI和rabbitmqadmin（仅当启用了管理插件时）\n61613,61614：没有和使用TLS的STOMP客户端（仅当启用了STOMP插件时）\n1883,8883:( 如果启用了MQTT插件，则没有和使用TLS的MQTT客户端\n15674：STOMP-over-WebSockets客户端（仅当启用了Web STOMP插件时）\n15675：MQTT-over-WebSockets客户端（仅当启用了Web MQTT插件时）\n\nRedis启动命令\n123docker stop redisdocker rm redisdocker run -itd -p 6379:6379 -v `pwd`data:data --name redis -v `pwd`redis.conf:etcredisredis_default.conf hub.c.163.compublicredis:2.8.4\nConfig\n主要用于动态更新和加载配置文件\n添加依赖\n服务端依赖\n1234567891011121314151617181920&lt;!-- config server --&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework.cloud&lt;groupId&gt;    &lt;artifactId&gt;spring-cloud-config-server&lt;artifactId&gt;&lt;dependency&gt;&lt;!-- bus --&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework.cloud&lt;groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;artifactId&gt;&lt;dependency&gt;&lt;!-- monitor --&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework.cloud&lt;groupId&gt;    &lt;artifactId&gt;spring-cloud-config-monitor&lt;artifactId&gt;&lt;dependency&gt;&lt;!-- 本身就是一个config服务, 所以需要注册Eureka --&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework.cloud&lt;groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;artifactId&gt;&lt;dependency&gt;\n客户端依赖\n12345678&lt;dependency&gt;    &lt;groupId&gt;org.springframework.cloud&lt;groupId&gt;    &lt;artifactId&gt;spring-cloud-config-client&lt;artifactId&gt;&lt;dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework.cloud&lt;groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;artifactId&gt;&lt;dependency&gt;\n服务端注解@EnableConfigServer\n12345678@SpringBootApplication@EnableDiscoveryClient@EnableConfigServer  需要指定git地址public class ConfigApplication &#123;    public static void main(String[] args) &#123;        SpringApplication.run(ConfigApplication.class, args);    &#125;&#125;\n配置文件\n需要指定git仓库地址\n1234567891011121314151617181920212223242526server:  port: 8083spring:  application:    name: config-server #服务名  cloud:    config:      server:        git: #git仓库地址          uri: https:github.comDoyuLycloud-config-repo          username: duyud@qq.com          password: duyu1988          # 本地clone地址, 最好不要在本项目里, 避免被覆盖          basedir: Usersappleideaspring-cloud-bingo-config-repoeureka:  client:    service-url:      defaultZone: http:localhost:8761eurekamanagement:  #config的UI管理界面配置  endpoints:    web:      expose: *env:  devlable:  master\n映射规则\n\n{name}-{profiles}.yml\n{lable}{name}-{profiles}.yml\n支持json, yml, properties三种后缀格式\nname: 配置文件名(必须是服务名, 否则无法匹配)\nprofiles: 环境, 可以取名env, test等随意填写\nlable: 表示git分支, 不写表示master分支\n\n1234567891011121314############################################ 支持三种后缀格式自动互转换###########################################`http:localhost:8083order-server.yml``http:localhost:8083order-server.json``http:localhost:8083order-server.properties`############################################&#123;lable&#125;表示分支branch, 不填写默认master分支#&#123;profiles&#125;代表什么环境的配置, 甚至可以写自己的名字, 若没有相当于没写(容错)###########################################`http:localhost:8083masterorder-server-dev.yml``http:localhost:8083releaseorder-server.yml``http:localhost:8083developorder-server-test.yml`\n自定义git log\n意思是将以下命令写到~.gitconfig的[alias]下面\n12# 定义一个lg别名, 格式化log日志输出git config --global alias.lg log --graph --pretty=format:%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset\n进入~.gitconfig查看\n1234567891011[user]        name = duyu        email = duyud@qq.com[color]        ui = true[alias]        lg = log --graph --pretty=format:%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset[credential]        helper = store[core]        autocrlf = false\n当然也可以直接输入命令, 只是很繁琐\n1git log --graph --pretty=format:%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset --abbrev-commit\n注意事项\n\nbootstrap.yml优先读取配置\n\n服务名spring.application.name必须配置在项目里的bootstrap.yml里, 不管是放在本地还是在远端\n1234spring:  application:    #经测试, 服务名必须配置在bootstrap.yml里才能通过, 否则会报数据库配置错误    name: order-server\n\norder.yml, order-dev.yml远端配置合并问题\n\n如果本地配置config拉取的是order-dev.yml, 如下 :\n123456789spring:  application:    name: order-serverv #经测试, 服务名必须配置在bootstrap.yml里才能通过, 否则会报数据库配置错误  cloud:    config:      discovery:        enabled: true        service-id: config-server      profile: dev # git上的配置文件必须叫&#123;order-server&#125;或者&#123;order-server-dev&#125;\nOrder服务通过config服务拉取到的配置会将order.yml, order-dev.yml两个配置进行合并; 有时候order.yml的内容多于order-dev.yml时, 会发现多出一些配置选项;\n如果拉取的是order.yml则不会合并\nBus\n是一个通知config更新的组件\n正常情况下所有服务实例都从config服务获取配置文件, 问题在于一旦启动后是不知道git仓库是否有更新;\nsping-cloud-bus作用就是用于通知配置更新的组件\n\n\ngit通过webhook调用actuatorbus-refresh接口通知config服务\nconfig服务会将收到的消息写入rabbitmq消息队列\n其他服务通过spring-cloud-starter-bus-amqpjar包就可以从消息队列取出消息进行重新加载更新\n\n\n使用步骤:\n1.安装RabbitMq\n2.所有服务和config服务添加依赖\n1234&lt;dependency&gt;    &lt;groupId&gt;org.springframework.cloud&lt;groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;artifactId&gt;&lt;dependency&gt;\n3.config服务为git仓库的webhook开启actuatorbus-refresh接口\n123456# 在spring-cloud-config 服务端配置此节点management:  endpoints:    web:      exposure:        include: * #默认有health,info两个状态的通知, 通知接口为actuatorbus-refresh, 用于给git仓库的webhook调用\n4.使用@RefreshScope\n需要添加@RefreshScope注解来让重新加载的配置生效, 否则不生效\n12345678910@Component@RefreshScope 注意如果配置需要生效, 必须在类上加此注解public class EnvTestBean &#123;    @Value($&#123;env&#125;)    private String env;    public String print() &#123;        return env;    &#125;&#125;\n5.配置webhook请求地址\n不可能每次更新配置之后手动调用actuatorbus-refresh接口, 所以需要配置此通知接口\n123使用内网穿透工具, 比如natapp配置webhook通知地址, 可以只选push类型通知, 不填密钥http:e9cfxj.natappfree.ccmonitor (指向本地8080 config服务端口)\n使用curl发起测试\n测试发现的确通知了Order服务刷新配置, 且在2~4秒内生效, 个人猜测生效时长在于服务的代码量大小\n1curl -v -X POST http:localhost:8083actuatorbus-refresh\n解释下curl命令参数\n\n-v 查看详细请求信息\n-X PUT  -X POST  -X DELETE 发起putpostdelete请求\n-d 参数\n-d “name=duyu&amp;age=28”\n-H “Content-Type:applicationjson” -d ‘“name”:“duyu”,“age”:28’\n-H 如上所示, 用于指定header\n-F 文件上传\n-F “file=@UsersduyuDownloads401.png” -H “token: 222” -v\nman curl 更新信息请通过此命令查阅\n\n踩坑\n由于springcloud在飞速迭代, 难免很多bug或者升级导致的代码和配置属性不一致的问题\n下面记录几个BUG\nspring-cloud-bus无法触发更新服务实例\n调试发现手动触发能更新配置\n1curl -v -X POST http:localhost:8083actuatorbus-refresh\n但是使用webhook则无法触发更新\n发现http:e9cfxj.natappfree.ccmonitor的确已经通知了config服务, 并且rabbitmq也已经写入了消息, order服务也消费了服务, 但是就是没有触发更新;\n只有调试spring-cloud-bus源码, 使用的版本为2.0.0.RELEASE\n1.下载源码\ngit clone https:github.comspring-cloudspring-cloud-bus.git\n2.切换版本到tag为2.0.0.RELEASE的commit id\ngit reset --hard 1974b23\n3.更改类BusEnvironmentPostProcessor中getDefaultServiceId方法的代码\n123private String getDefaultServiceId(ConfigurableEnvironment environment) &#123;\treturn $&#123;vcap.application.name:$&#123;spring.application.name:application&#125;&#125;:$&#123;vcap.application.instance_index:$&#123;spring.application.index:$&#123;local.server.port:$&#123;server.port:0&#125;&#125;&#125;&#125;:$&#123;vcap.application.instance_id:$&#123;random.value&#125;&#125;;&#125;\n其中spring.application.index改为spring.cloud.config.profile\n12private String getDefaultServiceId(ConfigurableEnvironment environment) &#123;\treturn $&#123;vcap.application.name:$&#123;spring.application.name:application&#125;&#125;:$&#123;vcap.application.instance_index:$&#123;spring.application.index:$&#123;local.server.port:$&#123;server.port:0&#125;&#125;&#125;&#125;:$&#123;vcap.application.instance_id:$&#123;random.value&#125;&#125;;\nMQ消息队列的使用\n首先说明一下, RabbitMQ是基于AMQP协议(2003), ActiveMQ是基于JMS, 所以前者注重数据协议, 后者注重API接口的规约\n所以RabbitMQ天生跨语言, ActiveMQ则只使用于java, 跨语言很麻烦, 需要其他语言实现客户端\n引入依赖\n以下三个都和mq消息队列有关\n1234567891011121314151617 &lt;!-- rabbitmq --&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;groupId&gt;    &lt;artifactId&gt;spring-boot-starter-amqp&lt;artifactId&gt;&lt;dependency&gt;&lt;!-- stream --&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework.cloud&lt;groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;artifactId&gt;&lt;!--spring-cloud-starter-stream-kafka--&gt;&lt;dependency&gt;&lt;!-- spring-cloud-bus自动刷新config --&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework.cloud&lt;groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;artifactId&gt;&lt;dependency&gt;\n配置\nrabbitmq配置\n1234567spring:  rabbitmq:    # addresses: amqp:127.0.0.1:5672    host: 127.0.0.1    port: 5672    username: guest    password: guest\nspring-cloud-sream配置\n1234567891011spring:  cloud:    stream:      bindings:        myStream: # 队列名(也是exchange名字, binding默认创建为#)          group: order-server # 消费者服务名字, 不指定则会多个相同服务实例都接收到消息          contentType: applicationjson # 默认队列存储的是base64编码字符串, 比如可以为textplain          #destination: myStream-exchange # 指定exchange名字的队列          #binder:          #consumer:          #producer\n注解的使用\n\n@RabbitListener 消费者\n\n方式1 : 不会主动创建队列, 需要去rabbitmq管理页面手动添加\n1@RabbitListener(queues = orderQueue)\n方式2 : 主动创建队列\n1@RabbitListener(queuesToDeclare = @Queue(orderQueue))\n方式3 : 主动创建队列, 同时Exchange和Queue绑定\nexchange是交换机, queue是队列, RabbitMQ具体实现后面单独讲解\n1234@RabbitListener(bindings = @QueueBinding(            exchange = @Exchange(orderExchange),            value = @Queue(test-order-queue)    ))\n方式4 : 主动创建队列, 同时Exchange和Queue绑定, 同时进行分组\n即不同的服务分组消费不同的队列, 否则会出现多个服务实例重复消费一条消息\n12345@RabbitListener(bindings = @QueueBinding(            exchange = @Exchange(orderExchange),            key = fruit,                         binding-key=fruit 水果订单分组            value = @Queue(fruit-order-queue)    绑定到fruit-order-queue队列, 注意没有都会自动创建    ))\n\n生产者\n\n123456789@Autowiredprivate AmqpTemplate amqpTemplate;public void mqSender() &#123;     参数1: exchange交换机     参数2: 队列名     参数3: 传输的数据    amqpTemplate.convertAndSend(orderExchange, digital, now  + new Date());&#125;\nspring-cloud-stream的使用\nspringcloud 对消息队列的使用还提供了steam, 它封装了MQ的不同, 来看如下图 :\n\n后续补充…\nZuul\n路由+ 过滤器 = zuul\n本质是一个servlet应用, ZuulServlet类似SpringMvc的DispatcherServlet, 所有的Request都要经过ZuulServlet的处理\n实现了一系列的filter,  类比Servlet框架的filter, 或者也和springmvc的interceptor拦截器理念是一致的;\n\n用以实现如下功能 :\n\n验证与安全保障: 识别面向各类资源的验证要求并拒绝那些与要求不符的请求。\n审查与监控: 在边缘位置追踪有意义数据及统计结果，从而为我们带来准确的生产状态结论。\n动态路由: 以动态方式根据需要将请求路由至不同后端集群处。\n压力测试: 逐渐增加指向集群的负载流量，从而计算性能水平。\n负载分配: 为每一种负载类型分配对应容量，并弃用超出限定值的请求。\n静态响应处理: 在边缘位置直接建立部分响应，从而避免其流入内部集群。\n多区域弹性: 跨越AWS区域进行请求路由，旨在实现ELB使用多样化并保证边缘位置与使用者尽可能接近。\n\n四种类型过滤器\n1.前置(Pre)\n限流, 鉴权, 跨域, 参数校验, 请求转发, 反向代理;\n配合OAuth2.0做权限验证和csrf, SQL注入, DDos, 盗链…\n12345678910111213141.ServletDetectionFilter:优先级-3, 最先被执行; 用来检测当前请求是通过Spring的DispatcherServlet处理运行的, 还是通过ZuulServlet来处理运行的2.Servlet30WrapperFilter:优先级-2, 第二个执行; 将原始的HttpServletRequest包装成Servlet30RequestWrapper对象3.FormBodyWrapperFilter:优先级-1, 第三个执行; 该过滤器仅对两类请求生效，第一类是Context-Type为applicationx-www-form-urlencoded的请求，第二类是Context-Type为multipartform-data并且是由String的DispatcherServlet处理的请求4.DebugFilter:优先级1, 第四个执行; 该过滤器会根据配置参数zuul.debug.request和请求中的debug参数来决定是否执行过滤器中的操作5.PreDecorationFilterpre阶段最后被执行的过滤器, 为当前请求做一些预处理, 比如路由匹配信息和设置Headers头域信息, 后续过滤器通过RequestContext.getCurrentContext()能获取到\n2.路由(Route)\n123456789101.RibbonRoutingFilter优先级10, route阶段第一个被执行; 只对请求上下文中存在serviceId参数的请求进行处理;直接向routeHost参数的物理地址发起请求作用是通过使用ribbon和hystrix来向服务实例发起请求, 并将服务实例的请求结果返回2.SimpleHostRoutingFilter优先级100, route阶段第二个被执行; 只对请求上下文存在routeHost参数的请求进行处理, 即只对通过url配置路由规则的请求生效作用是直接向routeHost参数的物理地址发起请求(直接使用HttpClient, 没有经过ribbon和hystrix)3.SendForwardFilter优先级500, route阶段第三个被执行; 只对请求上下文中存在的forward.do参数进行处理请求, 即用来处理路由规则中的forward本地跳转装配\n3.后置(Post)\n统计, 日志记录, 返回结果包装…\n123451.SendErrorFilter优先级0, post阶段第一个被执行;2.SendResponseFilter优先级1000, post阶段最后执行; 检查请求上下文中是否包含请求响应相关的头信息, 响应数据流或是响应体\nFilterConstants常量类\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192public class FilterConstants &#123;   KEY constants -----------------------------------  **   * Zuul &#123;@link com.netflix.zuul.context.RequestContext&#125; key for use in &#123;@link org.springframework.cloud.netflix.zuul.filters.pre.ServletDetectionFilter&#125;   *  public static final String IS_DISPATCHER_SERVLET_REQUEST_KEY = isDispatcherServletRequest;  **   * Zuul &#123;@link com.netflix.zuul.context.RequestContext&#125; key for use in &#123;@link org.springframework.cloud.netflix.zuul.filters.route.SendForwardFilter&#125;   *  public static final String FORWARD_TO_KEY = forward.to;  **   * Zuul &#123;@link com.netflix.zuul.context.RequestContext&#125; key for use in TODO: determine use   *  public static final String PROXY_KEY = proxy;  **   * Zuul &#123;@link com.netflix.zuul.context.RequestContext&#125; key for use in &#123;@link org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter&#125;   *  public static final String REQUEST_ENTITY_KEY = requestEntity;  **   * Zuul &#123;@link com.netflix.zuul.context.RequestContext&#125; key for use in to override the path of the request.   *  public static final String REQUEST_URI_KEY = requestURI;  **   * Zuul &#123;@link com.netflix.zuul.context.RequestContext&#125; key for use in &#123;@link org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter&#125;   *  public static final String RETRYABLE_KEY = retryable;  **   * Zuul &#123;@link com.netflix.zuul.context.RequestContext&#125; key for use in &#123;@link org.springframework.cloud.netflix.zuul.filters.post.SendResponseFilter&#125;   *  public static final String ROUTING_DEBUG_KEY = routingDebug;  **   * Zuul &#123;@link com.netflix.zuul.context.RequestContext&#125; key for use in &#123;@link org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter&#125;   *  public static final String SERVICE_ID_KEY = serviceId;  **   * Zuul &#123;@link com.netflix.zuul.context.RequestContext&#125; key for use in &#123;@link org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter&#125;   *  public static final String LOAD_BALANCER_KEY = loadBalancerKey;   ORDER constants -----------------------------------  **   * Filter Order for &#123;@link DebugFilter#filterOrder()&#125;   *  public static final int DEBUG_FILTER_ORDER = 1;  **   * Filter Order for &#123;@link org.springframework.cloud.netflix.zuul.filters.pre.FormBodyWrapperFilter#filterOrder()&#125;   *  public static final int FORM_BODY_WRAPPER_FILTER_ORDER = -1;  **   * Filter Order for &#123;@link org.springframework.cloud.netflix.zuul.filters.pre.PreDecorationFilter&#125;   *  public static final int PRE_DECORATION_FILTER_ORDER = 5;  **   * Filter Order for &#123;@link org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter#filterOrder()&#125;   *  public static final int RIBBON_ROUTING_FILTER_ORDER = 10;  **   * Filter Order for &#123;@link org.springframework.cloud.netflix.zuul.filters.post.SendErrorFilter#filterOrder()&#125;   *  public static final int SEND_ERROR_FILTER_ORDER = 0;  **   * Filter Order for &#123;@link SendForwardFilter#filterOrder()&#125;   *  public static final int SEND_FORWARD_FILTER_ORDER = 500;  **   * Filter Order for &#123;@link org.springframework.cloud.netflix.zuul.filters.post.SendResponseFilter#filterOrder()&#125;   *  public static final int SEND_RESPONSE_FILTER_ORDER = 1000;  **   * Filter Order for &#123;@link org.springframework.cloud.netflix.zuul.filters.route.SimpleHostRoutingFilter#filterOrder()&#125;   *  public static final int SIMPLE_HOST_ROUTING_FILTER_ORDER = 100;  **   * filter order for &#123;@link Servlet30WrapperFilter#filterOrder()&#125;   *  public static final int SERVLET_30_WRAPPER_FILTER_ORDER = -2;  **   * filter order for &#123;@link org.springframework.cloud.netflix.zuul.filters.pre.ServletDetectionFilter#filterOrder()&#125;   *  public static final int SERVLET_DETECTION_FILTER_ORDER = -3;   Zuul Filter TYPE constants -----------------------------------  **   * &#123;@link ZuulFilter#filterType()&#125; error type.   *  public static final String ERROR_TYPE = error;  **   * &#123;@link ZuulFilter#filterType()&#125; post type.   *  public static final String POST_TYPE = post;  **   * &#123;@link ZuulFilter#filterType()&#125; pre type.   *  public static final String PRE_TYPE = pre;  **   * &#123;@link ZuulFilter#filterType()&#125; route type.   *  public static final String ROUTE_TYPE = route;   OTHER constants -----------------------------------  **   * Zuul &#123;@link com.netflix.zuul.context.RequestContext&#125; key for use in &#123;@link org.springframework.cloud.netflix.zuul.filters.route.SendForwardFilter&#125;   *  public static final String FORWARD_LOCATION_PREFIX = forward:;  **   * default http port   *  public static final int HTTP_PORT = 80;  **   * default https port   *  public static final int HTTPS_PORT = 443;  **   * http url scheme   *  public static final String HTTP_SCHEME = http;  **   * https url scheme   *  public static final String HTTPS_SCHEME = https;   HEADER constants -----------------------------------  **   * X-* Header for the matching url. Used when routes use a url rather than serviceId   *  public static final String SERVICE_HEADER = X-Zuul-Service;  **   * X-* Header for the matching serviceId   *  public static final String SERVICE_ID_HEADER = X-Zuul-ServiceId;  **   * X-Forwarded-For Header   *  public static final String X_FORWARDED_FOR_HEADER = X-Forwarded-For;  **   * X-Forwarded-Host Header   *  public static final String X_FORWARDED_HOST_HEADER = X-Forwarded-Host;  **   * X-Forwarded-Prefix Header   *  public static final String X_FORWARDED_PREFIX_HEADER = X-Forwarded-Prefix;  **   * X-Forwarded-Port Header   *  public static final String X_FORWARDED_PORT_HEADER = X-Forwarded-Port;  **   * X-Forwarded-Proto Header   *  public static final String X_FORWARDED_PROTO_HEADER = X-Forwarded-Proto;  **   * X-Zuul-Debug Header   *  public static final String X_ZUUL_DEBUG_HEADER = X-Zuul-Debug-Header;&#125;\n4.错误(Error)\n参考: zuul过滤器详解\n生命周期\n\n123456789101112131415161718192021 ZuulServlet的doFilter方法核心流程try &#123;    preRoute();&#125; catch (ZuulException e) &#123;    error(e);    postRoute();    return;&#125;try &#123;    route();&#125; catch (ZuulException e) &#123;    error(e);    postRoute();    return;&#125;try &#123;    postRoute();&#125; catch (ZuulException e) &#123;    error(e);    return;&#125;\n可以动态加载filter, 它的过滤器是由groovy实现的, 放在指定目录, zuul server会定期扫描目录下的文件的变化, 动态的[读取][编译][运行]这些filter, 请查阅GroovyCompiler;\nRequestContext 生命周期管理, 因为ZuulServlet是单例多线程, 这就要求RequestContext即要线程安全又要Request安全, 所以使用了ThreadLocal来存储线程上下文数据 \n路由匹配规则\nyml配置\n主要是配置路由规则, 接口过滤名单ignored-patterns, http header会默认阻止三个cookie往服务路由转发\nCookie,Set-Cookie,Authorization\n1234567891011121314151617zuul:  #全部服务统一忽略敏感头  #sensitive-headers:  routes:    #自定义路由规则, 是一个map, key可以随意写, 通过 applicationroutes 接口可以看到所有路由规则    myproduct:      #自定义的路由url      path: myproduct**      #路由目的地服务名      serviceId: product-server      #zuul默认禁止三个敏感Header信息往内部服务传递[Cookie, Set-Cookie, Authorization], 设置黑名单为空即可      sensitiveHeaders:    #简洁写法, key必须是服务名    order-server: myorder**  ignored-patterns: #禁止外部调用     - product-serverproductlist  #或者通配符 **productlist     - myproductproductlist\n默认路由规则为\n123http:localhost:8083&#123;具体服务名&#125;&#123;具体服务的接口&#125;#比如http:localhost:8083product-serverproductlist\n上面配置自定义路由后, 还可以支持如下路由\n123http:localhost:8083&#123;自定义映射服务名&#125;&#123;具体服务的接口&#125;#比如http:localhost:8083myproductproductlist\n动态刷新配置\n12345678@Componentpublic class ZuulConfig &#123;    @ConfigurationProperties(zuul)    @RefreshScope    public ZuulProperties zuulProperties()&#123;        return new ZuulProperties();    &#125;&#125;\n对比\n123456789@Component@Data@ConfigurationProperties(animal)@RefreshScopepublic class Animal &#123;    private String name;    private Integer age;    private String kind;&#125;\n自定义filter\n限流过滤器\n这里可以做限流, 鉴权… (注意限流一定是在pre类型的最前面)\n限流可以有很多种方式\n参考: https:www.cnblogs.combiglittleantp8979915.html\n算法如下图：\n\n\n\n令牌桶限流算法\ngoogle开源的guava工具包就有实现\n原理:\n\n\n\n令牌桶(token bucket)以固定速率生成令牌token, 桶有最大容量, 一旦满了就溢出丢弃\n请求到达后从bucket获取一个token, 若能获取则放行, 若token耗尽则直接拒绝请求(丢弃request)\n\n\n\n漏桶算法(leaky bucket)\n本质即队列queue缓存请求, 并匀速转发, 队列满则丢弃\nnginx限流\nzuul网关限流\n\n\nnginx默认是漏桶算法\n\n\n$binary_remote_addr\n表示基于remote_addr(客户端IP)来做限流, binary_前缀 的目是压缩内存占用量\nzone=myRateLimit:10m\n定义共享内存区来存储访问信息, 表示名为myRateLimit的10M内存区域, 10M大致能保存16w IP请求信息\nrate=10rs\n设置最大访问速率, 表示每秒最多处理10个请求; nginx是ms毫秒为单位, 意味着每100毫秒处理一个请求, 之内如果还有其他请求到达, 则丢弃\n\n\n漏桶算法主要特点就是保证绝对平稳的速度, 所以是无法处理突发流量的\n注意下面burst=20 nodelay;\n\n\nburst=20\n它表示当请求量超过阈值该如何处理突发流量; 当前配置下如果100ms内(可理解为同时)到达21个请求, 则处理第一个, 其余20个入队, 每隔100ms取出一个进行处理, 请求数大于21, 拒绝处理, 配置直接返回503\nnodelay\n单独设置burst并不实用, 假设 burst=50 , rate依然为10rs, 排队中的50个请求虽然每100ms会处理一个, 但第50个请求却需要等待 50 * 100ms = 5s\nnodelay 表示这20个请求立马处理, 不能延迟\n不过，即使这20个突发请求立马处理结束，后续来了请求也不会立马处理。burst=20 相当于缓存队列中占了20个坑，即使请求被处理了，这20个位置这只能按 100ms一个来释放\n\n\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#动态加载模块，必须写道开头load_module modulesngx_stream_module.so;#cpu核心数 * 2worker_processes  4;#配置nginx打开最大文件数 (每个工作进程绑定一个cpu，worker_cpu_affinity配置)worker_rlimit_nofile   102400;#工作进程使用哪个cpu的核心(下面表示四核序列)worker_cpu_affinity 0001 0010 0100 1000;pid   logsnginx.pid;events &#123;    use epoll;    worker_connections  10240;&#125;http &#123;    include       mime.types;    default_type  applicationoctet-stream;    log_format  main  &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos;                      &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos;                      &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;;    sendfile           on;    keepalive_timeout  30;    #默认允许客户端最大上传文件大小    client_max_body_size 8m;    ####################### 核心 #######################    # ngx_http_limit_req_module 模块采用漏桶算法    limit_req_zone $binary_remote_addr zone=myRateLimit:10m rate=10rs;    #超出限制时, 统一返回状态码    limit_conn_status 503;    # 负载均衡配置\tupstream myserver &#123;\t\tserver 192.168.10.253:8090;\t&#125;\tserver &#123;\t\tlisten 80;\t\tlocation  &#123;\t\t    #limit_conn addr 1; #并发数限制\t\t    # 指定限流zone\t\t\tlimit_req zone=myRateLimit burst=20 nodelay;\t\t\t# 转发到负载均衡器\t\t\tproxy_pass http:myserver;\t\t&#125;\t&#125;\t##################################################&#125;\n限流过滤器\n12345678910111213141516171819202122232425262728293031323334public class RateLimiterFilter extends ZuulFilter &#123;    private static final RateLimiter RETELIMITER = RateLimiter.create(100); 每秒放100个token    @Override    public String filterType() &#123;        return PRE_TYPE;    &#125;    @Override    public int filterOrder() &#123;         限流要在所有pre类型过滤器之前        return SERVLET_DETECTION_FILTER_ORDER - 1;    &#125;    @Override    public boolean shouldFilter() &#123;        return true;    &#125;    @Override    public Object run() throws ZuulException &#123;        **         * 尝试获取token, 没有则会失败         * 注意: rateLimiter.tryAcquire(500, TimeUnit.MILLISECONDS)是判断500ms内是否能拿到令牌, 并不是真会阻塞1s         * 它是根据令牌生成速率和当前时间做对比,         * 比如100个令牌每秒, 在前100ms内到达101个请求, 说明令牌耗尽, 需要等待至少900ms才能拿到令牌, 所以没有等待必要, 立刻失败         *        if (RETELIMITER.tryAcquire())&#123;        &#125;        return null;    &#125;&#125;\n跨域过滤器CSRF\nspring提供了一个注解@CrossOrigin(allowCredentials = &quot;true&quot;)\nallowCredentials=&quot;true&quot;指cookie允许跨域\n问题在于它只能添加在类或方法上, 所以一劳永逸的办法还是添加过滤器\nSpring已经提供了CorsFilter, 配置一下即可\n1234567891011121314151617@Componentpublic class CorsConfig &#123;    @Bean    public CorsFilter corsFilter()&#123;        final UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource();        CorsConfiguration config = new CorsConfiguration();        config.setAllowCredentials(true);  设置允许cookie跨域        config.setAllowedOrigins(Arrays.asList(*));  设置允许跨域的域名        config.setAllowedHeaders(Arrays.asList(*));        config.setAllowedMethods(Arrays.asList(*));  设置允许GETPUTPOSTDELETE等        config.setMaxAge(300l); 设置跨域生存时间, 单位:S        source.registerCorsConfiguration(**, config); 设置对所有接口路径生效        return new CorsFilter(source);    &#125;&#125;\nSpring-Cloud-Gateway\nHystrix\n\n\n服务降级\n依赖隔离\n服务熔断\n缓存 (请求缓存,请求合并)\n监控 (Hystrix Dashboard)\n\n\n服务降级\nqps过大, 或者秒杀, 双11这种流量高峰期, 必须对核心服务提供高可用, 对非核心服务则可降级操作, 比如返回&quot;服务繁忙中…&quot;\n\n\n@HystrixCommand注解\nfallBackMethod(回退函数)中实现具体的降级逻辑, 比如导向一个繁忙提示页面, 或者一个包含友好提示的json数据\n\n\n\n添加依赖\n\n12345&lt;!-- 注意1.x时使用 spring-cloud-starter-hystrix --&gt;&lt;dependency&gt;  &lt;groupId&gt;org.springframework.cloud&lt;groupId&gt;  &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;artifactId&gt;&lt;dependency&gt;\n\n启动类添加注解@EnableCircuitBreaker\n\n开启熔断器的意思\n123456 必须添加包路径, 否则编译报错, 第二个路径用于测试@EnableFeignClients(basePackages = &#123;org.doyo.product.client, org.doyo.order.client&#125;)@SpringBootApplication@EnableDiscoveryClient@EnableCircuitBreaker@SpringCloudApplication  上面三者合并\n\n具体使用\n\n主要是设置@DefaultProperties(defaultFallback = &quot;defaultFallback&quot;)\ndefaultFallback是方法名, 指定超时或熔断后需要降级调用的方法;\n当然也可以全局指定降级方法@DefaultProperties(defaultFallback = &quot;defaultFallback&quot;)\n123456789101112131415161718@RestController此类所有方法出现异常都默认调用defaultFallback@DefaultProperties(defaultFallback = defaultFallback)public class HystrixTestController &#123;    @HystrixCommand(         指定某个方法的降级方法(优先级高于全局的)        fallbackMethod = fallback,        commandProperties = &#123;             默认超时时间为1秒, 根据具体业务设置timeout            @HystrixProperty(                name = execution.isolation.thread.timeoutInMilliseconds,                value = 2000)&#125;)    @GetMapping(hystrixgetProductList)    public String getProductList() &#123;         调用其他服务接口...    &#125;&#125;\n依赖隔离\n正常情况下, 请求都是使用一个线程池, 比如Servlet就是单例多线程模型, 多线程就是使用线程池;\n如果某个服务(方法调用rpc调用http调用)出现故障, 比如超时等待,或阻塞, 多人并发调用此服务会导致线程池瞬间耗尽, 影响其他服务的调用;\n解决办法就是线程隔离, 隔离办法就是为每个@HystrixCommand启动一个线程池, 池之间是互不影响的, 类似sandbox沙盒, 可以类比我们所熟悉的Reactor反应堆模型或Proactor主动器模型类似的实现方式\n同步异步, 阻塞非阻塞, reactorproactor\n这里复习下之前说过的概念, 为了捋顺思路, 分几个层次来说明\n\n同步异步, 阻塞非阻塞\n\n\n\n同步异步 : 关注消息通讯链路方式\n是原有链路返回, 还是通过其他本地接口回调MQ消息远程rpchttp接口, 即其他链路返回\n阻塞非阻塞: 关注线程在调用并等待获取结果时线程的状态\n可理解为client调用server之后, client是挂起等待, 还是立即不管了,可以去做其他事情\n如何理解同步非阻塞?\n看下面的分析\n\n\n\n理解层次的不同\n\n\n\ncpu层次\nIO指令发出后, 执行后续指令(并不等待), 所以是非阻塞\n数据准备好后是通过中断信号来通知IO操作, 所以是异步\ncpu是真正意义上的异步非阻塞\n操作系统(kernel内核)\n为了减轻编码难度, 系统内核封装成了同步调用接口(readwrite); 问题在于此方式会挂起调用方线程(即同步阻塞接口);\n所以提出改进 :\n主要改进点在于把阻塞点封装到内部并优化, 让外部使用者不阻塞即可, 至于异步还是同步重要程度不如前者; 因为阻塞挂起会极度影响效率; 实现方式当前有如下三种 :\n(1).多线程(同步阻塞)\n只是使用了线程池, 效率有一定提升, 本质还是同步阻塞\n(2).IO多路复用(selectpollepoll 同步非阻塞)\n它内部使用了一个select线程轮询所有的fd队列集合上的可读事件, 相当于将阻塞点封装到了内部的select轮询上, 这样就不会阻塞客户端调用线程,  且内部使用了事件机制来进行了优化, 效率大大提升;\n注意, client如果不阻塞了则需要轮询读取数据, 因为可能一次读取数据是没有准备完整的, 它只管是有可读事件, 有1byte也叫可读, 虽然同步, 但已经不阻塞客户端了\n(3).暴露异步接口(异步非阻塞)\n将同步接口直接改为异步返回, 既然异步了, 何不将数据完全准备好后再通知进程呢? 所以AIO的确是这样做的, 用户进程就无须再进行数据拷贝操作, 直接就可用; 典型的实现有kernel-aio(linux), ICOP(微软)\n程序员感知(应用进程)\n(1) NIONetty(java), 使用上是同步非阻塞, 本质是改变阻塞点到内部了, 使用上感知不到\n(2) NodeJS, 使用上是异步非阻塞接口, 实际在操作系统层次是同步非阻塞(IO多路复用-epoll)\n(3) AIO, 如果是在操作系统上的实现,比如ICOP, kernel-aio, 这两者是真正意义上的异步非阻塞, 因为异步非阻塞的一个重大特点就是应用进程不参与数据复制, 由内核完成数据拷贝后再通知, 所以真正的AIO是需要操作系统级别的支持;\n比如应用层次的netty4, 支持了AIO, 使用上是异步非阻塞, 内部还是多路复用, 只是提供了Future接口的get函数来阻塞获取最终完整结果, 模拟达到AIO的异步复制完成并通知的效果, 因为不阻塞read, 阻塞的是future.get\n\n\n\nReactorProactor\n\n其实这是上面讲述的IO多路复用的两种设计模式;\n\n\nReactor采用同步非阻塞(多路复用)\nProactor采用异步非阻塞(AIO)\n注意上面所讲述的异步非阻塞的重大特点就是应用进程不参与数据复制, 由内核完成数据拷贝后再通知, 所以真正的AIO是需要操作系统级别的支持; 所以可以通过同步IO模拟Proactor\n若是应用进程模拟, 则只能通过Future等形式来封装异步库, 使用者得到的即为AIO(不是真正的内核级别)\n\n\n\nnetty\n\n这个以后会单独写, 先看两个图\nnetty使用了IO多路复用模型, 内部使用异步接口Future, 所以netty对于使用者算是异步非阻塞,\n当然它也支持同步模式\nReactor模型是netty采用的实现模式\nSpring5发布了Spring WebFlux, 因为之前的SpringMVC是一请求一线程的同步阻塞模型, 就算提供了异步接口内部也是同步阻塞的;\nWebFlux则是基于Reactor模型响应式的\n图1 (Doug Lee - Scalable IO in Java)\n\nnetty参考了上图的Reactor模型, 具体实现只有细微差别, 大致方向是符合Doug Lee大神的思路\n\n参考: 目前最透彻的Netty原理架构解析 \n服务熔断\n主要还是@HystrixCommand, 之前说过降级配置fallbackMethod, 和调用超时阈值execution.isolation.thread.timeoutInMilliseconds(默认1秒);\n断路器设计模式-状态机\n\n\nclosed\n默认为关闭状态, 当失败(超时异常…)到达一定的阈值, 则转为open状态;\nopen\n一旦为open状态, 此时服务将采用降级调用, 会开启一个时钟倒计时, 计时结束后进入half-open状态\nhalf-open\n此状态会将到达的多个请求, 释放一次去执行正常业务逻辑, 如果还是失败, 则回到open状态, 时钟倒计时重置;  如果正常就回到closed状态\n\n\n\n现在来说明下熔断配置\n\n\ncircuitBreaker.enabled = true\n启用熔断; 用来跟踪circuit的健康性, 如果未达标则短路, 默认true\ncircuitBreaker.requestVolumeThreshold = 20\n滑动窗口最小请求数; 比如一个滑动窗口统计时间内(比如10s), 调用20次都失败(异常或超时), 则开启熔断机制,  进入open状态;  如果10s统计时间内只调用19次且都失败, 都不会开启熔断; 默认20\ncircuitBreaker.sleepWindowInMilliseconds = 5000\n滑动窗口长度(毫秒), 意思是half-open状态的到期时间; 此状态内, 降级逻辑临时成为主逻辑, 到期后会释放一次请求去执行主逻辑;\n如果成功, 则回到closed状态, 请求变更为执行主逻辑;\n如果失败, 则回到open状态, 重置到期时间开始倒计时;\ncircuitBreaker.errorThresholdPercentage = 50\n错误比率阀值; 上面设置断路器请求数为20, 这里是设置开启断路器开启的失败百分比; 默认50;\n比如10s内30次请求(&gt;=20)失败了15次, 失败率50%&gt;=50%, 则会进入open状态\nmetrics.rollingStats.timeInMilliseconds\n滑动窗口的统计时间, 默认10s; 它只会统计此时间内的请求情况\n\n\n1234567891011121314151617181920212223242526272829303132333435363738394041@HystrixCommand(        fallbackMethod = fallback,        commandProperties = &#123;                @HystrixProperty(name = execution.isolation.thread.timeoutInMilliseconds, value = 2000),                @HystrixProperty(name = circuitBreaker.enabled, value = true),  设置熔断                @HystrixProperty(name = circuitBreaker.requestVolumeThreshold, value = 20),                @HystrixProperty(name = circuitBreaker.sleepWindowInMilliseconds, value = 5000),                @HystrixProperty(name = circuitBreaker.errorThresholdPercentage, value = 60)        &#125;)@GetMapping(hystrixgetProductList1)public String getProductList1(@RequestParam(number) Integer number) &#123;     偶数则直接放行    if (number % 2 == 0) &#123;        return success;    &#125;     奇数则访问异常的product服务    else &#123;        try &#123;            Thread.sleep(2000);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;        RestTemplate restTemplate = new RestTemplate();        String res = restTemplate.postForObject(                http:127.0.0.1:8081productlistForOrder,                Arrays.asList(157875196366160022),                String.class);        return res;    &#125;&#125;** * 单个方法的降级,优先级高 * * @return *private String fallback() &#123;    return 繁忙中, 请稍后再试...;&#125;\n详细配置说明请参考 :\nHystrix 参数详解\nHystrix 配置参数全解析\n开启hystrix-dashboard\n\n添加依赖\n\n123456789&lt;dependency&gt;    &lt;groupId&gt;org.springframework.cloud&lt;groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;artifactId&gt;&lt;dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;groupId&gt;    &lt;artifactId&gt;spring-boot-starter-actuator&lt;artifactId&gt;&lt;dependency&gt;\n\nApplication启动类添加注解\n\n1@EnableHystrixDashboard\n\n添加servlet\n\n注意, 由于springboot的路径我们默认为’’, 所以需要在xml中添加hystrix-dashboard的servlet路由\n可以在HystrixMetricsStreamServlet的注释中找到说明\n123456789@Beanpublic ServletRegistrationBean getServlet() &#123;    HystrixMetricsStreamServlet streamServlet = new HystrixMetricsStreamServlet();    ServletRegistrationBean registrationBean = new ServletRegistrationBean(streamServlet);    registrationBean.setLoadOnStartup(1);    registrationBean.addUrlMappings(hystrix.stream);    registrationBean.setName(HystrixMetricsStreamServlet);    return registrationBean;&#125;\n\n进入dashboard\n\n经过尝试, 单节点应用按如下配置\n123地址: http:localhost:8082hystrix.streamdelay: 随意填title: 填项目名即可\n注意事项\n\n开启feign对Hystrix服务熔断降级支持\n\n12345678910111213#开启Feign Hystrix支持(Finchley.SR1版本没有属性提示)feign:  hystrix:    enabled: truehystrix:  command:    #更多配置请参考https:zhenbianshu.github.io201809hystrix_configuration_analysis.html    #针对所有请求生效, 如果想针对某个Action生效, 此处请写方法名, 或者commandKey指定的值 (不是URL)    default:      execution:        isolation:          thread:            timeoutInMilliseconds: 2000\n\n服务降级的接口或者类必须能扫描到\n\n12345此处为了扫描到FeignClientFallback服务降级类, 因为默认只会扫描此包下的类@ComponentScan(basePackages = org.doyo) 必须添加FeignClient接口包路径, 否则编译报错, 第二个路径用于测试@EnableFeignClients(basePackages = &#123;org.doyo.product.client, org.doyo.order.client&#125;)\nSleuth-Zipkin\n原理\n链路请求跟踪, zipkin是根据Google发表的Dapper论文进行实现;\nsleuth是对zipkin的一个包装\n其基本思路是在服务调用的请求和响应中加入ID, 标明上下游请求的关系;\n日志信息\n1[order-server,4315dc6135b627e5,8853c37e804e2230,false]\n\napplication name\n为一个请求分配的ID号, 用来标识一条请求链路\ntraceId\n为一个请求分配的ID号, 用来标识一条请求链路\nspanId\n表示一个基本的工作单元, 一个请求可以包含多个步骤, 每个步骤都拥有自己的spanId; 一个请求包含一个TraceId, 多个SpanId\nexport\n是否要将该信息输出到类似Zipkin这样的聚合器进行收集和展示;\n需要配置采集样本速率, 默认0.1, 如下所示 :\n\n1234567spring    sleuth:        feign:          enabled: true        sampler:          #采集率0~1          probability: 1.0\npom依赖\n\nzipkin客户端\n\n123456789&lt;dependency&gt;    &lt;groupId&gt;org.springframework.cloud&lt;groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-sleuth&lt;artifactId&gt;&lt;dependency&gt;&lt;!-- sleuth集成zipkin客户端 --&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework.cloud&lt;groupId&gt;    &lt;artifactId&gt;spring-cloud-sleuth-zipkin&lt;artifactId&gt;&lt;dependency&gt;\n或者简化为\n12345&lt;!-- 上面的两个依赖可简化为 --&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework.cloud&lt;groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;artifactId&gt;&lt;dependency&gt;\n\nzipkin服务端\n\n1234567891011&lt;!-- Zipkin服务端 --&gt;&lt;dependency&gt;    &lt;groupId&gt;io.zipkin.java&lt;groupId&gt;    &lt;artifactId&gt;zipkin-server&lt;artifactId&gt;&lt;dependency&gt;&lt;!-- Zipkin可视化界面依赖 --&gt;&lt;dependency&gt;    &lt;groupId&gt;io.zipkin.java&lt;groupId&gt;    &lt;artifactId&gt;zipkin-autoconfigure-ui&lt;artifactId&gt;    &lt;scope&gt;runtime&lt;scope&gt;&lt;dependency&gt;\n注解与配置\n\n服务端\n\n123456789 或者使用@EnableZipkinStreamServer, 但需要依赖MQ springboot2.0已经不推荐自建zipkin-server, 且mq方式也变了@EnableZipkinServer@SpringBootApplicationpublic class ZipkinServerApplication &#123;    public static void main(String[] args) &#123;        SpringApplication.run(ZipkinServerApplication.class,args);    &#125;&#125;\n\n客户端\n\n12345678910111213141516171819spring:  sleuth:    feign:      enabled: true    sampler:      #1.采集频率      probability: 1.0    web:      client:        enabled: true  zipkin:    enabled: true    #2.zipkin地址    base-url: http:localhost:9411    service:      name: $&#123;spring.application.name&#125;    sender:      #3.注意一定要指定数据传输方式, 否则不会到达zipkin      type: web\n升级spring-boot2.x\n已经不推荐上面自己创建zipkin server, 需要使用编译好的jar包\n1docker run -d -p 9411:9411 openzipkinzipkin\n本机服务地址\n12345678910eureka-server: http:localhost:8761zuul-gateway :    - http:localhost:8083product-serverproductlist    - http:localhost:8083order-serverordercreateorder-server :项目地址: https:github.comasan3524yiran配置文件地址: https:github.comDoyuLycloud-config-reporabbitmq: http:localhost:15672config-server: http:localhost:8080zipkin-server: http:localhost:9411","tags":[],"path":"2019/04/22/SpringCloud初体验/","external_link":""}]';

	s = s.replace(/\\n/g, "\\n")
               .replace(/\\'/g, "\\'")
               .replace(/\\"/g, '\\"')
               .replace(/\\&/g, "\\&")
               .replace(/\\r/g, "\\r")
               .replace(/\\t/g, "\\t")
               .replace(/\\b/g, "\\b")
               .replace(/\\f/g, "\\f")

// remove non-printable and other non-valid JSON chars
	s = s.replace(/[\u0000-\u0019]+/g,"");
	var list = JSON.parse(s);
	var fuse = new Fuse(list, options);
	var el = document.getElementById('search-form');
	var newBox = $('.Card-archive').first().clone();
	el.oninput = function(event){
		var searchText = el.value;
		var result = fuse.search(searchText);
		$('.archive-cards .Card-archive').remove();
		for(var i in result){
			var anotherBox = newBox.clone();
			var dateStr = new Date(result[i].date);
			anotherBox.css('display','flex');
			var url = "";
			if(result[i].external_link !== ""){
				url = result[i].external_link;
			}else{
				url = '/' + result[i].path;
			}

			anotherBox.find('.Card-title a').text(result[i].title).attr('href', url);
			anotherBox.find('.Card-date').text(dateStr.toDateString());
			anotherBox.appendTo('.archive-cards');
		}
	}
</script>

<div class="tagcloud-container">
<div class="tag-cloud">
	<a href="/tags/线程池/" style="font-size: 0.8em; color: #488baf">线程池</a> <a href="/tags/锁/" style="font-size: 0.8em; color: #488baf">锁</a> <a href="/tags/队列/" style="font-size: 0.8em; color: #488baf">队列</a>
</div>
</div>

  </div>

  

<footer id="footer">
    <div class="footer-copyright">
        <div>
            <p style="font-family: sketch; font-size: 28px;">just do it</p>
            <p> 版权所有 <a href>duyu </a> @ 2019</p>
            
        </div>
    </div>
    
    <div class="footer-social">
        
            
                
                    <div class="footer-social-item">
                        <a href="https://github.com/doooyo" target="_blank">
                        
                            <i class="fab fa-github fa-2x" aria-hidden="true"></i>
                        
                        </a>
                    </div>
                
            
                
                    <div class="footer-social-item">
                        <a href="/atom.xml" target="_blank">
                        
                             <i class="fa fa-rss fa-2x" aria-hidden="true"></i>
                        
                        </a>
                    </div>
                
            
        
    </div>
</footer>

  <br>

  <div id="footer-menu-container">
		



<nav class="menu">
	
	
		
		
		
		
		
		<div class="menu-item grow">
			<div class="menu-icon">
				<a href="/archives/" title="归档">
					<img src="/images/icons/own/archive.svg" alt>
				</a>
			</div>
			<div class="menu-name">
				<a class="menu-link" href="/archives/">
					<span>归档</span>
				</a>
			</div>
		</div>
		<div class="menu-item grow">
			<div class="menu-icon">
				<a href="/search/" title="搜索">
					<img src="/images/icons/own/search.svg" alt>
				</a>
			</div>
			<div class="menu-name">
				<a class="menu-link" href="/search/">
					<span>搜索</span>
				</a>
			</div>
		</div>

</nav>

	</div>

  



    






  <script>
  var gitment = new Gitment({
    id: window.location.pathname, // optional
    owner: 'doooyo',
    repo: 'https://github.com/doooyo',
    oauth: {
      client_id: '4320b9f63ad425418eb5',
      client_secret: '9c0cb6fffad72917fe8416c9ac2066dc70127d9b',
    },
    // ...
    // For more available options, check out the documentation below
  })

  gitment.render('gitment')
  </script>







    <script src="/js/lightgallery.min.js"></script>
<script src="/js/lg-zoom.min.js"></script>
<script type="text/javascript">
    $(document).ready(function() {
        $("#lightgallery").lightGallery(); 
        $(".article-content img").each(function(){
            console.log($(this).attr('src'))
            $(this).attr('data-src', $(this).attr('src')).lightGallery({
                selector: 'this'
            })
        });
    });
</script>






<script type="text/javascript">

  
</script>



<!-- <script src="/js/post.js"></script> -->

<script src="/js/headroom.min.js"></script>

<script data-no-instant type="text/javascript">

initHeadroom();

changeLayoutOnTouchScreen();

// 
</script>


<!-- End Document
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
</body>
</html>
